# 项目概要

实习：

* 视觉软件开发：对视觉软件进行二次开发，提供接口进行任务执行结果的配置、获取与返回，提供交互界面进行参数设置、任务图像显示窗口配置、图像实时显示等，并可通过网络调试工具及自有平台进行调用。
* OCR检测识别：通过深度学习方法对芯片的编号进行检测及识别，提高识别准确率，并支持自有平台接口调用。



视觉软件开发：

​	**项目背景：**已有的视觉软件不支持通信指令交互，无法结集成到自研平台中，且任务执行结果的获取受限，不方便操作人员使用。

​	**项目描述：**对视觉软件进行二次开发，提供接口进行任务执行结果的配置、获取与返回，提供交互界面进行参数设置、任务图像显示窗口配置、图像实时显示等，并可通过网络调试工具及自有平台进行调用。

​	**项目难点：**视觉软件存在65+个可选工具，每个工具对应着若干派生类及不同样式的多层嵌套的结果。对任务结果的获取与存储、配置文件的设计、界面的交互及展示的设计等是项目的重点。

技术栈：dnspy反编译软件

**代码量：**1.2k行

**项目实现：**

* 结果获取与保存：实现了65+个工具、12个派生类的结果获取函数，通过工厂模式派分，并使用多重嵌套的Dictionary保存任务执行的结果；
* 通信交互协议：通过TCP通信控制图像任务执行，参数设置，结果输出，并兼容VM协议。支持任务指令关联关键字配置、任务输出参数格式配置等；
* 显示界面配置：通过Winform搭建界面进行交互，提供了菜单及其他可视化选项，并实现了图像任务显示窗口配置、图像实时显示、任务配置入口等功能。



**OCR检测识别**：

​	部署PaddleOCR对芯片上的编号进行检测及识别，对数据集进行标注及清洗，并通过模型微调等提高准确率。

​	PP就是百度飞浆的一个源于产业实践的开源深度学习平台，PaddleOCR就是他们集成的一个OCR的库。像我们搞研究的可能应用不那么多，因为更改网络结构没那么方便。但对于应用部署会比较常用，因为集成度比较高，部署比较方便

​	主要工作是数据标注、清洗、调参，因为这个虽说完整度比较高，但还是需要去根据你具体的任务去调参、部署等



**腐蚀检测**

​	这个项目是2月多就开始拉群讨论的一个，和材料等很多学院合作的。一开始是让我带着研一的师弟搞的，前期参会比较多，然后五六月份我开始实习搞秋招，后面主要就是研一的师弟来搞了

​	这个项目因为还在搞，所以在简历里会写的比较模糊，且只写了其中的一部分。然后主要目的是对船舶材料

​	我们是检测算法组，主要负责的是先通过预处理去除金相图中的噪声，再使用特征提取网络提取图像特征，最后通过回归网络得到最后的预测DOS值结果。

​	预处理：固定值填充和自适应填充。固定值填充用我们预设的背景值直接填充噪点，以消除噪点的影响。而自适应填充通过设定一个阈值，将值大于阈值的点的三通道颜色值取平均得到每张图片的一个背景近似值，用该值填充噪点。虽然预处理后的图片更清晰，但实测反而会让网络的训练不稳定。

​	LIBS数据是基于激光脉冲峰值产生的数据，其通过不同波长下的波峰与元素的对应关系来推断DOS值大小。LIBS数据反映了金属材料中铝和镁的含量变化。而通过这一变化就可以反映出DOS值情况。然后通过波长和响应强度的一个数据分布，我们可以通过这个峰值来看这个镁铝的含量，判断其腐蚀程度，进而推测出DOS值



**人体姿态估计**：

​	首先对于骨干网络，用的HRNet，这个网络因其多尺度分支和特征融合的特性，广泛用于人体姿态估计任务中，但存在参数量大的问题。然后我首先将参数量占比70%的第四阶段去掉，看了下结果准确率降了2%，所以感觉这个第四阶段多少是比较冗余了，然后就开始探究如何来弥补这个准确率的损失。因为看似降低的比较少，但那些SOTA差距其实都蛮小的

​	首先就是改进编解码方式：将关键点坐标表征为两个一维向量，来减小量化误差的影响，并将人体关键点定位变为一个分类问题：网络输出n个关键点对应n个embedding，也就是网络输出n条一维向量，再通过线性投影（MLP等）输出n个SimDR表征，即每个关键点对应两条向量。然后通过1D高斯分布来生成监督信号。

​	改进特征提取网络：

​	然后加了GAU，就是结合了GLU和自注意力的一个模块

​	引入GCN，想来结合人体结构间的关系。去掉了MLP

​	探究了引入顺序、位置、MLP层等各种因素，因为加的不合适的话，不仅不会提高准确率，反而会降低的比较多。。

​	

**人脸口罩**：

​	科大讯飞这个就属于竞赛了，通过更改网络结构等跑出更高的成绩。但因为他这个数据量不够大，到后面比较难优化了



C++软件开发相关的项目经验的话：

​	分布式网络通信框架是在Linux下通过c++11开发的。服务发布方需要定义proto文件描述方法及请求响应类型、继承protobuf生成的基类并重写基类方法，即可将本地方法发布为远程RPC方法，实现大型项目的分布式部署。

* 使用Protobuf作为数据通信协议进行数据的序列化和反序列化；
* 使用Zookeeper作为服务注册中心，完成rpc服务的服务注册、服务发现；
* 使用Muduo网络库完成主机间的通信；
* 通过Notify接口将服务对象和方法存储在unordered_map中，通过run接口进行rpc服务的发布及网络服务的启动；
* 通过onMessage事件回调进行网络消息的接收、反序列化及rpc方法的调用，其中通过自定义消息结构避免粘包问题；
* 对于rpc服务调用方，通过重写protobuf中的CallMethod方法，实现请求的序列化、网络消息的发送及接受、反序列化响应得到rpc方法的调用结果；
* 通过CMake构建项目集成编译环境，将框架编译为静态库进行使用。



​	Linux 下开发的基于C++11标准的高并发 Web 服务器，在应用层实现了一个简单的HTTP服务器，支持多个客户端访问服务器的图片和视频等资源。在2核4G内存的云服务器中进行压测，长连接下QPS可达5.1w。

* 使用线程池、非阻塞IO、ET实现的epoll以及模拟Proactor的并发模型，并仿照Muduo网络库实现了主从Reactor的并发模型；
* 使用状态机解析HTTP请求报文，支持解析GET请求，支持HTTP长连接与短连接；
* 通过小根堆实现的定时器关闭超时的非活跃连接；
* 通过双缓冲区实现了异步日志。



​	Linux下开发的基于C++11标准的线程池，支持线程数量动态增长、任务优先级的调整、任意任务函数和任意数量参数的传递、异步获取任务处理结果。

* 实现了固定线程数量及线程数量动态增长两种模式，其中动态增长模式根据任务数量、空闲线程数量以及设定的最大线程数判断是否要创建新线程；
* 通过packaged_task对提交任务的函数进行包装，并通过future类模板异步获取任务处理结果；
* 使用STL容器管理线程对象和任务，实现线程安全的任务队列，并通过任务队列插入位置进行任务优先级的调整；
* 基于可变参模板、引用折叠、完美转发等原理实现线程池提交任务接口。





# 自我介绍

​	Hello interviewer, I am Wang Hao. I was born in Linyi City, Shandong Province, so I chose to major in automation in Shandong University for my undergraduate degree. I was ranked 7th in my major in my undergraduate program and won the first prize of Shandong University Academic Scholarship for many times. I wanted to go to a foreign province to have some experience in graduate school, and it just so happened that my sister was studying in Huanong, so I chose Huazhong University of Science and Technology (HUST) School of Artificial Intelligence and Automation when I was guaranteed a place in the program. During the postgraduate period, he was awarded the first class master's academic award and freshman scholarship of Huazhong University of Science and Technology.

















​	面试官好，我是王皓。很高兴能参加此次面试，下面我将对我的教育经历、实习经历、项目经历等进行一个简要的介绍。

​	我是山东临沂人，本科就读于山东大学自动化专业，专业排名第7，本科期间多次获得山东大学学业奖学金一等奖。
​	研究生保送到了华中科技大学人工智能与自动化学院的多谱信息智能处理技术全国重点实验室，研究方向是基于深度学习的二维人体姿态估计，主要任务是在多人场景下，对图像或视频中人体的关键点进行定位。研究生期间曾获华中科技大学一等硕士学业奖、新生奖学金等。

​	个人技术上，擅长软件开发方向，有Linux和Windows下软件开发经验，做过一些相关的项目如视觉软件开发、分布式网络通信框架、Web服务器等；其次擅长深度学习方向，做过人体姿态估计、腐蚀检测、OCR等项目。

​	实习方面在武汉的华为海思实习了两个月，期间独立完成了视觉软件开发和OCR检测识别两项任务，均交付使用。

​	我的自我介绍到此结束。感谢今天能有这个面试的机会。

## 项目描述

> 规范一下格式

![image-20230718233848311](E:\MarkDown\picture\image-20230718233848311.png)



这个过程可以这样跟面试官描述：

**1**、在消息推送平台里，我们有个接入层`austin-api`，它是**消息的统一入口**，所有的消息推送都会经过该接入层进行处理。

**2**、使用消息推送平台的业务方可以简单分为两种角色：运营和技术。如果是技术，他会调用我在接入层暴露的接口。如果是运营，他会使用我的消息推送后台去设置定时任务推送，所以我们会有个推送后台`austin-admin`以及定时任务模块`austin-cron`

**3**、接入层干的事情比较简单，简单概括就是消息做简单的校验以及参数拼装后就写入到了消息队列

**4**、写到了消息队列之后，自然就有个逻辑层对消息队列的消息进行消费，在我这边叫做`austin-handler`模块，它主要对消息做去重、夜间屏蔽等逻辑，最后就分到不同的消息类型Handler进行消息发送

**5**、消息推送平台跟普通消息下发最大的不同是我们是实现对**消息全链路追踪**的，业务方可以通过推送后台实时查看消息下发的情况，针对消息模板和用户都是OK的（比如这个用户是否接收到消息，如果没接收到，那可能是因为什么被过滤了）

**6**、所以消息推送平台会有个实时流的模块，用Flink实现的。我在消息处理的过程中**对多个关键的位置进行埋点**，在Flink对这些信息做清洗处理，实时的会写进Redis、离线的会落到Hive中



# 线程池项目

> * 线程池中的工作线程是一直等待吗？fixed模式下如果任务队列没有任务，是会堵塞等待；cache模式下则可能会被析构
> * 你的线程池工作线程处理完一个任务后的状态是什么？就绪执行或堵塞
> * 如果同时1000个客户端进行访问请求，线程数不多，怎么能及时响应处理每一个呢？任务队列或cache模式
> * 如果一个客户请求需要占用线程很久的时间，会不会影响接下来的客户请求呢，有什么好的策略呢？不会。采用线程池

## 线程池优势

* 频繁创建和销毁线程会影响程序的性能，而线程池可以重复利用已创建的线程，减小开销
* **提高线程的可管理性**，使用线程池可以控制系统中线程的数量，并对线程进行统一的分配、监控和调优
* 提高可维护性：使用线程池可以更好地管理线程，从而提高代码的可维护性。例如，可以为线程池中的线程设置优先级，以确保在系统资源有限的情况下，优先处理最重要的任务。
* 任务队列：线程池中的任务队列能够缓冲任务，使得线程池中的线程能够按照任务的优先级进行处理。

## 提交任务接口

函数模板、可变参模板、引用折叠、完美转发、尾置返回类型、future和package_task

```cpp
template <typename Func, typename... Args>
auto submitTask(Func&& func, Args&&... args) -> future<decltype(func(args...))> {
	using RType = decltype(func(args...));
	auto task = make_shared<packaged_task<RType()>>(bind(forward<Func>(func), forward<Args>(args)...));
	future<RType> result = task->get_future();
}
```



## 线程选择

* 主线程和子线程通过一个共享的工作队列来同步，当有新任务到来，主线程将任务添加到工作队列中，这将唤醒正在等待任务的子线程，其中一个子线程从工作队列中取出任务并执行，其他子线程继续睡眠
* 这里的通知机制用的就是条件变量，主线程和子线程构成生产者消费者模型

<img src="E:\MarkDown\picture\image-20230411201315490.png" alt="image-20230411201315490" style="zoom:50%;" />

提交任务后，任务会被放到任务队列中（如果1s内任务没有提交，比如任务队列满了，就会提交失败）。然后如果任务队列不为空，就会唤醒线程执行任务。

cached模式需要根据任务数量和空闲线程的数量，判断是否需要创建新的线程出来

## 双条件变量

> 在双条件变量的方式下，生产者和消费者分别有自己的条件变量，生产者堵塞自己的条件变量到不满、唤醒消费的条件变量；
>
> 消费者堵塞自己的条件变量到不空、唤醒生产者的条件变量。
>
> **优势：**
>
> * 减少唤醒竞争：生产者和消费者有各自的条件变量，减少了唤醒竞争问题。（只有一个条件变量时，当有多个消费者在等待时，生产者发出信号只能唤醒一个消费者，其他消费者会继续等待，导致唤醒竞争）
> * 粒度更细：比如可以在消费者线程中，判断如果任务队列有任务，则通知其他wait在notEmpty_的消费线程执行任务
>
> **劣势：**
>
> * 相对复杂：需要管理两个条件变量，逻辑较复杂。
> * 资源消耗稍多：需要维护两个条件变量。



> 没有空余才等待，因此需要等待notFull_
> 使用双条件变量可以进行更精细的操作，比如如果任务队列仍有任务，则通知其他wait在notEmpty_的线程执行任务

```c++
// 等到taskQue_.size()小于最大值，即等到不满，就能往里填任务了
notFull_.wait_for(lock, std::chrono::seconds(1), [&]()->bool {return taskQue_.size() < taskQueMaxThreshHold_; });
// 唤醒消费
notEmpty_.notify_all();
```

消费者

```c++
// 线程执行时，若任务队列为0，则notEmpty_.wait(lock);
while (taskQue_.size() == 0) {
    notEmpty_.wait(lock);
}


// 两个条件变量便于进行更精细的操作，比如在这里，
// 如果任务队列仍有任务，则通知其他wait在notEmpty_的消费线程执行任务
if (taskQue_.size() > 0) {
    notEmpty_.notify_all();
}
// 唤醒生产
// 通知 wait在notFull_上的生产者，可以继续提交任务
notFull_.notify_all();
```

```c++
void producer() {
	// 生产者每生产一个，就通知消费者消费一个
	for (int i = 1; i <= 10; ++i) {
		std::unique_lock<std::mutex> lock(mtx);

		// 如果容器不为空，代表还有产品未消费，则堵塞，等待消费者线程消费完，再生产
		while (!vec.empty()) {  // while(vec.size() == 10) // 如果为10，则堵塞，消费完再生产
			// wait做了两件事：进入堵塞态，即线程被堵塞，等待条件变量；释放mtx锁
			cv.wait(lock);
		}
		// 生产
		vec.push_back(i); // 表示生产者生产的产品序号i

		cv.notify_all();
	}
}
// 消费者线程函数
void consumer() {
	// 消费者每消费一个，就通知生产者生产一个
	for (int i = 1; i <= 10; ++i) {
		std::unique_lock<std::mutex> lock(mtx);

		// 如果容器为空，代表还有没有产品可消费，等待生产者生产，再消费
		while (vec.empty()) {
			// 判断容器为空，进入堵塞状态，释放mtx锁，
			// 让生产者线程抢到锁能够去生产产品
			cv.wait(lock);
		}
		// 消费
		vec.pop_back();

		cv.notify_all();
	}
}
```



## 线程的创建和销毁

​	**Thread类**中保存（线程池的）任务函数、线程id，并提供start函数创建任务函数为func的线程并设置为分离线程。detach()函数会立即将std::thread对象与线程分离，线程函数执行完毕后，线程会自动销毁，因此这里**为了维持线程的存在，线程函数都是while(1)循环**。

**创建：**
	创建的指向Thread对象的指针都存在：`std::unordered_map<int, std::unique_ptr<Thread>> threads_;`，使用unique_ptr就可以在要析构线程时方便的通过erase进行析构。

**启动：**
	线程池执行start函数后，会启动所有线程，此时所有的线程会执行（线程池的）任务函数，在while(1)循环中不断取任务（加锁）、执行任务。

**销毁：**
	当线程池对象析构的时候，isrunning标志位会置false，此时循环执行的线程会删除map中的当前线程，当前线程就会析构，然后通过`exitCond_.notify_all();`通知主线程。

​	线程池析构的时候会将 isPoolRunning_ 置为false，然后notEmpty_ .notify_all(); 并`exitCond_.wait`直到线程数量为0。这里每个线程看见isPoolRunning_ 后，就析构，并exitCond_.notify_all()下主线程，主线程就起来看下线程数量，当发现线程数量为0，线程池就结束析构了。

​	exitCond_ 是等待线程资源全部回收的条件变量

## 动态线程模式的实现

> 固定线程模式和动态线程模式
>
> * 动态线程模式适合任务处理比较紧急，适用于小而快的任务
> * 而对于比较耗时的任务，则固定线程模式更合适，因为若是不断有很多耗时的任务占着线程，会对系统的性能有很大的影响

​	在提交任务接口submittask中，根据任务数量、空闲线程数量以及设定的最大线程数判断是否要创建新线程出来。如果需要的话，就创建一个新线程，放到线程map中并执行线程

​	空闲时间超过60s会对线程进行回收。这里的检测是在线程执行函数中，**当任务列表为0，就会进行线程空闲时间的检测**，当大于设置的超时时间的时候，就在map中erase当前线程。

## 线程同步

> reference：https://subingwen.cn/cpp/mutex/#2-std-lock-guard

​	一个代码能否在多线程环境下执行，要看这段代码是否存在 **竞态条件**，如果存在竞态条件，我们就说该代码段**不是线程安全的**，不能直接运行在多线程环境当中。若是的话，则将这段代码称为 **临界区代码段**，我们需要保证它的**原子操作**。

​	如果这段代码在多线程环境下不存在竞态条件，则称为可重入的，否则称为不可重入的

对于线程同步，有线程互斥和线程通信两种场景

### 线程互斥

> 并发锁机制/并发的锁机制：互斥锁、读写锁、自旋锁、条件变量、信号量

#### **atomic 原子类型**

> ​	线程池中的总线程数量、空闲线程数量、任务的数量、线程池的启动状态(bool)都是用的比较轻量的原子类型，来实现线程安全。比较轻量，性能也好，用起来也简单。

> ​	原子指的是一系列不可被 CPU 上下文交换的机器指令，这些指令组合在一起就形成了原子操作。**原子操作就是要么全部执行，要么都不执行，不能出现执行到一半的中间状态**。在多核 CPU 下，当某个 CPU 核心开始运行原子操作时，会先暂停其它 CPU 内核对内存的操作，以保证原子操作不会被其它 CPU 内核所干扰。由于原子操作是通过指令提供的支持，因此它的性能相比锁和消息传递会好很多。

​	操作系统提供的CAS操作，一种无锁机制，比较轻量，基于活锁的方式，在linux下调用compare and set相关的接口实现，效率和性能高一些

```cpp
#include<atomic>
std::atomic_uint size;  // 有各种类型，如atomic_int、char等
```

##### **CAS**实现

​	CAS（compare and set）是乐观锁，假设不会发生并发冲突，每次不加锁而是先去完成某项操作，只在提交操作时检查是否违反数据完整性。

一般加锁的过程，包含两个步骤：

* 第一步，查看锁的状态，如果锁是空闲的，则执行第二步；
* 第二步，将锁设置为当前线程持有；

CAS 函数就把这两个步骤合并成一条硬件级指令，形成**原子指令**，这样就保证了这两个步骤是不可分割的，要么一次性执行完两个步骤，要么两个步骤都不执行。

* CAS操作包含三个操作数——内存位置（V）、预期原值（A）、新值(B)。
* 如果内存位置的值与预期原值相匹配，那么处理器会自动将该位置值更新为新值。
* 否则，处理器不做任何操作。
* 无论哪种情况，它都会在CAS指令之前返回该位置的值。
* CAS有效地说明了“我认为位置V应该包含值A；如果包含该值，则将B放到这个位置；否则，不要更改该位置，只告诉我这个位置现在的值即可。

```cpp
// CAS和TAS比较像，相比TAS就是增加了与旧值的一个比较操作，与旧值相同才设为新值
// 这里返回值也可以设置为bool，返回操作有没有成功
// 内存位置、预期原值、新值
int compare_and_swap (int* old_ptr, int oldval, int newval) {   
      int old = *old_ptr;   
      if (old == oldval) *old_ptr = newval;   
      return old; 
}

bool CAS(int* old_ptr, int old_val, int new_val) {
	int old = *old_ptr;
    if (old == old_val) {
        *old_val = new_val;
        return true;
    }
    return false;
}

// TAS
// 原子操作指令 —— 测试和置位（Test-and-Set）指令
// 既可以测试旧值，又可以设置新值，所以我们把这条指令叫作「测试并设置」
// 即使上锁和检查是两个步骤，不具有原子性，但通过返回的old临时变量的值保存的是上锁时lock的值，在多线程并发执行的时候不会存在线程安全问题
int TestAndSet(int *old_ptr, int newval) {
	int old = *old_ptr;
	*old_ptr = newval;
	return old;
}
```

#### 互斥锁/互斥量 mutex

##### **c++11：std::mutex**

> 在 C++11 中一共提供了四种互斥锁：
>
> * std::mutex：独占的互斥锁，不能递归使用。最为常用
> * std::timed_mutex：带超时的独占互斥锁，不能递归使用
> * std::recursive_mutex： /rɪˈkɜːsɪv/ 递归互斥锁，不带超时功能。也会用到，允许一个线程多次获得互斥锁的所有权，比如要对一个数字做加减乘除，则这几个运算函数都要是线程安全的，若其中有个操作，调用了加和减操作，则需要用到[递归锁](https://subingwen.cn/cpp/mutex/#3-std-recursive-mutex)
> * std::recursive_timed_mutex：带超时的递归互斥锁

​	mutex可以直接使用裸锁，即通过mutex.lock()和mutex.unlock()加锁解锁，也可以将mutex包装为lock类使用。

​	提供了两种Lock类：`lock_guard`（通过构造函数加锁，析构解锁，因此是在作用域内有效，适用于需要在一段代码块中进行保护的场景，不支持手动解锁操作）和`unique_lock`（灵活性更高，可以通过构造函数参数控制是否要对互斥量进行加锁，也可以通过成员函数`lock()`和`unlock()`手动加锁和解锁）。

> 多个线程是**线性的执行临界区代码**的，临界区越大程序效率越低，因此灵活度更高的unique_lock使用更多
>
> 线程池项目中用的都是unique_lock。但其实替换成lock_guard也一样，因为没有使用更精细化的lock和unlock操作

```cpp
std::mutex taskQueMtx_;
std::unique_lock<std::mutex> lock(taskQueMtx_);  // 封装裸锁，默认锁没锁的状态和传入的锁相同。然后正常的lock和unlock来使用

// unique_lock也可以传入第二个参数。unique_lock 的成员函数 lock() 上锁后，在对象析构的时候会自动解锁。当然也可以我们自己用Unlock解锁，很灵活
// std::adopt_lock表示这个互斥锁已经被 lock() 了，uniqie_lock 不会再重复上锁。
std::mutex taskQueMtx_;
taskQueMtx_.lock();  // 先lock()，才能在 unique_lock 中用 adopt_lock 标准
std::unique_lock<std::mutex> lock(taskQueMtx_, std::adopt_lock);

//  std::defer_lock表示并没有给 mutex 加锁，即初始化了一个没有加锁的 mutex
std::unique_lock<std::mutex> m_guard1(m_mutex1, std::defer_lock);
m_guard1.lock();
```

在linux中，`std::mutex` 在内部使用了 `pthread_mutex_t` 作为其实现的一部分，但 `std::mutex` 还提供了一些额外的功能，例如非递归锁等。

```cpp
class mutex {
    pthread_mutex_t _M_mutex;
public:
    mutex() { _M_mutex = PTHREAD_MUTEX_INITIALIZER; }
    ~mutex() { pthread_mutex_destroy(&_M_mutex); }
    void lock() { pthread_mutex_lock(&_M_mutex); }
    bool try_lock() { return pthread_mutex_trylock(&_M_mutex) == 0; }
    void unlock() { pthread_mutex_unlock(&_M_mutex); }
}
```

##### **linux：pthread_mutex_t**

​	实现是基于内核中的 `futex` 机制。上锁类型有普通锁、**可重入锁**(允许同一个线程对同一个锁成功获得多次，并通过多次 unlock 解锁)、**自适应锁**（自旋锁与普通锁的混合）、**检错锁**（如果同一个线程重复请求同一个锁，则返回EDEADLK(35)，报死锁错误）

​	对于其加锁操作，底层是汇编级别的CAS实现的

```cpp
// reference：https://blog.csdn.net/m0_37910557/article/details/110358119
typedef union {
  struct __pthread_mutex_s {
    int __lock;                 //!< mutex状态，0：未占用；1：占用。futex共享变量。
    unsigned int __count;       //!< 可重入锁时，持有线程上锁的次数。
    int __owner;                //!< 持有线程的线程ID。
    unsigned int __nusers;
    int __kind;                 //!< 上锁类型。
    int __spins;
    __pthread_list_t __list;
  } __data;
} pthread_mutex_t;
```

​	当多个线程试图获得同一个 `pthread_mutex_t` 时，它们会被放入一个等待队列中。这个等待队列被维护在内核中，它是一个双向链表。当一个线程成功获取了这个互斥锁，其他线程会被放入等待队列中，然后进入睡眠状态。当持有这个互斥锁的线程释放了它，等待队列中的一个线程会被唤醒，然后重新尝试获取这个互斥锁。

> `pthread_mutex_t`采用了futex的机制
>
> ​	**futex**的全称为fast userspace mutex，是一种快速用户空间互斥量。Futex是一种**用户态和内核态混合机制**，所以需要两个部分合作完成，linux上提供了sys_futex系统调用，对进程竞争情况下的同步处理提供支持。
>
> ​	futex提供了一种比传统的互斥量更高效的机制。**传统互斥量**的同步机制都是对一个内核对象操作来完成的，这个内核对象对要同步的进程都是可见的，其提供了共享的状态信息和原子操作。当进程间要同步的时候必须要通过系统调用在**内核**中完成。需要在内核和用户态之间进行频繁的切换。但很多同步是无竞争的，即某个进程进入 互斥区，到再从某个互斥区出来这段时间，可能并没有其他进程要进这个互斥区或者请求同一同步变量的。
>
> ​	而**futex**是一种用户态和内核态混合机制。**同步的进程间通过mmap共享一段内存，futex变量就位于这段共享内存中且操作是原子的，作为一个标记位，这个标记的值可以表示互斥量的状态或者等待队列的状态。**当进程尝试进入互斥区或者退出互斥区的时候，先去查看共享内存中的futex变量，如果没有竞争发生，直接进入临界区，并修改futex。而不用再执行系统调用了。当通过访问futex变量告诉进程有竞争发生，这时才会执行系统调用去完成相应的处理。简单的说，**futex就是通过在用户态对futex变量的检查，在用户态就可以完成对互斥量的操作，只有在存在竞争时才进行系统调用，这样可以减少内核态和用户态之间的切换次数，提高了程序的性能。**
>
> futex 可以根据共享资源的繁忙程度来决定是在用户态自旋等待还是在内核态等待，从而提高同步效率。
>
> futex实现的基本思想是：
>
> ​	在用户空间中，在共享内存创建一个一个整型变量作为内核态和用户态的标记，这个标记的值可以表示互斥量的状态或者等待队列的状态。当线程需要获取互斥量时，它首先在用户态尝试获取标记，如果成功获取，则直接进入临界区；如果获取失败，则线程将自己添加到等待队列，并将自己挂起，进入内核态等待标记的状态改变。当持有互斥量的线程释放互斥量时，会将标记的值改变，唤醒等待队列中的线程，使它们重新尝试获取标记。
>
> futex（fast user-space mutex）则是一种基于等待通知的锁，它是一种用户空间锁，支持线程阻塞，可以在等待锁的时候进行进程调度，相对于自旋锁在长时间等待的情况下性能更好。futex锁在等待锁的时候，使用系统调用进入内核空间，等待锁的状态变化，当锁可用时，futex通过系统调用返回，并获取到锁。
>
> ​	对于pthread_mutex_t，其_ data._ lock成员对应了futex变量

**区别**

`pthread_mutex_t` 是 POSIX 标准线程库中提供的锁类型，而 `std::mutex` 是 C++11 引入的标准互斥锁类。它们的主要区别在于语言和实现层面。

* 语言层面：`pthread_mutex_t` 是 C 语言中提供的锁类型，而 `std::mutex` 是 C++ 标准库中提供的互斥锁类。
* 使用方式：在 C++ 中，可以使用 RAII (Resource Acquisition Is Initialization) 的方式来保证锁的正确使用，也就是通过构造函数和析构函数的方式来实现自动加锁和解锁，避免了手动加解锁的可能出错的情况。而在使用 `pthread_mutex_t` 时，需要手动调用 `pthread_mutex_lock()` 和 `pthread_mutex_unlock()` 来加解锁。
* 实现方式：实际上，`std::mutex` 在内部使用了 `pthread_mutex_t` 作为其实现的一部分，但 `std::mutex` 还提供了一些额外的功能，例如非递归锁等。
*  `pthread_mutex_t`可以是**线程锁和进程锁**，std::mutex是**线程锁**



```cpp
// mutex使用
#include <iostream>
#include <thread>
#include <Windows.h>
#include <mutex>
 
using namespace std;
 
mutex mu;  //线程互斥对象
 
int totalNum = 100;
 
void thread01()
{
	while (totalNum > 0)
	{
		mu.lock(); //同步数据锁
		cout << totalNum << endl;
		totalNum--;
		Sleep(100);
		mu.unlock();  //解除锁定
	}
}
void thread02()
{
	while (totalNum > 0)
	{
		mu.lock();
		cout << totalNum << endl;
		totalNum--;
		Sleep(100);
		mu.unlock();
	}
}
 
int main()
{
	thread task01(thread01);
	thread task02(thread02);
	task01.detach();
	task02.detach();
	system("pause");
}
```



#### 忙等待锁/自旋锁spin lock

​	自旋锁是一种基于忙等待的锁，当一个线程发现共享资源被其他线程占用时，会**在一个循环中不停地尝试获取该资源，直到成功为止**。因此自旋锁适用于**短时间内能够获取到锁的情况，避免了进程上下文切换和线程阻塞等开销**。

```cpp
// 原子操作指令 —— 测试和置位（Test-and-Set）指令
// 既可以测试旧值，又可以设置新值，所以我们把这条指令叫作「测试并设置」
// 即使上锁和检查是两个步骤，不具有原子性，但通过返回的old临时变量的值保存的是上锁时lock的值，在多线程并发执行的时候不会存在线程安全问题
int TestAndSet(int *old_ptr, int new) {
	int old = *old_ptr;
	*old_ptr = new;
	return old;
}
// 自旋锁的实现
typedef struct lock_t {
	int flag;
} lock_t;
void init(lock_t *lock) {
	lock->flag = 0;
}
void lock(lock_t *lock) {  // 如果原来是0，则成功加锁；否则就在while中自旋
	while(TestAndSet(&lock->flag, 1) == 1);
}
void unlock(lock_t *lock) {  // 
	lock->flag = 0;
}
```

* 第一个场景是，首先假设一个线程在运行，调用 `lock()`，没有其他线程持有锁，所以 `flag` 是 0。当调用 `TestAndSet(flag, 1)` 方法，返回 0，线程会跳出 while 循环，获取锁。同时也会原子的设置 flag 为1，标志锁已经被持有。当线程离开临界区，调用 `unlock()` 将 `flag` 清理为 0。
* 第二种场景是，当某一个线程已经持有锁（即 `flag` 为1）。本线程调用 `lock()`，然后调用 `TestAndSet(flag, 1)`，这一次返回 1。只要另一个线程一直持有锁，`TestAndSet()` 会重复返回 1，本线程会一直**忙等**。当 `flag` 终于被改为 0，本线程会调用 `TestAndSet()`，返回 0 并且原子地设置为 1，从而获得锁，进入临界区。

很明显，当获取不到锁时，线程就会一直 while 循环，不做任何事情，所以就被称为「忙等待锁」，也被称为**自旋锁（spin lock）**。

这是最简单的一种锁，一直自旋，利用 CPU 周期，直到锁可用。在单处理器上，需要抢占式的调度器（即不断通过时钟中断一个线程，运行其他线程）。否则，自旋锁在单 CPU 上无法使用，因为一个自旋的线程永远不会放弃 CPU。

##### 无等待锁

![img](E:\MarkDown\picture\15-无等待锁.jpg)

##### 互斥锁与自旋锁的区别

* 互斥锁和自旋锁对于加锁失败后的处理方式是不一样的：**当加锁失败时，互斥锁用「线程切换」来应对，自旋锁则用「忙等待」来应对**。

  * **互斥锁**加锁失败后，线程会**释放 CPU** ，给其他线程；

  * **自旋锁**加锁失败后，线程会**忙等待**，直到它拿到锁；
* 互斥锁加锁失败而阻塞的现象，是由操作系统内核实现的，会有**两次线程上下文切换的成本**：

  * 当线程加锁失败时，内核会把线程的状态从「运行」状态设置为「堵塞」状态，然后把 CPU 切换给其他线程运行；

  * 接着，当锁被释放时，之前「堵塞」状态的线程会变为「就绪」状态，然后内核会在合适的时间，把 CPU 切换给该线程运行。

  * 上下切换的耗时有大佬统计过，大概在几十纳秒到几微秒之间，如果你锁住的代码执行时间比较短，那可能上下文切换的时间都比你锁住的代码执行时间还要长。所以，**如果你能确定被锁住的代码执行时间很短，就不应该用互斥锁，而应该选用自旋锁，否则使用互斥锁。**
* 自旋锁是通过 CPU 提供的 `CAS` 函数（*Compare And Swap*），在「用户态」完成加锁和解锁操作，不会主动产生线程上下文切换，所以相比互斥锁来说，会快一些，开销也小一些。



#### 读写锁

> c++17 有提供读写锁，shared_mutex类

​	由「读锁」和「写锁」两部分构成，如果只读取共享资源用「读锁」加锁，如果要修改共享资源则用「写锁」加锁。**读写锁适用于能明确区分读操作和写操作的场景**。**读写锁在读多写少的场景，能发挥出优势**。

读写锁的工作原理是：

* 当「写锁」没有被线程持有时，多个线程能够并发地持有读锁，这大大提高了共享资源的访问效率，因为「读锁」是用于读取共享资源的场景，所以多个线程同时持有读锁也不会破坏共享资源的数据。
* 但是，一旦「写锁」被线程持有后，读线程的获取读锁的操作会被阻塞，而且其他写线程的获取写锁的操作也会被阻塞。

所以说，**写锁是独占锁**，因为任何时刻只能有一个线程持有写锁，类似互斥锁和自旋锁，而**读锁是共享锁**，因为读锁可以被多个线程同时持有。

互斥锁和自旋锁都是最基本的锁，读写锁可以根据场景来选择这两种锁其中的一个进行实现。



#### 手撕读写锁

* 类 readWriteLock 中定义了两个互斥锁 readMtx 和 writeMtx
* 当读写锁中的读锁被某个线程加上时，先加上读互斥锁，这样保证了其他线程不能再读了；接着，再加上写互斥锁，同时计数加上 1，这样保证了其他线程不能再写了。接着，把读互斥锁释放掉，因为要允许其他线程也能读这个共享变量。**也就是说，多次读时，只需要加一把写锁，表明其他线程暂时不能执行写操作。**
* 当读写锁中的读锁被某个线程释放时，也是加上了读互斥锁，这样保证多个线程同时释放读写锁中的读锁时没有问题。**当没有线程读操作时，释放写互斥锁。表明其他线程可以执行写操作了。**

```cpp
class readWriteLock {
private:
    std::mutex readMtx;
    std::mutex writeMtx;
    int readCnt; // 已加读锁个数
public:
    readWriteLock() : readCnt(0) {}
    void readLock()
    {
        readMtx.lock();
        if (++readCnt == 1) {
            writeMtx.lock();  // 存在线程读操作时，写加锁（只加一次）
        }
        readMtx.unlock();
    }
    void readUnlock()
    {
        readMtx.lock();
        if (--readCnt == 0) { // 没有线程读操作时，释放写锁
            writeMtx.unlock();
        }
        readMtx.unlock();
    }
    void writeLock()
    {
        writeMtx.lock();
    }
    void writeUnlock()
    {
        writeMtx.unlock();
    }
};
```



#### 乐观锁与悲观锁

* 前面提到的互斥锁、自旋锁、读写锁，都是属于悲观锁。
* 悲观锁做事比较悲观，它认为**多线程同时修改共享资源的概率比较高，于是很容易出现冲突，所以访问共享资源前，先要上锁**。
* 乐观锁做事比较乐观，它假定冲突的概率很低，它的工作方式是：**先修改完共享资源，再验证这段时间内有没有发生冲突，如果没有其他线程在修改资源，那么操作完成，如果发现有其他线程已经修改过这个资源，就放弃本次操作**。
* **乐观锁全程并没有加锁，所以它也叫无锁编程**。
* 乐观锁虽然去除了加锁解锁的操作，但是一旦发生冲突，重试的成本非常高，所以**只有在冲突概率非常低，且加锁成本非常高的场景时，才考虑使用乐观锁。**
* CAS可以看作是乐观锁



### 线程通信

​	多线程在运行过程中，各个线程都是随着OS的调度算法，占用CPU时间片来执行指令做事情，每个**线程的运行完全没有顺序可言**。但是在某些应用场景下，一个线程需要等待另外一个线程的运行结果，才能继续往下执行，这就需要涉及线程之间的同步通信机制。好比「操作 A 应在操作 B 之前执行」，「操作 C 必须在操作 A 和操作 B 都完成之后才能执行」等

#### **条件变量**

condition_variable

条件变量的使用是依赖于mutex的

```cpp
// wait操作需要传入一个unique_lock
void wait (unique_lock<mutex>& lck);
template <class Rep, class Period>
cv_status wait_for (unique_lock<mutex>& lck,
                    const chrono::duration<Rep,Period>& rel_time);
template <class Clock, class Duration>
cv_status wait_until (unique_lock<mutex>& lck,
                      const chrono::time_point<Clock,Duration>& abs_time);

void notify_one() noexcept;
void notify_all() noexcept;
```

> * `notify_one` 唤醒一个等待线程，如果有多个线程在等待，则会随机唤醒一个。因为只唤醒等待队列中的一个线程，不存在锁争用，所以能够立即获得锁
>* `notify_all` 唤醒所有等待线程。存在锁争用，只有一个线程能够获得锁。其他线程会一直尝试获得锁，而不会再次堵塞
> 
> notify_one通知一个堵塞在cv条件变量上的线程，notify_all通知所有，因此notify_all是更加耗性能的，但他更安全：比如有t1 t2 t3三个线程，如果t1 t2线程都阻塞了，线程t3执行完+1之后执行notify_one，如果唤醒的线程是t2，而t2不满足执行条件，线程t1的条件才是符合的。此时线程就都阻塞了。而使用notifyAll，会唤醒所有阻塞线程，只要有一个线程符合条件就可以继续执行，就不会出现这种情况了。因此一般notify_one不怎么用，因为很容易造成堵塞



#### 生产消费模型

[另一个比较好的生产者消费者模型(框架和这里的线程池类似)](https://subingwen.cn/cpp/condition/#1-2-%E7%94%9F%E4%BA%A7%E8%80%85%E5%92%8C%E6%B6%88%E8%B4%B9%E8%80%85%E6%A8%A1%E5%9E%8B)

​	线程间同步通信最典型的例子就是生产者-消费者模型，生产者线程生产出产品以后，会通知消费者线程去消费产品；如果消费者线程去消费产品，发现还没有产品生产出来，它需要通知生产者线程赶快生产产品，等生产者线程生产出产品以后，消费者线程才能继续往下执行。

​	C++11 线程库提供的条件变量 condition_variable ，就是 Linux 平台下的 Condition Variable 机制，用于解决线程间的同步通信问题，下面通过代码演示一个生产者-消费者线程模型，仔细分析代码：

> 注意，图中的状态名字有误导性，以下面我写的为准：
> 四个状态：等待、堵塞、就绪、运行。wait时，由运行状态变为堵塞状态。等待状态抢到锁时，进入运行状态。notify_all通知另一个线程由堵塞变为等待态

![image-20230311195827822](E:\MarkDown\picture\image-20230311195827822.png)



![image-20230411154014879](E:\MarkDown\picture\image-20230411154014879.png)

```cpp
#include <iostream>           // std::cout
#include <thread>             // std::thread
#include <mutex>              // std::mutex, std::unique_lock
#include <condition_variable> // std::condition_variable
#include <vector>

// 定义互斥锁(条件变量需要和互斥锁一起使用)
std::mutex mtx;
// 定义条件变量(用来做线程间的同步通信)，条件变量需要配合mutex来使用
std::condition_variable cv;
// 定义vector容器，作为生产者和消费者共享的容器
std::vector<int> vec;

// 生产者线程函数
void producer() {
	// 生产者每生产一个，就通知消费者消费一个
	for (int i = 1; i <= 10; ++i) {
		// 获取mtx互斥锁资源
		// 在结合条件变量的时候，一般不会用裸锁，也不用lock_guard，而是用unique_lock
		// 因为wait里面要传入一个锁，手动的释放锁，所以得用unique_lock
		// 而lock_guard是通过构造函数加锁，析构解锁，在这里没法使用
		std::unique_lock<std::mutex> lock(mtx);

		// 如果容器不为空，代表还有产品未消费，则堵塞，等待消费者线程消费完，再生产
		while (!vec.empty()) {  // while(vec.size() == 10) // 如果为10，则堵塞，消费完再生产
			// wait做了两件事：进入堵塞态，即线程被堵塞，等待条件变量；释放mtx锁
			// 这就让消费者线程有机会抢到锁去消费产品
             // wait就是个堵塞线程的操作
			cv.wait(lock);
		}
		// 容器空了，就开始生产
		vec.push_back(i); // 表示生产者生产的产品序号i
		std::cout << "producer生产产品:" << i << std::endl;

		/* 
		生产者线程生产完产品，通知 堵塞在cv条件变量 上的消费者线程，使其变为等待状态
		可以开始消费产品了
		*/
		cv.notify_all();

		// 出了作用域后，释放锁mtx
	}
}
// 消费者线程函数
void consumer() {
	// 消费者每消费一个，就通知生产者生产一个
	for (int i = 1; i <= 10; ++i) {
		// 获取mtx互斥锁资源
		// 若是生产者线程
		std::unique_lock<std::mutex> lock(mtx);

		// 如果容器为空，代表还有没有产品可消费，等待生产者生产，再消费
		while (vec.empty()) {
			// 判断容器为空，进入堵塞状态，释放mtx锁，
			// 让生产者线程抢到锁能够去生产产品
			cv.wait(lock);
		}
		int data = vec.back(); // 表示消费者消费的产品序号i
		vec.pop_back();
		std::cout << "consumer消费产品:" << data << std::endl;

		/*
		消费者消费完产品，通知堵塞在cv条件变量上的生产者线程，
		*/
		cv.notify_all();

		// 出了作用域后，释放锁释放锁mtx
	}
}
int main()
{
	// 创建生产者和消费者线程
	std::thread t1(producer);
	std::thread t2(consumer);

	// main主线程等待所有子线程执行完
	t1.join();
	t2.join();

	return 0;
}
```

若是消费者线程先获取到锁，但发现容器为空，没有产品，就会wait进入堵塞状态并释放锁，此时生产者线程获取到锁，生产完产品后notify_all，唤醒在条件变量上wait的消费者线程，使其变为等待状态。等生产者线程出了作用域后，自动释放锁。

此时若是消费者线程先抢到锁，从等待状态变为**就绪**状态，等待分配到时间片后就开始运行

若又是生产者线程先抢到锁，则while中发现容器不为空，就wait，让生产者先消费，生产者线程进入堵塞状态并释放锁，之后消费者线程就能抢到锁，进入就绪状态了。一旦消费者消费了一个，notify_all通知堵塞在条件变量上的生产者线程，使之变为等待状态。

之后若是生产者抢到了锁，则生产者进入就绪状态，继续生产；若消费者抢到了锁，则while发现容器为空，进入堵塞状态，让生产者先生产。之后循环....

> 上面实现的是每生产一个，就消费一个。
>
> 若是想实现**先生产，后消费**，就将while中的条件改为vec.size() == 10，则就能实现先生产再消费
>
> 在这种情况下，若是生产者生产了一个，释放锁后：
>
> 若又是生产者线程先抢到锁，则while中发现容器没满十个，就继续生产，若一直能抢到锁，则直到产满十个，进入wait状态，使得生产者进入堵塞状态并释放锁，之后消费者就进行消费了
>
> 若是中途消费者先抢到了锁，就判断容器是否为空，为空就wait，不为空就消费，这就实现了先生产再消费（注意，不是先生产十个，然后消费十个，再生产十个这样，别搞混了）

**代码运行结果如下**，可以看到，生产者和消费者线程交替生产产品和消费产品，两个线程之间进行了完美的通信协调运行。

```
producer生产产品:1
consumer消费产品:1
producer生产产品:2
consumer消费产品:2
producer生产产品:3
consumer消费产品:3
producer生产产品:4
consumer消费产品:4
producer生产产品:5
consumer消费产品:5
producer生产产品:6
consumer消费产品:6
producer生产产品:7
consumer消费产品:7
producer生产产品:8
consumer消费产品:8
producer生产产品:9
consumer消费产品:9
producer生产产品:10
consumer消费产品:10
```



#### **信号量**

c++20从语言上提供了semaphore。更低的版本一般用条件变量来实现信号量

semaphore的控制没有条件变量那么精细，只能实现先生产再消费。所以如果只是想实现两个线程操作一前一后的顺序，那用信号量就行，先执行的线程负责post，后执行的线程wait

`semaphore sem(0)`即一开始的资源数是0

`sem.post()`使得资源计数+1

`sem.wait()`，使得资源-1

![image-20230311210850520](E:\MarkDown\picture\image-20230311210850520.png)

如果`semaphore sem(3)`即一开始的资源数是3，若2个线程`sem.wait()`，则都能执行。若四个线程wait，则只有三个线程能同时进去，当有一个线程执行完了，然后post，剩下那个线程才能进来

<img src="E:\MarkDown\picture\image-20230311211347279.png" alt="image-20230311211347279" style="zoom:60%;" />

**信号量的实现**

在C++11中，通过互斥锁和条件变量实现 semaphore

```cpp
#include <condition_variable>
#include <mutex>
// 实现一个信号量类
class Semaphore {
public:
	Semaphore(int count = 0) : resLimit_(count) {}
	// 获取一个信号量资源
	void wait() {
		std::unique_lock<std::mutex> lock(mtx_);
		// 等待信号量有资源
		cond_.wait(lock, [&]()->bool { return resLimit_ > 0; });
		resLimit_--;
	}
	// 增加一个信号量资源
	void post() {
		std::unique_lock<std::mutex> lock(mtx_);
		resLimit_++;
		cond_.notify_all();
	}
private:
	int resLimit_;
	std::mutex mtx_;
	std::condition_variable cond_;
};

// 使用
#include <iostream>
#include <thread>
#include <vector>
std::string FormatTimeNow(const char* format) {
    auto now = std::chrono::system_clock::now();
    std::time_t now_c = std::chrono::system_clock::to_time_t(now);
    std::tm* now_tm = std::localtime(&now_c);

    char buf[20];
    std::strftime(buf, sizeof(buf), format, now_tm);
    return std::string(buf);
}

Semaphore g_semaphore(4);
std::mutex g_io_mtx;

void DoWork() {
    g_semaphore.wait();

    std::thread::id thread_id = std::this_thread::get_id();
    std::string now = FormatTimeNow("%H:%M:%S");
    {
        std::lock_guard<std::mutex> lock(g_io_mtx);
        std::cout << "Thread " << thread_id << ": wait succeeded"
                  << " (" << now << ")" << std::endl;
    }

    std::this_thread::sleep_for(std::chrono::seconds(1));

    g_semaphore.post();
}

int main() {
    int threadNum = 4;
    std::vector<std::thread> v;
    v.reserve(threadNum);
    for (std::size_t i = 0; i < threadNum; ++i) {
        v.emplace_back(&DoWork);
    }
    for (std::thread& t : v) {
        t.join();
    }
    return 0;
}
```



##### **c++20中的信号量**

信号量被定义为了两个类：

* counting_semaphore 实现非负资源计数的信号量 
* binary_semaphore 仅拥有二个状态的信号量（通过counting_semaphore实现）

```cpp
// 源码
// std::counting_semaphore
namespace std {
  template<ptrdiff_t LeastMaxValue = /* 实现定义 */>
  class counting_semaphore {
  public:
    static constexpr ptrdiff_t max() noexcept;
 
    constexpr explicit counting_semaphore(ptrdiff_t desired);
    ~counting_semaphore();
 
    counting_semaphore(const counting_semaphore&) = delete;
    counting_semaphore& operator=(const counting_semaphore&) = delete;
 
    void release(ptrdiff_t update = 1);  // 相当于V
    void acquire();  // 相当于P
    bool try_acquire() noexcept;
    template<class Rep, class Period>
      bool try_acquire_for(const chrono::duration<Rep, Period>& rel_time);
    template<class Clock, class Duration>
      bool try_acquire_until(const chrono::time_point<Clock, Duration>& abs_time);
 
  private:
    ptrdiff_t counter;          // 仅用于阐释
  };
}
// std::binary_semaphore
namespace std {
  template<ptrdiff_t LeastMaxValue = /* 实现定义 */>
    class counting_semaphore;
	using binary_semaphore = counting_semaphore<1>;
}
```

**示例：使用信号量循环打印 ABC**

```cpp
#include <semaphore>
#include <iostream>
#include <thread>
#include <semaphore>
using namespace std;

counting_semaphore sema(1);
counting_semaphore semb(0);
counting_semaphore semc(0);


void pthread_fun1() //线程函数 1 打印 a
{
    int i = 0;
    for (; i < 10; ++i)
    {
        sema.acquire();
        cout << "A" << endl;
        std::this_thread::sleep_for(std::chrono::milliseconds(200));
        semb.release();
    }
}
void pthread_fun2() //线程函数 2 打印 l
{
    int i = 0;
    for (; i < 10; ++i)
    {
        semb.acquire();
        cout << "B" << endl;
        std::this_thread::sleep_for(std::chrono::milliseconds(200));
        semc.release();
    }
}
void pthread_fun3() //线程函数 3 打印 i
{
    int i = 0;
    for (; i < 10; ++i)
    {
        semc.acquire();
        cout << "C" << endl;
        std::this_thread::sleep_for(std::chrono::milliseconds(200));
        sema.release();
    }
}
int main()
{
    thread s1(pthread_fun1);
    thread s2(pthread_fun2);
    thread s3(pthread_fun3);
    s1.join();
    s2.join();
    s3.join();
    system("pause");
    return 0;
}
```



##### 信号量与mutex的异同

> 信号量与mutex的异同？
>
> 信号量是实现线程通信的，mutex是实现线程互斥的
>
> 信号量可以看作资源计数没有限制的Mutex互斥锁，`semaphore sem(10)`则一开始的资源数是10，`semaphore sem(1)`则一开始资源数为1
>
> * mutex互斥锁的资源计数只能是0或1
>
>   ```cpp
>   mutex.lock();  // 锁的资源计数 1 -> 0
>   ....
>   mutex.unlock();  // 锁的资源计数 0 -> 1
>
> * 而二元信号量`semaphore sem(1)`，资源计数为0 1，就可以完成和mutex同样的线程互斥操作。
>
> 区别点：
> 	**mutex只能是哪个线程获取锁，就由哪个线程释放锁**，lock和unlock只能在一个线程中调用。比如3个线程在等待，线程1进去了，只有等线程1执行完了，它释放锁，其他线程才有机会执行
> 	而**sem.wait()和sem.post可以处在不同的线程中调用**。比如3个线程在wait，线程1进去了，还没执行完呢，线程2给post了，这时候就能把线程2或者3的wait放进去了

#### PV操作

对于信号量，P就是信号量的wait，V就是post

对于条件变量，P就是wait，V就是notify_all，但注意notify仅能将另一个线程从等待状态变为阻塞状态，只有那个线程抢到锁才能进入就绪状态

#### 哲学家就餐问题

#### 读者—写者问题



## 参数设置

程序中的一些参数：

* 最大任务数量：1024
* 最大线程数量：100
* 线程最大等待时间：10s，在cached模式下，等待时间大于这个值就会回收线程
* 线程池类中，还有原子类型的线程池中线程的总数量、空闲线程的数量、任务的数量

> 使用的时候需要设置线程池为fixed模式或cached模式，并设置初始线程数量，默认是和cpu核心数相同:`int num = thread::hardware_concurrency();`可以将初始线程数量设置为cpu数量。concurrency为并行

CPU密集型和IO密集型的区别。

(1)、**CPU密集型**

​	**CPU密集型也叫计算密集型，指的是系统的硬盘、内存性能相对CPU要好很多**，此时，系统运作大部分的状况是CPU Loading 100%，CPU要读/写 I/O (硬盘/内存)，I/O在很短的时间就可以完成，而CPU还有许多运算要处理，CPU Loading 很高。

​	在多重程序系统中，大部分时间用来做计算、逻辑判断等CPU动作的程序称之CPU bound。CPU bound的程序一般而言CPU占用率相当高。这可能是因为任务本身不太需要访问I/O设备，也可能是因为程序是多线程实现因此屏蔽掉了等待I/O的时间。

(2)、**IO密集型**

​	**IO密集型指的是系统的CPU性能相对硬盘、内存要好很多**，此时，系统运作，大部分的状况是CPU在等I/O (硬盘/内存) 的读/写操作，此时CPU Loading并不高。

I/O bound的程序一般在达到性能极限时，CPU占用率仍然较低。这可能是因为任务本身需要大量I/O操作，而pipeline做得不是很好，没有充分利用处理器能力。

> **CPU密集型**：主要执行计算任务，CPU利用率高。虽然CPU密集型任务可以并行执行，但并行任务越多，花在任务切换上的时间越多，CPU效率越低。核心线程数 = CPU核数 + 1
>
> **IO密集型**：主要执行IO操作，由于IO操作时间较长，导致CPU利用率不高，CPU常处于空闲状态。corePoolSize = CPU核数 \* 2
>
> **混合型任务**：任务既要执行计算又要执行IO。相对来说IO操作的执行时间较长，CPU利用率也不是很高。例如WEB服务器的http请求，一次请求包括DB操作、缓存操作等多种操作。计算公式：最佳线程数=（线程等待时间/线程cpu时间+1）*cpu核数

## 亮点

* 增加了线程数量动态增长的模式；可以调整任务优先级；
* 通过future异步获取任务结果
* 双条件变量实现任务队列的安全，实现更精细的操作
* 使用c++11提供的多线程支持，兼容windows和linux



### std::thread替代pthread

> 为什么使用std::thread？

[std::thread](https://subingwen.cn/cpp/thread/)

**区别**

pthread是“粗犷、直接、暴力”的类UNIX[ˈjunɪks]平台上的线程表示方式

c++的thread类在语言级别上提供了线程支持，优势是跨平台且更精细。在不同操作系统上，依赖于平台本身的线程库，如在linux下底层调用还是pthread。

std::thread

优点：

* 构造比较方便，可以直接传递一个函数和这个函数的参数列表给这个线程。甚至可以传递一个类成员函数，此时参数列表的第二个参数（第一个参数是被传递的成员函数）会被作为该类成员函数所作用的实例。而pthread_create只接受`void *f(void *)`这样的函数签名。如果你想调用现成的函数，你得包装一下。并且其参数的传递需要定义为一个结构体，再转换成void*类型传递进去。

* 简单，易用，比如配合lambda表达式创建线程、可以直接join和detach（pthread需要填入线程ID）、配合mutex的std::unique_lock和std::lock_guard等
* 跨平台，pthread只能用在POSIX系统上（其他系统有其独立的thread实现）
* 提供了更多高级功能，比如future
* 更加C++（跟匿名函数，std::bind，RAII等C++特性更好的集成）

缺点：

* 没有读写锁RWlock。有一个类似的shared_mutex，不过它属于C++14,你的编译器很有可能不支持。
* 操作线程和Mutex等的API较少。毕竟为了跨平台，只能选取各原生实现的子集。如果你需要设置某些属性，需要通过API调用返回原生平台上的对应对象，再对返回的对象进行操作。

## 任务优先级

​	对于调整任务优先级，这里定义了两个空结构体a和b，在提交任务的时候，通过模板将结构体传入函数中，然后用 `std::is_same` 判断输入的元素类型和我们需要的是否相同。比如如果传入的和a相同，则std::is_same<T, a>::value == true，就将任务插入到任务队列deque的最前面。正常任务就是插入到最后面，先来先服务

> 这里这个例子(https://github.com/CodingHanYa/workspace)是使用了std::enable_if来使用不同的submit的偏特化版本，true则执行偏特化分支。我们这里没采用这种方法是因为我们需要保留这个返回值，实现起来比较麻烦

​	在这里我们不能保证`task A`一定会被先执行，因为当我们提交`task A`的时候，`task B`可能已经在执行中了。`urgent`标签可以让任务被插入到队列头部，但无法改变已经在执行的任务。

```cpp
struct normal   {};  // normal task (for type inference)
struct urgent   {};  // urgent task (for type inference)

template<typename T = normal, typename Func, typename... Args> 
    // Func&&引用折叠，可以接收左值和右值引用
    // 配合auto写成尾置返回类型
    // 返回值为future<>类型，而future中的类型需要decltype进行推导
	auto submitTask(Func&& func, Args&&... args) 
        -> std::future<decltype(func(args...))>
    {  
        bool isNorm;
        if (std::is_same<T, normal>::value) isNorm = true;
        else isNorm = false;
}

int main () {
    std::future<int> result = pool.submitTask(sum1, 1, 2);
    std::future<int> result1 = pool.submitTask<normal>(sum1, 1, 2);
    std::future<int> result5 = pool.submitTask<urgent>(sum1, 2, 2);
}
```





## 编译动态库

> linux下.a是静态库，.so是动态库

静态库

* 优点：

  * 静态库被打包到应用程序中加载速度快

  * 发布程序无需提供静态库，移植方便

* 缺点：
  * 相同的库文件数据可能在内存中被加载多份，消耗系统资源，浪费内存
  * 库文件更新需要重新编译项目文件，生成新的可执行程序，浪费时间。

动态库

* 优点：
  * 可实现不同进程间的资源共享
  * 动态库升级简单，只需要替换库文件，无需重新编译应用程序
  * 程序猿可以控制何时加载动态库，不调用库函数动态库不会被加载

* 缺点：
  * 加载速度比静态库慢，以现在计算机的性能可以忽略
  * 发布程序需要提供依赖的动态库

### 静态库

​	对于静态库的编译，需要先将源文件编译为.o文件，再执行` ar -rcs libxxx.a a.o b.o`，其中库名一般以.a为扩展名，以lib开头。-rcs是ar的参数

```shell
# 编译的时候指定库信息
-L: 指定库所在的目录(相对或者绝对路径)
-l: 指定库的名字, 掐头(lib)去尾(.a) ==> xxx
# -L -l, 参数和参数值之间可以有空格, 也可以没有  -L./ -lcalc
gcc main.c -o app -L ./ -l xxx
```



### 动态库的编译

libxxx.so

将threadpool.cpp文件编译为动态库libtdpool.so

```shell
g++ -fPIC -shared threadpool.cpp -o libtdpool.so -std=c++17
```

* -fPIC：表示编译为位置独立的代码，不用此选项的话，编译后的代码是位置相关的，所以动态载入时是通过代码拷贝的方式来满足不同进程的需要，而不能达到真正代码段共享的目的。
* -shared：指明编译成动态库。

通常系统在编译时会在./usr/lib和/usr/local/lib这两个文件夹下找.a(静态库) .so(动态库)文件，在/usr/include和/usr/local/include文件夹下找.h文件。当然，这个.h文件也可以放在项目下，反正保证`#include "xx.h"能找到就行`

因此我们把.so库放到了/usr/local/lib文件夹下，把threadpool.h放到了/usr/local/include/文件夹下

### 使用

想要链接libtdpool.so，而这个名字是lib-自己取的名.so，这里取的名是tdpool，因此链接的话是-ltdpool

这里还需要链接linux本地的pthread线程库

```shell
g++ test.cpp -std=c++17 -ltdpool -lpthread

# 运行
./a.out 
```

而系统在运行程序时，会在/etc/ld.so.conf.d/下的.conf即配置文件里找。因此我们创建mylib.conf，在里面设置下我们自己的静态库的路径，即写上/usr/local/lib这句话。保存后执行ldconfig刷新下配置文件，就可以通过./a.out执行了

生成a.out文件

## 杂

> 线程池工作线程处理完一个任务后的状态

如果任务队列为空，如果是cached模式，等待60s后会自动销毁；如果是fixed模式，这个线程就回到堵塞等待的状态，等待任务队列有元素后notify他

如果任务队列不为空，就处于竞争状态，获得锁的处理下个任务

### packaged_task

> 为什么使用package_task而不是async
>
> reference：https://blog.csdn.net/weiwei9363/article/details/106418146
>
> ​	`std::packaged_task` 本身和线程没啥关系，它只是一个关联了 `std::future` 的仿函数。std:packaged_task 的使用稍微麻烦一些，需要显式的调用或者传递给std::thread进行异步调用，但其具有更加灵活的控制调用方式，并且可以选择什么时间开始任务，而 std::async 则是一旦调用立马开始执行，并且直接调用 std::async()中临时变量析构的导致阻塞的坑，std::packaged_task 没有。



​	类似于`funciton`, `packaged_task`可以绑定一个可调用对象, 并执行，但是它的返回类型是`void`，获取它的返回值需要先使用get_future()获取到`future`类型的返回值，再通过future的get()函数得到最后的结果

​	这个类模板传入函数的返回值和形参类型，然后将这个函数及其任意数量的参数包装为一个可调用对象

```cpp
int main() {
    // 如何给它传入固定参数, 而不必在调用时指定
    std::packaged_task<int(int)> t(factorial);  // 传入factorial函数
    std::packaged_task<int()> t(std::bind(factorial, 6));  // 并绑定一个参数

    // do something else

    t(); // in a different context， always return void
    int x = t.get_future().get();
    std::cout << x << std::endl;
    return 0;
}
```



使用packaged_task进行包装，通过bind绑定形参，其中形参的传入使用std::forward完美转发。

[packaged_task](https://www.apiref.com/cpp-zh/cpp/thread/packaged_task.html)



### **std::future**

​	thread对象是C++11中提供异步创建多线程的工具。但是我们想要从线程中返回异步任务结果，一般需要依靠**全局变量**；从安全角度看，有些不妥；为此C++11提供了std::future[类模板](https://so.csdn.net/so/search?q=类模板&spm=1001.2101.3001.7020)，future对象提供访问异步操作结果的机制，很轻松解决从异步任务中返回结果。

相当于我们自己实现的Result + Any。通过`get()`获取结果

### decltype与std::result_of

（类型推断为什么使用decltype

对于我们线程池提交任务的接口来说，这两个是完全可以等价的。但decltype功能更强大：

**decltype**

​	decltype功能更强大。有时需要从表达式的类型推断出要定义的变量的类型，但是不想用该表达式的值初始化该变量，于是就可以使用decltype关键字，其作用是选择并返回操作数的数据类型，decltype 的推导过程是在**编译期完成**的，并且不会真正计算表达式的值。

```cpp
decltype (f()) sum = x;  // sum的类型
```

decltype(exp) 的推导规则：

* exp 是标识符、类访问表达式，decltype(exp) 和 exp 的类型一致。
* exp 是函数调用，decltype(exp) 和返回值的类型一致。
* 其他情况，若 exp 是一个左值，则 decltype(exp) 是 exp 类型的左值引 用，否则和exp 类型一致。

**std::result_of**

> 头文件：<type_traits>
>
> 在gcc 4.5上，result_of是根据decltype实现的
>
> c++17中更名为invoke_result
>
> ```cpp
> // 定义
> template< class >
> class result_of;
> // F为函数类型 ArgTypes为函数可变参数类型
> template< class F, class... ArgTypes >
> class result_of<F(ArgTypes...)>;
> 
> // 使用
> int fun(int x) {
>  return x + 1;
> }
> std::result_of<fun(int)>::type d = 10;    // d的类型是fun返回类型int
> ```
>
> 

如果您需要的不是函数调用之类的类型，则std::result_of就不适用。 decltype()可以为您提供任何表达式的类型。

```cpp
template <typename F, typename Arg>
typename std::result_of<F(Arg)>::type
invoke(F f, Arg a)
{
    return f(a);
}


template <typename F, typename Arg>
auto invoke(F f, Arg a) -> decltype(f(a)) //uses the f parameter
{
    return f(a);
}
```



## 实现



> 第一版实现

**Any类型：**
作用：作为run函数的返回值，接收任意类型的数据
技术点：使用了继承和模板，涉及到指针的都为unique_ptr
实现：
Any类中包含一个基类和一个模板类类型的派生类。其中基类仅用于多态用途；派生类中保存模板类型的数据
构造时将任意类型的数据包在派生类中，用基类的指针指向。
想要提取数据时，将这个基类指针转换为派生类指针，取出数据。
这样Any类中只需要保存一个基类的指针，就可以指向任意类型的数据
（这里基类的虚构函数为虚析构，来保证delete基类指针时运行正确的析构函数版本）
提问：
为什么不直接将返回结果设为模板呢？我们这里的run是虚函数，虚函数是不能和模板写在一起的
因为在编译的时候，对于虚函数，会产生虚函数表，记录这个函数的地址。而若这个函数是个函数模板，则在运行的时候才会实例化，根本没有地址。因此run的返回值不能用模板来表示。
进阶：
可以用c++17中的Any类代替

**Result类型**
作用：
作为submitTask的返回值
实现：
构造时绑定指向task的指针
类中存放Any对象来存储任务的返回值
提供了两个接口，一个用于任务将Any类型的返回值放到Result对象中；一个用于用户调用，获得这个Any
使用Semaphore类实现线程通信（主线程中的Result对象通过get来获取任务线程的返回值，因此需要与任务线程进行线程通信，即线程任务得到返回值后再给Result
进阶：
使用c++11中的future类模板来代替Any和Result

**Task类型**
作用：
任务抽象基类
用户可以自定义任意任务类型，从 Task 继承，重写 run 方法，实现自定义任务处理
实现：
存放一个Result类型的指针
一个虚函数run作为我们要执行的任务

**Thread线程类型**
实现：
使用std::function可调用对象的包装器类型的func_ 作为线程的函数
定义start函数执行此线程
构造时放入ThreadFunc类型的func_

**ThreadPool线程池类型**
接口：
设置线程池模式

start：
开启线程池时会创建若干个线程对象，这里将threadFunc函数绑定到当前线程池上，并将其变为指向Thread类型的智能指针？再将这个指针放到线程列表

***************************************************************************

threadFunc：
在线程池中获取并执行任务

***************************************************************************

Result submitTask(std::shared_ptr<Task> sp);
用于用户提交任务，用户调用时传入task派生类，提交任务操作将其放入任务队列中，并返回Result

数据：
queue类型的任务队列，其中的Task指针用shared_ptr保存来延长生命周期
unordered_map类型的线程列表（使用map而不是vector是便于根据线程id查到对应线程
atomic_uint类型的任务数量（线程池中任务数量的增加和减少也要保证是线程安全的，直接使用轻量的原子类型
锁和条件变量，实现任务队列的线程安全，这里实现了个生产者——消费者模型，保证线程池中有任务时就执行

**Semaphore类**
使用条件变量、锁实现
注意，对于linux下的程序，由于锁和条件变量不会自动析构，会引起死锁，因此这里使用了一个atomic_bool类型的状态位，析构时设置一下状态位，在post和wait中检测状态位，为1时返回，就能避免死锁
进阶：
在c++20中提供了信号量semaphore



> c++11实现

如何能让线程池提交任务更加方便

1. 我们希望直接传入函数和参数，而不是第一版那种定义一个类继承Task基类，通过类的构造函数传参，在类中定义任务函数
   pool.submitTask(sum1, 10, 20);
   pool.submitTask(sum2, 1 ,2, 3);
   submitTask:可变参模板编程
2. 我们自己造了一个Result以及相关的Any类型来接收数据，代码挺多
   2.1.用packaged_task代替function
   packaged_task与std::function很像，也是一个函数对象，可以很方便的获取线程的返回值
   2.2.使用future来代替Result节省线程池代码

第一版程序提交任务，需要自定义类，



删除了Result、Any、Semaphore(用于Result类线程通信)、Task类，重写submitTask函数

可变参模板编程：
通过Variadic Templates(c++11)接收任意数量和类型的参数



如果有任务的话，是需要将task放到任务队列的，而我们的任务队列存储的形式为
using Task = std::function<void()>;
std::queue< Task> taskQue_;  // 任务队列
即 function<void()> 的返回类型为void的函数对象，因此在放入任务的时候传入的是返回类型为void的、函数体中调用task的lambda表达式

```cpp
auto submitTask(Func&& func, Args&&... args) 
        -> std::future<decltype(func(args...))> 
{
        using RType = decltype(func(args...));
        auto task = std::make_shared<std::packaged_task<RType()>>(std::bind(std::forward<Func>(func), std::forward<Args>(args)...));
        std::future<RType> result = task->get_future();

        std::unique_lock<std::mutex> lock(taskQueMtx_);

        if (!notFull_.wait_for(lock, std::chrono::seconds(1), [&]()->bool {return taskQue_.size() < taskQueMaxThreshHold_; })) {
            // 等待1s，条件仍不满足
            std::cerr << "task queue is full, submit task fail." << std::endl;
            // 若任务提交失败，则返回一个空值
            auto task = std::make_shared<std::packaged_task<RType()>>(
                []()->RType { return RType(); }
                );
            (*task)();
            return task->get_future();
        }

        // 有空余，将任务放入任务队列
        // 任务队列中的类型我们写成了如下的形式，是一个没有返回值的
        // using Task = std::function<void()>;
        // 我们通过写成无返回值的lambda表达式的形式调用task来实现
        taskQue_.emplace([task]() {
            // 执行下面的任务
            (*task)();  // task解引用后就是packaged_task的函数对象
        }
        );
        taskSize_++;

        // 任务队列不空，通知notEmpty_
        notEmpty_.notify_all();

        // cached模式需要根据任务数量和空闲线程的数量，判断是否需要创建新的线程出来
        // 且需要当前线程总数小于我们设定的最大线程数
        if (poolMode_ == PoolMode::MODE_CACHED && taskSize_ > idleThreadSize_ && curThreadSize_ < threadSizeThreshHold_) {
            std::cout << "create new thread" << std::endl;
            // 创建新线程
            auto ptr = std::make_unique<Thread>(std::bind(&ThreadPool::threadFunc, this, std::placeholders::_1));  // c++14
            int threadId = ptr->getId();
            threads_.emplace(threadId, std::move(ptr));
            // 启动线程
            threads_[threadId]->start();
            // 修改线程个数相关的变量
            curThreadSize_++;
            idleThreadSize_++;
        }
        return result;
    }
```



## 项目设计

> 为什么线程用map存？

因为cached模式需要对空闲时间超过60s的线程进行回收

**设计：**

​	线程池中使用了两个容器，unordered_map负责缓存线程，queue负责缓存任务。对于线程map，其大小需要是可变的；对于任务队列，需要一个 task max threshold = 1024 来限制任务的数量

​	线程池的线程队列中有很多线程来操纵任务队列，即消费者，来消费这个任务；用户通过线程池对象提交任务，相当于生产者。因此需要对**任务队列**考虑线程安全问题，这里可以使用比较轻量化的atomic原子类型实现线程互斥。对于线程通信，使用mutex + condition variable来实现，看到队列满了就不放了。对于fixed模式的线程队列是事先创建好的，不用考虑线程安全问题；而cached模式的线程队列需要考虑线程安全问题，因为空闲了60s需要回收，要考虑线程的删除
​	这里条件变量定义了两个，为notFull和notEmpty，notFull则生产，用户线程可以向任务队列提交任务，notEmpty则消费，则线程队列从任务队列中取出任务

![image-20230311205220809](E:\MarkDown\picture\image-20230311205220809.png)

**使用：**

```cpp
ThreadPool pool;  // 定义一个线程池对象
pool.setMode(fixed(default)|cached);  // 设定模式，支持fixed和cached模式。不设定的话默认fixed
pool.start();  // 启动线程池，即创建一些线程，然后等待任务过来

// 给线程池提交任务
// result是返回的结果，比如这个任务执行了个加法，需要返回一个数字
Result result = pool.submitTask(concreatTask);

// 获取处理结果
// 用c++17中的any类型返回我们指定类型的结果
result.get().Cast<结果类型>()
```





### 线程池初期的功能测试

> 此阶段的线程池，对于线程执行任务函数，是没有返回值的
>
> 如对于一个网络程序，主线程是IO线程，负责新用户链接，产生一个套接字给子线程，每个子线程都是一个epoll，此时子线程只需要去做已连接的用户的读写事件即可，此时不需要获取线程执行任务的返回值

### 阶段二 有返回值的task

#### 问题1：怎么设计run函数的返回值，可以表示任意的类型？

> 有些场景，需要我们的线程执行任务提供返回值
>
> 如 多线程实现1 + ... + 10000，每个线程负责一部分；主线程负责给每个线程分配计算的区间，并等待每个线程算完后，合并最终结果
>
> 此时就需要给Task类的run函数设置一个返回结果。而这个返回结果，根据不同的需求可能是不同的类型。因此想到可以用模板。但注意，run是虚函数，虚函数是不能和模板写在一起的
>
> 因为在编译的时候，对于虚函数，会产生虚函数表，记录这个函数的地址。而若这个函数是个函数模板，则在运行的时候才会实例化，根本没有地址。因此run的返回值不能用模板来表示。

#### Any类型

对于问题1，可以通过Any类型实现。

c++17中提供了Any类，可以接收任意类型。通过这个Any类，可以实现继承任意类型的结果

![image-20230313145542430](E:\MarkDown\picture\image-20230313145542430.png)

总体思路：定义一个基类和一个模板类类型的派生类，派生类通过模板就可以保存任意类型的数据。Any类通过基类指针指向派生类，对数据进行操作

**Any类型的实现**

```cpp
// Any类型：可以接收任意数据的类型
// 将其作为函数返回值类型时，会看Any有没有一个合适的构造函数，来接收return返回的对象
class Any {
public:
	// 将任意类型的data包在派生类中，用基类指针指向
	template<typename T>
	Any(T data) : base_(std::make_unique<Derive<T>>(data)) {}

	// 定义一个方法，将Any对象存储的data_数据提取出来
	template<typename T>
	T cast_() {
		// 从base_指针中找到所指向的派生类对象，取出data_成员变量
		// 用智能指针提供的get方法取得裸指针，用 dynamic_cast 进行自动的类型转换至派生类指针
		Derive<T>* pd = dynamic_cast<Derive<T>*>(base_get());
		if (pd == nullptr) {
			// dynamic_cast 转换失败，比如人家是int，你以为是long，就cast_<long>来调用，结果人家是Derive<int>，就转换失败了
			throw "type is unmatch"
		}
		return pd->data_;
	}
	Any() = default;
	~Any() = default;
	// Any类中的成员变量是unique_ptr类型的，对于这个智能指针，禁止了拷贝构造和赋值，仅支持移动构造
	// 因此Any类中也是这样的。这就是默认实现，不写也无所谓
	Any(const Any&) = delete;
	Any& operator=(const Any&) = delete;
	Any(Any&&) = default;
	Any& operator=(Any&&) = default;
private:
	// 基类类型
	class Base {
	public:
		// 对于多态用途的基类，需要虚析构函数
		// 若不是虚析构，在delete一个指向派生类的基类指针的时候，可能仅将派生类对象的基类部分西沟了，因此其结果将是未定义的
		// 定义为虚析构，才能确保delete基类指针时运行正确的析构函数版本
		virtual ~Base() = default;
	};
	// 派生类类型
	template<typename T>
	class Derive : public Base {
	public:
		Derive(T data) : data_(data) {};
		T data_;
	};
private:
	// 定义一个基类的指针
	std::unique_ptr<Base> base_;
};
```



#### 问题2：如何设计submitTask函数的返回值？

> ​	子线程的执行可能很耗时，也可能马上就能执行完，而用户即主线程通过`Result res = pool.submitTask(std::make_shared<MyTask>());`想得到返回值的时候，若调用早了，任务没有执行完，则调用`res.get()`的时候，就应该把当前调用的这个线程阻塞住；若已经被执行完了，则get()应该直接得到返回的结果

对于问题2，需要先实现接收提交到线程池的task任务执行完成后的返回值类型Result，然后将task和result耦合在一起，使得submitTask函数中创建result时，将此result绑定在当前task上，而task在执行后也会将返回的结果存在task类中指向result的指针的成员函数中

其中涉及了线程的通信。提交任务、调用任务的返回值都是在用户的主线程里面做的，而线程的执行是在线程池的子线程中实现的。通过实现一个Semaphore信号量类实现不同线程间的通信（即保证线程的执行顺序

<img src="E:\MarkDown\picture\image-20230313155326452.png" alt="image-20230313155326452" style="zoom:70%;" />







### 阶段三 cached模式

> cached模式适合任务处理比较紧急，适用于小而快的任务；
>
> 而对于比较耗时的任务，则fixed模式更合适，因为若是不断有很多耗时的任务占着线程，会对系统的性能有很大的影响

​	阶段二中实现的线程池仅是fixed，即固定数量的线程。在阶段三中我们要实现cached即线程数量可动态增长的线程池

1、在min函数中，用户如何设置线程池的工作模式：setMode函数

2、在线程池的`submitTask`函数中，需要根据任务数量和空闲线程的数量，判断是否需要创建新的线程出来

3、在`threadFunc`函数中，在cached模式下，有可能已经创建了很多的线程，但是空闲时间超过60s，如何把多余的线程结束回收掉



### 阶段四 资源回收

​	可以发现，对于当前的程序，线程池对象在离开作用域后会析构，但线程池里的线程却都没有结束。线程池相关的资源如何回收？

threadpool.cpp

```cpp
#include"threadpool.h"

const int TASK_MAX_THRESHHOLD = 1024;
const int THREAD_MAX_THRESHHOLD = 100;
const int THREAD_MAX_IDLE_TIME = 10;  // 等待的时间，s
//////////////////////  Task方法实现
Task::Task(): result_(nullptr) {}
// 在task对应的result类进行构造的时候调用，将新创建的result绑定到当前的task上
// 即为task中指向Result的成员变量result_赋值，之后就可以通过这个指针，将task的结果存到Result对象中了
void Task::setResult(Result* res) {
	result_ = res;
}
void Task::exec() {
	// run，并将任务的返回值保存在Result类中
	if (result_ != nullptr) {
		result_->setVal(run());  // run在这里发生多态调用
	}
}

//////////////////////  线程池方法实现
ThreadPool::ThreadPool()
	: initThreadSize_(4)
	, taskSize_(0)
	, taskQueMaxThreshHold_(TASK_MAX_THRESHHOLD)
	, threadSizeThreshHold_(THREAD_MAX_THRESHHOLD)
	, poolMode_(PoolMode::MODE_FIXED)
	, isPoolRunning_(false)
	, curThreadSize_(0)
	, idleThreadSize_(0)
{}

ThreadPool::~ThreadPool() {
	isPoolRunning_ = false;
	// 等待线程池中所有的线程返回
	// 两种状态：阻塞 / 执行中
	// 这里就需要进行线程的通信
    notEmpty_.notify_all();
	std::unique_lock<std::mutex> lock(taskQueMtx_);
	exitCond_.wait(lock, [&]()->bool {return threads_.size() == 0; });
}

// 设置cached模式下线程阈值
void ThreadPool::setThreadSizeThreshHold(int threshhold) {
	if (checkRunningState()) return;
	if (poolMode_ == PoolMode::MODE_CACHED) {
		threadSizeThreshHold_ = threshhold;
	}
}
// 设置线程池工作模式
void ThreadPool::setMode(PoolMode mode) {
	// 如果线程池已经启动了，则不能设置工作模式了
	if (checkRunningState()) return;
	poolMode_ = mode;
}

// 检查线程池的运行状态
bool ThreadPool::checkRunningState() const {
	return isPoolRunning_;
}

// 任务相关
// 设置task任务队列上限阈值
void ThreadPool::setTaskQueMaxThreshHold(int threshhold) {
	// 如果线程池已经启动了，则不能设置了
	if (checkRunningState()) return;
	taskQueMaxThreshHold_ = threshhold;
}

// 开启线程池，并设置初始的线程数量
void ThreadPool::start(size_t initThreadSize) {
	// 设置线程池的启动状态
	isPoolRunning_ = true;

	// 设置初始的线程数量
	initThreadSize_ = initThreadSize;
	// 记录线程总数
	curThreadSize_ = initThreadSize;

	// 创建线程对象
	for (size_t i = 0; i < initThreadSize_; i++) {
		// 创建thread线程对象的时候，需要把线程函数给到thread类
		// 这样在Thread::start中才能启动这个线程函数
		// 通过构造函数，将threadFunc放进去
		// 这里我们使用bind。对于类的成员函数，前面要取个地址
		// 且需要绑定一个类对象才能使用，这里绑定了this即当前对象
		// 这里使用智能指针创建线程对象，让其能自动析构
		auto ptr = std::make_unique<Thread>(std::bind(&ThreadPool::threadFunc, this, std::placeholders::_1));  // c++14
		// 使用move将左值转换为对应的右值引用类型
		int threadId = ptr->getId();
		threads_.emplace(threadId, std::move(ptr));
		// unique_ptr是不允许拷贝构造的，仅支持一个智能指针指向它
		// 因此 emplace_back(ptr) 的操作会报错
		// unique_ptr虽然关闭了左值引用的拷贝和赋值，但支持右值引用的操作！
	}

	// 启动所有线程
	for (size_t i = 0; i < initThreadSize_; i++) {
		// 注意，这里threads_[i]是指针
		// 调用了线程类里的start函数创建并启动线程
		threads_[i]->start();
		idleThreadSize_++;
	}
}

// threadFunc负责在线程池中获取并执行任务
// 在线程池类中定义线程函数，由线程类执行
// 线程函数需要的那些锁和条件变量，都定义在线程池中
// 这里线程函数若是定义在Thread类中，则不方便访问ThreadPool里的那些私有的锁和条件变量
// 因此将线程函数定义在ThreadPool类中
void ThreadPool::threadFunc(int threadid) {
	auto lastTime = std::chrono::high_resolution_clock().now();

	// 所有任务必须执行完成，线程池才可以回收所有线程资源
	// 相当于while(true)。线程执行threadFunc后便一直在此函数中尝试获取任务
	while (isPoolRunning_){
		// 注意，我们仅需要在取任务的时候获取锁，取到任务后释放锁，再执行任务
		std::shared_ptr<Task> task;
		{
			// 获取锁
			std::unique_lock<std::mutex> lock(taskQueMtx_);

			std::cout << "tid:" << std::this_thread::get_id()
				<< "尝试获取任务!" << std::endl;

			// cached模式下，有可能已经创建了很多的线程，但是空闲时间超过60s
			// 对于超过初始线程数量initThreadSize_的线程，需要看情况进行回收
			while (taskQue_.size() == 0) {
				// 每一秒返回一次
				// while来区分是超时返回还是有任务待执行返回
				// 任务队列有任务，就跳过while去消费，没任务才等待任务
				if (poolMode_ == PoolMode::MODE_CACHED) {
					// wait_for函数的返回值cv_status有两个状态，超时和不超时
					if (std::cv_status::timeout == 
						notEmpty_.wait_for(lock, std::chrono::seconds(1))) {
						auto now = std::chrono::high_resolution_clock().now();
						auto dur = std::chrono::duration_cast<std::chrono::seconds>(now - lastTime);
						if (dur.count() >= THREAD_MAX_IDLE_TIME
							&& curThreadSize_ > initThreadSize_) {
							// 回收线程
							// 记录线程数量的相关变量的值
							idleThreadSize_--;
							curThreadSize_--;

							// 将线程对象从线程列表中删除 但没法将threadFunc对应到thread对象
							// threadid => thread对象 => 删除
							threads_.erase(threadid);
							std::cout << "threadid:" << std::this_thread::get_id() << " exit!" << std::endl;
							return;
						}
					}
				}
				else {
					notEmpty_.wait(lock);
				}
				// 判断一下是有任务才被唤醒的，还是因为线程池结束才唤醒的
				if (!isPoolRunning_) {
					// 将线程对象从线程列表中删除 但没法将threadFunc对应到thread对象
					// threadid => thread对象 => 删除
					threads_.erase(threadid);
					std::cout << "threadid:" << std::this_thread::get_id() << " exit!" << std::endl;
					// 通知下主线程的条件变量，否则会阻塞在主线程
					exitCond_.notify_all();
					return;
				}
			}
			idleThreadSize_--;

			std::cout << "tid:" << std::this_thread::get_id()
				<< "成功获取任务!" << std::endl;

			task = taskQue_.front(); taskQue_.pop();
			taskSize_--;

			// 为什么用了两个条件变量呢，这便于进行更精细的操作
			// 如果任务队列仍有任务，则通知其他wait在notEmpty_的线程执行任务
			if (taskQue_.size() > 0) {
				notEmpty_.notify_all();
			}
			
			// 通知 wait在notFull_上的生产者，可以继续提交任务
			notFull_.notify_all();
		}  // 取完任务，释放锁
		if (task != nullptr) {
			// 执行任务，并把任务的返回值setVal方法给到Result
			// task->run();
			// run是个需要重写的方法，我们不可能将增加的这部分功能写到run里面
			// 所以我们在Task类中增加了exec函数，在这个函数中执行run和新增加的功能
			task->exec();
		}
		idleThreadSize_++;
		lastTime = std::chrono::high_resolution_clock().now();
	}
	// 若是线程池结束时还有任务没执行完，则等其结束wait状态后，跳出while循环，在这里进行析构
	threads_.erase(threadid);
	std::cout << "threadid:" << std::this_thread::get_id() << " exit!" << std::endl;

}

// 给线程池提交任务
// 生产者：获取锁，while(满) {wait}，提交任务，notify_all
Result ThreadPool::submitTask(std::shared_ptr<Task> sp) {
	// 获取锁
	std::unique_lock<std::mutex> lock(taskQueMtx_);

	// 线程的通信 等待任务队列有空余
	// 没有空余才等待，因此需要等待notFull_
	// 这里使用了lambda表达式的隐式捕获的引用捕获，让编译器根据函数体中代码推断捕获列表
	//// notFull_.wait(lock, [&]()->bool {return taskQue_.size() < taskQueMaxThreshHold_; });
	// 与下面三行等价
	//while (taskQue_.size() == taskQueMaxThreshHold_) {
	//	notFull_.wait(lock);
	//}
	// 增加一个要求：用户提交任务，最长不能阻塞超过1s，否则判断提交任务失败，返回
	// wait()：一直等待到条件满足；wait_for()：等一段时间；wait_until()：等到一个时间点
	/*notFull_.wait_for(lock, std::chrono::seconds(1), [&]()->bool {return taskQue_.size() < taskQueMaxThreshHold_; });*/
	if (!notFull_.wait_for(lock, std::chrono::seconds(1), [&]()->bool {return taskQue_.size() < taskQueMaxThreshHold_; })) {
		// 等待1s，条件仍不满足
		std::cerr << "task queue is full, submit task fail." << std::endl;
		// 若任务提交失败，则
		return Result(sp, false);
	}

	// 有空余，将任务放入任务队列
	taskQue_.emplace(sp);
	taskSize_++;

	// 任务队列不空，通知notEmpty_
	notEmpty_.notify_all();

	// cached模式需要根据任务数量和空闲线程的数量，判断是否需要创建新的线程出来
	// 且需要当前线程总数小于我们设定的最大线程数
	if (poolMode_ == PoolMode::MODE_CACHED && taskSize_ > idleThreadSize_ && curThreadSize_ < threadSizeThreshHold_) {
		std::cout << "create new thread" << std::endl;
		// 创建新线程
		auto ptr = std::make_unique<Thread>(std::bind(&ThreadPool::threadFunc, this, std::placeholders::_1));  // c++14
		int threadId = ptr->getId();
		threads_.emplace(threadId, std::move(ptr));
		// 启动线程
		threads_[threadId]->start();
		// 修改线程个数相关的变量
		curThreadSize_++;
		idleThreadSize_++;
	}
	// 对于Result，可以通过task类里面的函数返回，也可以用Result类进行封装
	// return task->getResult();  // 不行！task对象被线程取出来用完后就析构了，再想使用这个task对象是不行的
	// return Result(task);  // 因此通过Result来维持task的生命周期，保证我们想要task返回值的时候task对象还在
	return Result(sp);
}


/////////////////////////////////// 线程方法实现
int Thread::generateId_ = 0;

Thread::Thread(ThreadFunc func)
	: func_(func)
	, threadId_(generateId_++)
{}

Thread::~Thread() {

}

int Thread::getId() const {
	return threadId_;
}

// 启动线程
void Thread::start() {
	// 创建线程
	// ThreadPool::start函数创建了thread，传入了func_
	// 因此创建线程的时候直接把func_放进去就行
	// 这里thread的构造函数通过完美转发将参数传递给线程函数
	
	std::thread t(func_, threadId_);
	// 注意，上面是将线程函数写到线程池类的写法
	// 若是将线程函数写到Thread类中，则应该写为
	// std::thread t(&Thread::threadFunc, &thread1);
	// thread1表示一个线程对象，相应的start函数也应该有形参：start(Thread& thread1)

	// 注意，这个线程对象t出了这个作用域就会自动销毁
	// 因此要设置为分离线程，使得此线程变为守护线程，驻留后台运行
	t.detach();
}



/////////////////////////////  Result的实现
Result::Result(std::shared_ptr<Task> task, bool isValid) 
	: task_(task), isValid_(isValid){
	// 顺便将result对象绑定到task上
	task_->setResult(this);
}

Any Result::get() {
	if (!isValid_) return "";  // 如果返回值无效，返回g个空
	sem_.wait();  // task任务如果没有执行完，则堵塞用户的线程
	return std::move(any_);

}

void Result::setVal(Any any) {
	// 存储task的返回值
	this->any_ = std::move(any);
	sem_.post();
}
```

threadpool.h

```cpp
#ifndef THREADPOOL_H
#define THREADPOOL_H
// 使用 #ifndef 而非 #pragma once ，因为后者需要编译器支持，在linux下不支持
#include<iostream>
#include<vector>
#include<queue>
#include<memory>  // 智能指针
#include<atomic>  // 原子类型，实现线程互斥
#include<mutex>  // 锁
#include<condition_variable>  // 条件变量，实现线程通信
#include<functional>
#include<thread>
#include<unordered_map>

// Any类型：可以接收任意数据的类型
// 将其作为函数返回值类型时，会看Any有没有一个合适的构造函数，来接收return返回的对象
class Any {
public:
	// 将任意类型的data包在派生类中，用基类指针指向
	template<typename T>
	Any(T data) : base_(std::make_unique<Derive<T>>(data)) {}

	// 定义一个方法，将Any对象存储的data_数据提取出来
	template<typename T>
	T cast_() {
		// 从base_指针中找到所指向的派生类对象，取出data_成员变量
		// 用智能指针提供的get方法取得裸指针，用 dynamic_cast 进行自动的类型转换至派生类指针
		Derive<T>* pd = dynamic_cast<Derive<T>*>(base_.get());
		if (pd == nullptr) {
			// dynamic_cast 转换失败，比如人家是int，你以为是long，就cast_<long>来调用，结果人家是Derive<int>，就转换失败了
			throw "type is unmatch";
		}
		return pd->data_;
	}
	Any() = default;
	~Any() = default;
	// Any类中的成员变量是unique_ptr类型的，对于这个智能指针，禁止了拷贝构造和赋值，仅支持移动构造
	// 因此Any类中也是这样的。这就是默认实现，不写也无所谓
	Any(const Any&) = delete;
	Any& operator=(const Any&) = delete;
	Any(Any&&) = default;
	Any& operator=(Any&&) = default;
private:
	// 基类类型
	class Base {
	public:
		// 对于多态用途的基类，需要虚析构函数
		// 若不是虚析构，在delete一个指向派生类的基类指针的时候，可能仅将派生类对象的基类部分西沟了，因此其结果将是未定义的
		// 定义为虚析构，才能确保delete基类指针时运行正确的析构函数版本
		virtual ~Base() = default;
	};
	// 派生类类型
	template<typename T>
	class Derive : public Base {
	public:
		Derive(T data) : data_(data) {};
		T data_;
	};
private:
	// 定义一个基类的指针
	std::unique_ptr<Base> base_;
};

// 实现一个信号量类，来实现Result类的线程通信
// 这个信号量默认的资源数为0
class Semaphore {
public:
	Semaphore(int count = 0) : resLimit_(count) {}
	// 获取一个信号量资源
	void wait() {
		std::unique_lock<std::mutex> lock(mtx_);
		// 等待信号量有资源
		cond_.wait(lock, [&]()->bool { return resLimit_ > 0; });
		resLimit_--;
	}
	// 增加一个信号量资源
	void post() {
		std::unique_lock<std::mutex> lock(mtx_);
		resLimit_++;
		cond_.notify_all();
	}
private:
	int resLimit_;
	std::mutex mtx_;
	std::condition_variable cond_;
};

class Task;  // Task对象的前置声明
// Result类：作为 submitTask 的返回值
// 实现接收提交到线程池的task任务执行完成后的返回值类型
// 主线程中的Result类通过get来获取任务线程的返回值，因此需要与任务线程进行线程通信
class Result {
public:
	Result(std::shared_ptr<Task> task, bool isValid = true);
	// 获取任务执行完的返回值，将task_ run()的返回值放到any_里
	void setVal(Any any);
	// 用户调用这个方法获取task的返回值
	Any get();

private:
	Any any_;  // 存储任务的返回值
	Semaphore sem_;  // 线程通信的信号量
	std::shared_ptr<Task> task_;  // 指向对应的需要获取返回值的task对象
	std::atomic_bool isValid_;  // 返回值是否有效
};


//////////////////////////////    任务抽象基类
class Task {
public:
	// 用户可以自定义任意任务类型，从 Task 继承，重写 run 方法，实现自定义任务处理
	Task();
	virtual Any run() = 0;
	void exec();
	void setResult(Result* res);
private:
	Result* result_;  // 这里用普通的指针就行，因为result的生命周期比task长
};


// 线程池支持的模式
// 这里使用了限定作用域的枚举类型
// 使用时必须显示的访问，PoolMode p = PoolMode::MODE_FIXED;
enum class PoolMode {
	MODE_FIXED,  // 固定数量的线程
	MODE_CACHED,  // 线程数量可动态增长
};


//////////////////////////////////   线程类型
class Thread {
public:
	// 线程函数对象类型，为function函数对象
	using ThreadFunc = std::function<void(int)>;

	Thread(ThreadFunc func);
	~Thread();
	void start();

	// 获取线程id
	int getId() const;
private:
	ThreadFunc func_;
	static int generateId_;  // 类的所有对象共享静态成员变量，通过它来得到变化的threadId_
	int threadId_;  // 保存线程ID
};


///////////////////////////////////   线程池类型
/*
example:
ThreadPool pool;
pool.start(4);

class MyTask : public Task
{
	public:
		void run() { // 线程代码... }
};

pool.submitTask(std::make_shared<MyTask>());
*/
class ThreadPool {
public:
	ThreadPool();
	~ThreadPool();
	// 禁止线程池的拷贝和复制
	ThreadPool(const ThreadPool&) = delete;
	ThreadPool& operator=(const ThreadPool&) = delete;

	// 设置线程池模式
	void setMode(PoolMode mode);

	// 开启线程池，并设置初始的线程数量，为cpu系统的核心数量
	void start(size_t initThreadSize = std::thread::hardware_concurrency());

	// 设置cached模式下线程阈值
	void setThreadSizeThreshHold(int threshhold);
	// 任务相关
	// 设置task任务队列上限阈值
	void setTaskQueMaxThreshHold(int threshhold);
	// 给线程池提交任务
	Result submitTask(std::shared_ptr<Task> sp);

private:
	// 定义线程函数
	void threadFunc(int threadid);

	// 检查线程池的运行状态
	bool checkRunningState() const;
private:
	

	// 线程相关
	// 线程列表。对于线程的创建，是在ThreadPool::start中new出来的，还需要delete
	// 因此直接使用智能指针。线程的话unique就行
	// std::vector<std::unique_ptr<Thread>> threads_;
	// 为了实现通过threadId_查询到对应的线程，这里最后使用了map
	std::unordered_map<int, std::unique_ptr<Thread>> threads_;

	size_t threadSizeThreshHold_;  // 线程数量的上限
	// 为什么新增一个变量而不是用threads_.size()呢，因为vector不是线程安全的
	std::atomic_int curThreadSize_;  // 记录当前线程池里面线程的总数量
	std::atomic_int idleThreadSize_;  // 记录空闲线程的数量
	int initThreadSize_;  // 初始的线程数量。size_t增强了可移植性，表示任何对象所能达到的最大长度
	
	// 需要使用基类的指针或引用才能实现多态
	// 而用户传入的通常会是临时的一个任务对象，出了submitTask语句后就析构了，用指针指向一个析构了的对象是没有意义的
	// 而我们是需要考虑来保持这个任务的生命周期的，当这个任务run执行以后在析构
	// 因此需要使用智能指针
	std::queue<std::shared_ptr<Task>> taskQue_;  // 任务队列
	std::atomic_uint taskSize_;  // 任务的数量。考虑到线程安全问题，使用轻量化的原子类型实现线程互斥
	size_t taskQueMaxThreshHold_;  // 任务队列数量的上限

	// 实现线程通信
	std::mutex taskQueMtx_;  // 保证任务队列的线程安全
	std::condition_variable notEmpty_;  // 任务队列不空
	std::condition_variable notFull_;  // 任务队列不满
	std::condition_variable exitCond_;  // 等待线程资源全部回收

	PoolMode poolMode_;  // 当前线程池的工作模式

	std::atomic_bool isPoolRunning_;  // 表示当前线程池的启动状态
	
};


#endif // !THREADPOOL_H

```

**test.cpp**

```cpp
#include"threadpool.h"
#include<chrono>

class MyTask : public Task
{
public:
	MyTask(int begin, int end)
		: begin_(begin)
		, end_(end)
	{}
	Any run() {
		std::cout << "tid:" << std::this_thread::get_id()
			<< "begin!" << std::endl;
		std::this_thread::sleep_for(std::chrono::seconds(5));
		int sum = 0;
		for (int i = begin_; i <= end_; i++)
			sum += i;
		std::cout << "tid:" << std::this_thread::get_id()
			<< "end!" << std::endl;
		return sum;
	}
private:
	int begin_;
	int end_;
};

// const int TASK_MAX_THRESHHOLD = 4;，任务列表设为了最大四个任务
// 此时线程池设置4个线程。每个任务执行5s，提交若干个任务后，会有一些任务提交失败（等待超过了1s）

int main() {
	{
		ThreadPool pool;
		// 用户自己设置线程池的工作模式
		pool.setMode(PoolMode::MODE_CACHED);
		// 启动线程池
		pool.start(2);
		// Master - Slave线程模型
		// Master线程用来分解任务，然后给各个Slave线程分配任务
		// 等待各个Slave线程执行完任务，返回结果
		// Master线程合并各个任务结果，输出
		Result res1 = pool.submitTask(std::make_shared<MyTask>(1, 100));
		Result res2 = pool.submitTask(std::make_shared<MyTask>(101, 200));
		Result res3 = pool.submitTask(std::make_shared<MyTask>(201, 300));
		int sum = res1.get().cast_<int>() + res2.get().cast_<int>() + res3.get().cast_<int>();
		std::cout << sum << std::endl;
		int sum2 = 0;
		for (int i = 1; i <= 300; i++) {
			sum2 += i;
		}
		std::cout << "answer:" << sum2 << std::endl;
	}
	getchar();
}
```

### 阶段五 解决死锁问题

> [死锁的四个条件](https://xiaolincoding.com/os/4_process/deadlock.html)
>
> * **互斥条件**；即多个线程不能同时访问同一个资源
> * **持有并等待条件**；即一个线程已经持有了资源1，又需要获取资源2，但资源2被另一个线程持有，则线程就进入到了持有资源1且处于等待的状态
> * **不可剥夺条件**；线程持有资源后，在自己使用完之前不能被其他线程获取
> * **环路等待条件**：两个线程获取资源的顺序构成了环形链，即A持有1等待2，B持有2等待1
>
> 因此想要避免死锁，只需要破坏其中一个条件，比如使用资源有序分配法，即线程以相同的顺序申请想要的资源

#### 常规解决死锁问题

```cpp
#include <iostream>           // std::cout
#include <thread>             // std::thread
#include <mutex>              // std::mutex, std::unique_lock
#include <condition_variable> // std::condition_variable
#include <vector>

// 锁资源1
std::mutex mtx1;
// 锁资源2
std::mutex mtx2;

// 线程A的函数
void taskA()
{
	// 保证线程A先获取锁1
	std::lock_guard<std::mutex> lockA(mtx1);
	std::cout << "线程A获取锁1" << std::endl;

	// 线程A睡眠2s再获取锁2，保证锁2先被线程B获取，模拟死锁问题的发生
	std::this_thread::sleep_for(std::chrono::seconds(2));

	// 线程A先获取锁2
	std::lock_guard<std::mutex> lockB(mtx2);
	std::cout << "线程A获取锁2" << std::endl;

	std::cout << "线程A释放所有锁资源，结束运行！" << std::endl;
}

// 线程B的函数
void taskB()
{
	// 线程B先睡眠1s保证线程A先获取锁1
	std::this_thread::sleep_for(std::chrono::seconds(1));
	std::lock_guard<std::mutex> lockB(mtx2);
	std::cout << "线程B获取锁2" << std::endl;

	// 线程B尝试获取锁1
	std::lock_guard<std::mutex> lockA(mtx1);
	std::cout << "线程B获取锁1" << std::endl;

	std::cout << "线程B释放所有锁资源，结束运行！" << std::endl;
}
int main()
{
	// 创建生产者和消费者线程
	std::thread t1(taskA);
	std::thread t2(taskB);

	// main主线程等待所有子线程执行完
	t1.join();
	t2.join();

	return 0;
}
```



线程堵塞：

<img src="E:\MarkDown\picture\image-20230411161826256.png" alt="image-20230411161826256" style="zoom:50%;" />

**1、ps命令查看进程当前的运行状态和PID**

ps -aux | grep a.out

![image-20230411161840069](E:\MarkDown\picture\image-20230411161840069.png)

Sl+表示 S 处于休眠状态、l 多线程、+ 位于后台的进程组；

**2、top命令再查看一下进程内每个线程具体的运行情况**

top -Hp 338821

![image-20230411162338760](E:\MarkDown\picture\image-20230411162338760.png)

​	从top命令的打印信息可以看出，所有线程都进入阻塞状态，CPU占用率都为0.0，**可以排除是死循环的问题**，因为死循环会造成CPU使用率居高不下，而且线程的状态也不会是S。那么接下来有可能是由于I/O网络事件没有发生使线程阻塞，或者是线程发生死锁问题了。

3、**通过gdb远程调试正在运行的程序，打印进程每一个线程的调用堆栈信息**

通过gdb attach pid远程调试上面的a.out进程，命令如下：
gdb attach 338821

进入gdb调试命令行以后，打印所有线程的调用栈信息，信息如下：
thread apply all bt命令查看所用线程堆栈信息

![image-20230411162959010](E:\MarkDown\picture\image-20230411162959010.png)
![image-20230411163033066](E:\MarkDown\picture\image-20230411163033066.png)

从上面的线程调用栈信息可以看到，当前进程有三个线程，分别是**Thread1是main线程，Thread2是taskA线程，Thread3是taskB线程**。

从调用栈信息可以看到，Thread3线程进入S阻塞状态的原因是因为它最后在#0 __lll_lock_wait () at，也就是它在等待获取一把锁(lock_wait)，而且堆栈信息打印的很清晰，#1  0x00007f9ca3cffb09 in pthread_mutex_lock () from /lib64/libpthread.so.0，Thread3在获取而获取不到，因此进入阻塞状态了。
Thread2同理。

既然定位到taskA和taskB线程阻塞的原因，都是因为锁获取不到，然后再结合源码进行分析定位，最终发现taskA之所以获取不到mtx2，是因为mtx2早被taskB线程获取了；同样taskB之所以获取不到mtx1，是因为mtx1早被taskA线程获取了，导致所有线程进入阻塞状态，等待锁资源的获取，但是又因为没有线程释放锁，最终导致死锁问题。（从各线程调用栈信息能看出来，这里面和I/O网络事件没什么关系）

> 当然，也可以在源码上定位到问题代码，需要先得到debug版本(https://blog.csdn.net/QIANGWEIYUAN/article/details/88792621)

#### 项目中解决死锁问题

在fixed模式下，概率性遇到了死锁问题，即主线程堵塞住了



通过打印一些输出，发现线程死在资源回收那一块，对应线程池的析构函数。

```cpp
ThreadPool::~ThreadPool() {
	isPoolRunning_ = false;
	// 等待线程池中所有的线程返回
	// 两种状态：阻塞 / 执行中
	// 这里就需要进行线程的通信
	notEmpty_.notify_all();
	std::unique_lock<std::mutex> lock(taskQueMtx_);
	exitCond_.wait(lock, [&]()->bool {return threads_.size() == 0; });
}

void ThreadPool::threadFunc(int threadid) {
    while (isPoolRunning_) {
    	std::unique_lock<std::mutex> lock(taskQueMtx_);
    	notEmpty_.wait(lock);
    	if (!isPoolRunning_) {
        	threads_.erase(threadid);
        	// 通知下主线程的条件变量，否则会阻塞在主线程
        	exitCond_.notify_all();
        	return;
    	}
    }
}
```

​	在析构函数中先将 isPoolRunning_ 状态位置为false，然后唤醒notEmpty_信号量中等待的线程，之后堵塞在wait中。

​	1.对于正在等待的线程会被唤醒，进入到`if (!isPoolRunning_)`的判断，此时会将这个线程对象删除，然后唤醒主线程。主线程被唤醒后继续检查线程列表是否为空，不为空则继续堵塞。

​	2.对于正在执行的线程，主线程的notify是没有意义的。但这个线程执行完后，继续while循环时，发现isPoolRunning_ == false，同样也会终止循环并删除自己

​	对于上两种情况，即子线程在等待和子线程在执行的情况，都可以正常处理。但如果主线程执行线程池的析构时，子线程刚好进到了while (isPoolRunning_) 里面，此时会又分为两种情况：线程池先抢到锁和子线程先抢到锁。

​	3.1.若是线程池先抢到锁，线程池先判断条件，发现线程列表大于0，因此wait并释放锁，子线程拿到锁后，发现任务列表没有任务，因此进入wait状态。就死锁了。

​	3.2.若是线程先拿到锁，发现没任务，进入wait并释放锁，此时线程池拿到锁，然后还是wait了。

​	3.1和3.2这两种情况都发生了死锁！！子线程在notEmpty_下wait了，却没人唤醒。

```cpp
// 解决：
// 1.将notify放到了获取锁之后
ThreadPool::~ThreadPool() {
	isPoolRunning_ = false;
	std::unique_lock<std::mutex> lock(taskQueMtx_);
	notEmpty_.notify_all();  // 调换了4、5行的位置
	exitCond_.wait(lock, [&]()->bool {return threads_.size() == 0; });
}
// 2
void ThreadPool::threadFunc(int threadid) {
    while (isPoolRunning_){
        while (isPoolRunning_ && taskQue_.size() == 0) {}  // 增加了isPoolRunning_ 的判断
    }
}
```

​	3.1.若是线程池先抢到锁，线程池先判断条件，发现线程列表大于0，因此wait并释放锁，子线程拿到锁后，发现任务列表没有任务，因此进入wait状态。就死锁了。还是和之前一样。但区别在于，此时isPoolRunning_标志位已经置为false了，此时在`while (taskQue_.size() == 0)`的判断中进行双重判断，即变为`while (isPoolRunning_ && taskQue_.size() == 0)`，此时这个子线程就不会因为任务数为0而进入while循环，而是直接删除了。

​	3.2.若是线程先拿到锁，发现没任务，进入wait并释放锁，此时线程池拿到锁，然后notify唤醒线程，线程跳出while循环，删除掉自己

这样死锁问题就解决了！



Linux下可以通过gdb的调试找出，用gdb attach到正在运行的死锁的进程，调试每个线程的调用堆栈，找死锁问题。

[死锁问题分析解决](https://blog.csdn.net/QIANGWEIYUAN/article/details/88792621?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522167853425416800182746014%2522%252C%2522scm%2522%253A%252220140713.130102334..%2522%257D&request_id=167853425416800182746014&biz_id=0&utm_medium=distribute.pc_search_result.none-task-blog-2~all~sobaiduend~default-1-88792621-null-null.142^v73^control,201^v4^add_ask,239^v2^insert_chatgpt&utm_term=%E5%A4%A7%E7%A7%A6%E5%9D%91%E7%8E%8B%20gdb%E8%B0%83%E8%AF%95c%20%2011%E6%AD%BB%E9%94%81%E9%97%AE%E9%A2%98&spm=1018.2226.3001.4187)



.h

```cpp
#ifndef THREADPOOL_H
#define THREADPOOL_H
// 使用 #ifndef 而非 #pragma once ，因为后者需要编译器支持，在linux下不支持
#include<iostream>
#include<vector>
#include<queue>
#include<memory>  // 智能指针
#include<atomic>  // 原子类型，实现线程互斥
#include<mutex>  // 锁
#include<condition_variable>  // 条件变量，实现线程通信
#include<functional>
#include<thread>
#include<unordered_map>

// Any类型：可以接收任意数据的类型
// 将其作为函数返回值类型时，会看Any有没有一个合适的构造函数，来接收return返回的对象
class Any {
public:
	// 将任意类型的data包在派生类中，用基类指针指向
	template<typename T>
	Any(T data) : base_(std::make_unique<Derive<T>>(data)) {}

	// 定义一个方法，将Any对象存储的data_数据提取出来
	template<typename T>
	T cast_() {
		// 从base_指针中找到所指向的派生类对象，取出data_成员变量
		// 用智能指针提供的get方法取得裸指针，用 dynamic_cast 进行自动的类型转换至派生类指针
		Derive<T>* pd = dynamic_cast<Derive<T>*>(base_.get());
		if (pd == nullptr) {
			// dynamic_cast 转换失败，比如人家是int，你以为是long，就cast_<long>来调用，结果人家是Derive<int>，就转换失败了
			throw "type is unmatch";
		}
		return pd->data_;
	}
	Any() = default;
	~Any() = default;
	// Any类中的成员变量是unique_ptr类型的，对于这个智能指针，禁止了拷贝构造和赋值，仅支持移动构造
	// 因此Any类中也是这样的。这就是默认实现，不写也无所谓
	Any(const Any&) = delete;
	Any& operator=(const Any&) = delete;
	Any(Any&&) = default;
	Any& operator=(Any&&) = default;
private:
	// 基类类型
	class Base {
	public:
		// 对于多态用途的基类，需要虚析构函数
		// 若不是虚析构，在delete一个指向派生类的基类指针的时候，可能仅将派生类对象的基类部分西沟了，因此其结果将是未定义的
		// 定义为虚析构，才能确保delete基类指针时运行正确的析构函数版本
		virtual ~Base() = default;
	};
	// 派生类类型
	template<typename T>
	class Derive : public Base {
	public:
		Derive(T data) : data_(data) {};
		T data_;
	};
private:
	// 定义一个基类的指针
	std::unique_ptr<Base> base_;
};

// 实现一个信号量类，来实现Result类的线程通信
// 这个信号量默认的资源数为0
class Semaphore {
public:
	Semaphore(int count = 0) : resLimit_(count) {}
	// 获取一个信号量资源
	void wait() {
		std::unique_lock<std::mutex> lock(mtx_);
		// 等待信号量有资源
		cond_.wait(lock, [&]()->bool { return resLimit_ > 0; });
		resLimit_--;
	}
	// 增加一个信号量资源
	void post() {
		std::unique_lock<std::mutex> lock(mtx_);
		resLimit_++;
		cond_.notify_all();
	}
private:
	int resLimit_;
	std::mutex mtx_;
	std::condition_variable cond_;
};

class Task;  // Task对象的前置声明
// Result类：作为 submitTask 的返回值
// 实现接收提交到线程池的task任务执行完成后的返回值类型
// 主线程中的Result类通过get来获取任务线程的返回值，因此需要与任务线程进行线程通信
class Result {
public:
	Result(std::shared_ptr<Task> task, bool isValid = true);
	// 获取任务执行完的返回值，将task_ run()的返回值放到any_里
	void setVal(Any any);
	// 用户调用这个方法获取task的返回值
	Any get();

private:
	Any any_;  // 存储任务的返回值
	Semaphore sem_;  // 线程通信的信号量
	std::shared_ptr<Task> task_;  // 指向对应的需要获取返回值的task对象
	std::atomic_bool isValid_;  // 返回值是否有效
};


//////////////////////////////    任务抽象基类
class Task {
public:
	// 用户可以自定义任意任务类型，从 Task 继承，重写 run 方法，实现自定义任务处理
	Task();
	virtual Any run() = 0;
	void exec();
	void setResult(Result* res);
private:
	Result* result_;  // 这里用普通的指针就行，因为result的生命周期比task长
};


// 线程池支持的模式
// 这里使用了限定作用域的枚举类型
// 使用时必须显示的访问，PoolMode p = PoolMode::MODE_FIXED;
enum class PoolMode {
	MODE_FIXED,  // 固定数量的线程
	MODE_CACHED,  // 线程数量可动态增长
};


//////////////////////////////////   线程类型
class Thread {
public:
	// 线程函数对象类型，为function函数对象
	using ThreadFunc = std::function<void(int)>;

	Thread(ThreadFunc func);
	~Thread();
	void start();

	// 获取线程id
	int getId() const;
private:
	ThreadFunc func_;
	static int generateId_;  // 类的所有对象共享静态成员变量，通过它来得到变化的threadId_
	int threadId_;  // 保存线程ID
};


///////////////////////////////////   线程池类型
/*
example:
ThreadPool pool;
pool.start(4);

class MyTask : public Task
{
	public:
		void run() { // 线程代码... }
};

pool.submitTask(std::make_shared<MyTask>());
*/
class ThreadPool {
public:
	ThreadPool();
	~ThreadPool();
	// 禁止线程池的拷贝和复制
	ThreadPool(const ThreadPool&) = delete;
	ThreadPool& operator=(const ThreadPool&) = delete;

	// 设置线程池模式
	void setMode(PoolMode mode);

	// 开启线程池，并设置初始的线程数量，为cpu系统的核心数量
	void start(size_t initThreadSize = std::thread::hardware_concurrency());

	// 设置cached模式下线程阈值
	void setThreadSizeThreshHold(int threshhold);
	// 任务相关
	// 设置task任务队列上限阈值
	void setTaskQueMaxThreshHold(int threshhold);
	// 给线程池提交任务
	Result submitTask(std::shared_ptr<Task> sp);

private:
	// 定义线程函数
	void threadFunc(int threadid);

	// 检查线程池的运行状态
	bool checkRunningState() const;
private:
	

	// 线程相关
	// 线程列表。对于线程的创建，是在ThreadPool::start中new出来的，还需要delete
	// 因此直接使用智能指针。线程的话unique就行
	// std::vector<std::unique_ptr<Thread>> threads_;
	// 为了实现通过threadId_查询到对应的线程，这里最后使用了map
	std::unordered_map<int, std::unique_ptr<Thread>> threads_;

	size_t threadSizeThreshHold_;  // 线程数量的上限
	// 为什么新增一个变量而不是用threads_.size()呢，因为vector不是线程安全的
	std::atomic_int curThreadSize_;  // 记录当前线程池里面线程的总数量
	std::atomic_int idleThreadSize_;  // 记录空闲线程的数量
	int initThreadSize_;  // 初始的线程数量。size_t增强了可移植性，表示任何对象所能达到的最大长度
	
	// 需要使用基类的指针或引用才能实现多态
	// 而用户传入的通常会是临时的一个任务对象，出了submitTask语句后就析构了，用指针指向一个析构了的对象是没有意义的
	// 而我们是需要考虑来保持这个任务的生命周期的，当这个任务run执行以后在析构
	// 因此需要使用智能指针
	std::queue<std::shared_ptr<Task>> taskQue_;  // 任务队列
	std::atomic_uint taskSize_;  // 任务的数量。考虑到线程安全问题，使用轻量化的原子类型实现线程互斥
	size_t taskQueMaxThreshHold_;  // 任务队列数量的上限

	// 实现线程通信
	std::mutex taskQueMtx_;  // 保证任务队列的线程安全
	std::condition_variable notEmpty_;  // 任务队列不空
	std::condition_variable notFull_;  // 任务队列不满
	std::condition_variable exitCond_;  // 等待线程资源全部回收

	PoolMode poolMode_;  // 当前线程池的工作模式

	std::atomic_bool isPoolRunning_;  // 表示当前线程池的启动状态
	
};


#endif // !THREADPOOL_H

```

.cpp

```cpp
#include"threadpool.h"

const int TASK_MAX_THRESHHOLD = 1024;
const int THREAD_MAX_THRESHHOLD = 100;
const int THREAD_MAX_IDLE_TIME = 10;  // 等待的时间，s
//////////////////////  Task方法实现
Task::Task(): result_(nullptr) {}
// 在task对应的result类进行构造的时候调用，将新创建的result绑定到当前的task上
// 即为task中指向Result的成员变量result_赋值，之后就可以通过这个指针，将task的结果存到Result对象中了
void Task::setResult(Result* res) {
	result_ = res;
}
void Task::exec() {
	// run，并将任务的返回值保存在Result类中
	if (result_ != nullptr) {
		result_->setVal(run());  // run在这里发生多态调用
	}
}

//////////////////////  线程池方法实现
ThreadPool::ThreadPool()
	: initThreadSize_(4)
	, taskSize_(0)
	, taskQueMaxThreshHold_(TASK_MAX_THRESHHOLD)
	, threadSizeThreshHold_(THREAD_MAX_THRESHHOLD)
	, poolMode_(PoolMode::MODE_FIXED)
	, isPoolRunning_(false)
	, curThreadSize_(0)
	, idleThreadSize_(0)
{}

ThreadPool::~ThreadPool() {
	isPoolRunning_ = false;
	// 等待线程池中所有的线程返回
	// 两种状态：阻塞 / 执行中
	// 这里就需要进行线程的通信
	std::unique_lock<std::mutex> lock(taskQueMtx_);
	notEmpty_.notify_all();
	exitCond_.wait(lock, [&]()->bool {return threads_.size() == 0; });
}

// 设置cached模式下线程阈值
void ThreadPool::setThreadSizeThreshHold(int threshhold) {
	if (checkRunningState()) return;
	if (poolMode_ == PoolMode::MODE_CACHED) {
		threadSizeThreshHold_ = threshhold;
	}
}
// 设置线程池工作模式
void ThreadPool::setMode(PoolMode mode) {
	// 如果线程池已经启动了，则不能设置工作模式了
	if (checkRunningState()) return;
	poolMode_ = mode;
}

// 检查线程池的运行状态
bool ThreadPool::checkRunningState() const {
	return isPoolRunning_;
}

// 任务相关
// 设置task任务队列上限阈值
void ThreadPool::setTaskQueMaxThreshHold(int threshhold) {
	// 如果线程池已经启动了，则不能设置了
	if (checkRunningState()) return;
	taskQueMaxThreshHold_ = threshhold;
}

// 开启线程池，并设置初始的线程数量
void ThreadPool::start(size_t initThreadSize) {
	// 设置线程池的启动状态
	isPoolRunning_ = true;

	// 设置初始的线程数量
	initThreadSize_ = initThreadSize;
	// 记录线程总数
	curThreadSize_ = initThreadSize;

	// 创建线程对象
	for (size_t i = 0; i < initThreadSize_; i++) {
		// 创建thread线程对象的时候，需要把线程函数给到thread类
		// 这样在Thread::start中才能启动这个线程函数
		// 通过构造函数，将threadFunc放进去
		// 这里我们使用bind。对于类的成员函数，前面要取个地址
		// 且需要绑定一个类对象才能使用，这里绑定了this即当前对象
		// 这里使用智能指针创建线程对象，让其能自动析构
		auto ptr = std::make_unique<Thread>(std::bind(&ThreadPool::threadFunc, this, std::placeholders::_1));  // c++14
		// 使用move将左值转换为对应的右值引用类型
		int threadId = ptr->getId();
		threads_.emplace(threadId, std::move(ptr));
		// unique_ptr是不允许拷贝构造的，仅支持一个智能指针指向它
		// 因此 emplace_back(ptr) 的操作会报错
		// unique_ptr虽然关闭了左值引用的拷贝和赋值，但支持右值引用的操作！
	}

	// 启动所有线程
	for (size_t i = 0; i < initThreadSize_; i++) {
		// 注意，这里threads_[i]是指针
		// 调用了线程类里的start函数创建并启动线程
		threads_[i]->start();
		idleThreadSize_++;
	}
}

// threadFunc负责在线程池中获取并执行任务
// 在线程池类中定义线程函数，由线程类执行
// 线程函数需要的那些锁和条件变量，都定义在线程池中
// 这里线程函数若是定义在Thread类中，则不方便访问ThreadPool里的那些私有的锁和条件变量
// 因此将线程函数定义在ThreadPool类中
void ThreadPool::threadFunc(int threadid) {
	auto lastTime = std::chrono::high_resolution_clock().now();

	// 所有任务必须执行完成，线程池才可以回收所有线程资源，所以还是必须用for(;;)
	// 相当于while(true)。线程执行threadFunc后便一直在此函数中尝试获取任务
	while (isPoolRunning_) {
		// 注意，我们仅需要在取任务的时候获取锁，取到任务后释放锁，再执行任务
		std::shared_ptr<Task> task;
		{
			// 获取锁
			std::unique_lock<std::mutex> lock(taskQueMtx_);

			std::cout << "tid:" << std::this_thread::get_id()
				<< "尝试获取任务!" << std::endl;

			// cached模式下，有可能已经创建了很多的线程，但是空闲时间超过60s
			// 对于超过初始线程数量initThreadSize_的线程，需要看情况进行回收
			while (isPoolRunning_ && taskQue_.size() == 0) {
				// 每一秒返回一次
				// while来区分是超时返回还是有任务待执行返回
				// 任务队列有任务，就跳过while去消费，没任务才等待任务
				if (poolMode_ == PoolMode::MODE_CACHED) {
					// wait_for函数的返回值cv_status有两个状态，超时和不超时
					if (std::cv_status::timeout == 
						notEmpty_.wait_for(lock, std::chrono::seconds(1))) {
						auto now = std::chrono::high_resolution_clock().now();
						auto dur = std::chrono::duration_cast<std::chrono::seconds>(now - lastTime);
						if (dur.count() >= THREAD_MAX_IDLE_TIME
							&& curThreadSize_ > initThreadSize_) {
							// 回收线程
							// 记录线程数量的相关变量的值
							idleThreadSize_--;
							curThreadSize_--;

							// 将线程对象从线程列表中删除 但没法将threadFunc对应到thread对象
							// threadid => thread对象 => 删除
							threads_.erase(threadid);
							std::cout << "threadid:" << std::this_thread::get_id() << " exit!" << std::endl;
							return;
						}
					}
				}
				else {
					notEmpty_.wait(lock);
				}
				//// 判断一下是有任务才被唤醒的，还是因为线程池结束才唤醒的
				//if (!isPoolRunning_) {
				//	// 将线程对象从线程列表中删除 但没法将threadFunc对应到thread对象
				//	// threadid => thread对象 => 删除
				//	threads_.erase(threadid);
				//	std::cout << "threadid:" << std::this_thread::get_id() << " exit!" << std::endl;
				//	// 通知下主线程的条件变量，否则会阻塞在主线程
				//	exitCond_.notify_all();
				//	return;
				//}
			}
			// 线程池要结束，回收线程资源，后面的这些都不执行了，直接跳出while循环，来执行删除线程操作
			// 就省了155-164的繁琐操作
			if (!isPoolRunning_) break;
			idleThreadSize_--;

			std::cout << "tid:" << std::this_thread::get_id()
				<< "成功获取任务!" << std::endl;

			task = taskQue_.front(); taskQue_.pop();
			taskSize_--;

			// 为什么用了两个条件变量呢，这便于进行更精细的操作
			// 如果任务队列仍有任务，则通知其他wait在notEmpty_的线程执行任务
			if (taskQue_.size() > 0) {
				notEmpty_.notify_all();
			}
			
			// 通知 wait在notFull_上的生产者，可以继续提交任务
			notFull_.notify_all();
		}  // 取完任务，释放锁
		if (task != nullptr) {
			// 执行任务，并把任务的返回值setVal方法给到Result
			// task->run();
			// run是个需要重写的方法，我们不可能将增加的这部分功能写到run里面
			// 所以我们在Task类中增加了exec函数，在这个函数中执行run和新增加的功能
			task->exec();
		}
		idleThreadSize_++;
		lastTime = std::chrono::high_resolution_clock().now();
	}
	// 若是线程池结束时还有任务没执行完，则等其结束wait状态后，跳出while循环，在这里进行析构
	threads_.erase(threadid);
	std::cout << "threadid:" << std::this_thread::get_id() << " exit!" << std::endl;
	// 结束时通知下pool所在的主线程
	exitCond_.notify_all();
}

// 给线程池提交任务
// 生产者：获取锁，while(满) {wait}，提交任务，notify_all
Result ThreadPool::submitTask(std::shared_ptr<Task> sp) {
	// 获取锁
	std::unique_lock<std::mutex> lock(taskQueMtx_);

	// 线程的通信 等待任务队列有空余
	// 没有空余才等待，因此需要等待notFull_
	// 这里使用了lambda表达式的隐式捕获的引用捕获，让编译器根据函数体中代码推断捕获列表
	//// notFull_.wait(lock, [&]()->bool {return taskQue_.size() < taskQueMaxThreshHold_; });
	// 与下面三行等价
	//while (taskQue_.size() == taskQueMaxThreshHold_) {
	//	notFull_.wait(lock);
	//}
	// 增加一个要求：用户提交任务，最长不能阻塞超过1s，否则判断提交任务失败，返回
	// wait()：一直等待到条件满足；wait_for()：等一段时间；wait_until()：等到一个时间点
	/*notFull_.wait_for(lock, std::chrono::seconds(1), [&]()->bool {return taskQue_.size() < taskQueMaxThreshHold_; });*/
	if (!notFull_.wait_for(lock, std::chrono::seconds(1), [&]()->bool {return taskQue_.size() < taskQueMaxThreshHold_; })) {
		// 等待1s，条件仍不满足
		std::cerr << "task queue is full, submit task fail." << std::endl;
		// 若任务提交失败，则
		return Result(sp, false);
	}

	// 有空余，将任务放入任务队列
	taskQue_.emplace(sp);
	taskSize_++;

	// 任务队列不空，通知notEmpty_
	notEmpty_.notify_all();

	// cached模式需要根据任务数量和空闲线程的数量，判断是否需要创建新的线程出来
	// 且需要当前线程总数小于我们设定的最大线程数
	if (poolMode_ == PoolMode::MODE_CACHED && taskSize_ > idleThreadSize_ && curThreadSize_ < threadSizeThreshHold_) {
		std::cout << "create new thread" << std::endl;
		// 创建新线程
		auto ptr = std::make_unique<Thread>(std::bind(&ThreadPool::threadFunc, this, std::placeholders::_1));  // c++14
		int threadId = ptr->getId();
		threads_.emplace(threadId, std::move(ptr));
		// 启动线程
		threads_[threadId]->start();
		// 修改线程个数相关的变量
		curThreadSize_++;
		idleThreadSize_++;
	}
	// 对于Result，可以通过task类里面的函数返回，也可以用Result类进行封装
	// return task->getResult();  // 不行！task对象被线程取出来用完后就析构了，再想使用这个task对象是不行的
	// return Result(task);  // 因此通过Result来维持task的生命周期，保证我们想要task返回值的时候task对象还在
	return Result(sp);
}


/////////////////////////////////// 线程方法实现
int Thread::generateId_ = 0;

Thread::Thread(ThreadFunc func)
	: func_(func)
	, threadId_(generateId_++)
{}

Thread::~Thread() {

}

int Thread::getId() const {
	return threadId_;
}

// 启动线程
void Thread::start() {
	// 创建线程
	// ThreadPool::start函数创建了thread，传入了func_
	// 因此创建线程的时候直接把func_放进去就行
	// 这里thread的构造函数通过完美转发将参数传递给线程函数
	
	std::thread t(func_, threadId_);
	// 注意，上面是将线程函数写到线程池类的写法
	// 若是将线程函数写到Thread类中，则应该写为
	// std::thread t(&Thread::threadFunc, &thread1);
	// thread1表示一个线程对象，相应的start函数也应该有形参：start(Thread& thread1)

	// 注意，这个线程对象t出了这个作用域就会自动销毁
	// 因此要设置为分离线程，使得此线程变为守护线程，驻留后台运行
	t.detach();
}



/////////////////////////////  Result的实现
Result::Result(std::shared_ptr<Task> task, bool isValid) 
	: task_(task), isValid_(isValid){
	// 顺便将result对象绑定到task上
	task_->setResult(this);
}

Any Result::get() {
	if (!isValid_) return "";  // 如果返回值无效，返回g个空
	sem_.wait();  // task任务如果没有执行完，则堵塞用户的线程
	return std::move(any_);

}

void Result::setVal(Any any) {
	// 存储task的返回值
	this->any_ = std::move(any);
	sem_.post();
}
```

test.cpp

```cpp
#include"threadpool.h"
#include<chrono>

class MyTask : public Task
{
public:
	MyTask(int begin, int end)
		: begin_(begin)
		, end_(end)
	{}
	Any run() {
		std::cout << "tid:" << std::this_thread::get_id()
			<< "begin!" << std::endl;
		std::this_thread::sleep_for(std::chrono::seconds(5));
		int sum = 0;
		for (int i = begin_; i <= end_; i++)
			sum += i;
		std::cout << "tid:" << std::this_thread::get_id()
			<< "end!" << std::endl;
		return sum;
	}
private:
	int begin_;
	int end_;
};

// const int TASK_MAX_THRESHHOLD = 4;，任务列表设为了最大四个任务
// 此时线程池设置4个线程。每个任务执行5s，提交若干个任务后，会有一些任务提交失败（等待超过了1s）

int main() {
	{
		ThreadPool pool;
		// 用户自己设置线程池的工作模式
		//pool.setMode(PoolMode::MODE_CACHED);
		// 启动线程池
		pool.start(2);
		// Master - Slave线程模型
		// Master线程用来分解任务，然后给各个Slave线程分配任务
		// 等待各个Slave线程执行完任务，返回结果
		// Master线程合并各个任务结果，输出
		Result res1 = pool.submitTask(std::make_shared<MyTask>(1, 100));
		Result res2 = pool.submitTask(std::make_shared<MyTask>(101, 200));
		Result res3 = pool.submitTask(std::make_shared<MyTask>(201, 300));
		int sum = res1.get().cast_<int>() + res2.get().cast_<int>() + res3.get().cast_<int>();
		std::cout << sum << std::endl;
		int sum2 = 0;
		for (int i = 1; i <= 300; i++) {
			sum2 += i;
		}
		std::cout << "answer:" << sum2 << std::endl;
	}
	getchar();
}
```





### 阶段六 线程池资源回收策略修改

如果不设置一个值来接收我们的结果，那随着pool出作用域就会析构，我们的任务就直接结束了，并不会等任务都执行完才结束。

因为我们submitTask提交任务是很快的，任务刚提交给线程，线程池对象就因为出了作用域析构了，此时运行标志位置false，执行任务的threadFunc可能还没进while(isPoolRunning_)取任务并执行，就直接被结束了。

```cpp
int main() {
	{
		ThreadPool pool;
		pool.start(2);
		Result res1 = pool.submitTask(std::make_shared<MyTask>(1, 100));
		Result res2 = pool.submitTask(std::make_shared<MyTask>(101, 200));
		Result res3 = pool.submitTask(std::make_shared<MyTask>(201, 300));
        // int sum = res1.get().cast_<int>();
	}  // pool析构
	getchar();
}
```

为了保证等所有任务执行完成，线程池才可以回收所有线程资源，threadFunc中还是必须用for(;;)/while(true)，然后更改函数中的逻辑

threadFunc

```cpp
void ThreadPool::threadFunc(int threadid) {
	auto lastTime = std::chrono::high_resolution_clock().now();

	// 所有任务必须执行完成，线程池才可以回收所有线程资源，所以还是必须用for(;;)
	// 相当于while(true)。线程执行threadFunc后便一直在此函数中尝试获取任务
	// while (isPoolRunning_){
	for (;;) {
		// 注意，我们仅需要在取任务的时候获取锁，取到任务后释放锁，再执行任务
		std::shared_ptr<Task> task;
		{
			// 获取锁
			std::unique_lock<std::mutex> lock(taskQueMtx_);

			std::cout << "tid:" << std::this_thread::get_id()
				<< "尝试获取任务!" << std::endl;

			// cached模式下，有可能已经创建了很多的线程，但是空闲时间超过60s
			// 对于超过初始线程数量initThreadSize_的线程，需要看情况进行回收
			while (taskQue_.size() == 0) {
				// 线程池要结束，回收线程资源，后面的这些都不执行了，直接跳出while循环，来执行删除线程操作
				if (!isPoolRunning_) {
					// 若是线程池结束时还有任务没执行完，则等其结束wait状态后，跳出while循环，在这里进行析构
					threads_.erase(threadid);
					std::cout << "threadid:" << std::this_thread::get_id() << " exit!" << std::endl;
					// 结束时通知下pool所在的主线程
					exitCond_.notify_all();
					return;
				}
				// 每一秒返回一次
				// while来区分是超时返回还是有任务待执行返回
				// 任务队列有任务，就跳过while去消费，没任务才等待任务
				if (poolMode_ == PoolMode::MODE_CACHED) {
					// wait_for函数的返回值cv_status有两个状态，超时和不超时
					if (std::cv_status::timeout == 
						notEmpty_.wait_for(lock, std::chrono::seconds(1))) {
						auto now = std::chrono::high_resolution_clock().now();
						auto dur = std::chrono::duration_cast<std::chrono::seconds>(now - lastTime);
						if (dur.count() >= THREAD_MAX_IDLE_TIME
							&& curThreadSize_ > initThreadSize_) {
							// 回收线程
							// 记录线程数量的相关变量的值
							idleThreadSize_--;
							curThreadSize_--;

							// 将线程对象从线程列表中删除 但没法将threadFunc对应到thread对象
							// threadid => thread对象 => 删除
							threads_.erase(threadid);
							std::cout << "threadid:" << std::this_thread::get_id() << " exit!" << std::endl;
							return;
						}
					}
				}
				else {
					notEmpty_.wait(lock);
				}
				//// 判断一下是有任务才被唤醒的，还是因为线程池结束才唤醒的
				//if (!isPoolRunning_) {
				//	// 将线程对象从线程列表中删除 但没法将threadFunc对应到thread对象
				//	// threadid => thread对象 => 删除
				//	threads_.erase(threadid);
				//	std::cout << "threadid:" << std::this_thread::get_id() << " exit!" << std::endl;
				//	// 通知下主线程的条件变量，否则会阻塞在主线程
				//	exitCond_.notify_all();
				//	return;
				//}
			}

			idleThreadSize_--;

			std::cout << "tid:" << std::this_thread::get_id()
				<< "成功获取任务!" << std::endl;

			task = taskQue_.front(); taskQue_.pop();
			taskSize_--;

			// 为什么用了两个条件变量呢，这便于进行更精细的操作
			// 如果任务队列仍有任务，则通知其他wait在notEmpty_的线程执行任务
			if (taskQue_.size() > 0) {
				notEmpty_.notify_all();
			}
			
			// 通知 wait在notFull_上的生产者，可以继续提交任务
			notFull_.notify_all();
		}  // 取完任务，释放锁
		if (task != nullptr) {
			// 执行任务，并把任务的返回值setVal方法给到Result
			// task->run();
			// run是个需要重写的方法，我们不可能将增加的这部分功能写到run里面
			// 所以我们在Task类中增加了exec函数，在这个函数中执行run和新增加的功能
			task->exec();
		}
		idleThreadSize_++;
		lastTime = std::chrono::high_resolution_clock().now();
	}
}

```

test.cpp

```cpp
#include"threadpool.h"
#include<chrono>

class MyTask : public Task
{
public:
	MyTask(int begin, int end)
		: begin_(begin)
		, end_(end)
	{}
	Any run() {
		std::cout << "tid:" << std::this_thread::get_id()
			<< "begin!" << std::endl;
		std::this_thread::sleep_for(std::chrono::seconds(5));
		int sum = 0;
		for (int i = begin_; i <= end_; i++)
			sum += i;
		std::cout << "tid:" << std::this_thread::get_id()
			<< "end!" << std::endl;
		return sum;
	}
private:
	int begin_;
	int end_;
};

// const int TASK_MAX_THRESHHOLD = 4;，任务列表设为了最大四个任务
// 此时线程池设置4个线程。每个任务执行5s，提交若干个任务后，会有一些任务提交失败（等待超过了1s）

int main() {
	{
		ThreadPool pool;
		// 用户自己设置线程池的工作模式
		//pool.setMode(PoolMode::MODE_CACHED);
		// 启动线程池
		pool.start(2);
		// Master - Slave线程模型
		// Master线程用来分解任务，然后给各个Slave线程分配任务
		// 等待各个Slave线程执行完任务，返回结果
		// Master线程合并各个任务结果，输出
		Result res1 = pool.submitTask(std::make_shared<MyTask>(1, 100));
		Result res2 = pool.submitTask(std::make_shared<MyTask>(101, 200));
		Result res3 = pool.submitTask(std::make_shared<MyTask>(201, 300));
		/*int sum = res1.get().cast_<int>() + res2.get().cast_<int>() + res3.get().cast_<int>();
		std::cout << sum << std::endl;
		int sum2 = 0;
		for (int i = 1; i <= 300; i++) {
			sum2 += i;
		}
		std::cout << "answer:" << sum2 << std::endl;*/
	}
	getchar();
}
```







## 最终版代码

```cpp
#ifndef THREADPOOL_H
#define THREADPOOL_H
// 使用 #ifndef 而非 #pragma once ，因为后者需要编译器支持，在linux下不支持
#include<iostream>
#include<vector>
#include<queue>
#include<memory>  // 智能指针
#include<atomic>  // 原子类型，实现线程互斥
#include<mutex>  // 锁
#include<condition_variable>  // 条件变量，实现线程通信
#include<functional>
#include<thread>
#include<unordered_map>
#include<future>

const int TASK_MAX_THRESHHOLD = 1024;
const int THREAD_MAX_THRESHHOLD = 100;
const int THREAD_MAX_IDLE_TIME = 10;  // 等待的时间，s

// 线程池支持的模式
// 这里使用了c++11中限定作用域的枚举类型
// 使用时必须显示的访问，PoolMode p = PoolMode::MODE_FIXED;
enum class PoolMode {
	MODE_FIXED,  // 固定数量的线程
	MODE_CACHED,  // 线程数量可动态增长
};

//////////////////////////////////   线程类型
class Thread {
public:
	// 线程函数对象类型，为function函数对象
	using ThreadFunc = std::function<void(int)>;

	Thread(ThreadFunc func)
        : func_(func)
        , threadId_(generateId_++)
    {}
	
    ~Thread() = default;
	// 启动线程
    void start() {
        // 创建线程
        // ThreadPool::start函数创建了thread，传入了func_
        // 因此创建线程的时候直接把func_放进去就行
        // 这里thread的构造函数通过完美转发将参数传递给线程函数
        
        std::thread t(func_, threadId_);
        // 注意，上面是将线程函数写到线程池类的写法
        // 若是将线程函数写到Thread类中，则应该写为
        // std::thread t(&Thread::threadFunc, &thread1);
        // thread1表示一个线程对象，相应的start函数也应该有形参：start(Thread& thread1)

        // 注意，这个线程对象t出了这个作用域就会自动销毁
        // 因此要设置为分离线程，使得此线程变为守护线程，驻留后台运行
        t.detach();
    }

	// 获取线程id
	int getId() const {
        return threadId_;
    }
private:
	ThreadFunc func_;
	static int generateId_;  // 类的所有对象共享静态成员变量，通过它来得到变化的threadId_
	int threadId_;  // 保存线程ID
};
// 静态成员变量在类外要初始化
int Thread::generateId_ = 0;

///////////////////////////////////   线程池类型

class ThreadPool {
public:
	ThreadPool()
        : initThreadSize_(4)
        , taskSize_(0)
        , taskQueMaxThreshHold_(TASK_MAX_THRESHHOLD)
        , threadSizeThreshHold_(THREAD_MAX_THRESHHOLD)
        , poolMode_(PoolMode::MODE_FIXED)
        , isPoolRunning_(false)
        , curThreadSize_(0)
        , idleThreadSize_(0)
    {}
	~ThreadPool() {
        isPoolRunning_ = false;
        // 等待线程池中所有的线程返回
        // 两种状态：阻塞 / 执行中
        // 这里就需要进行线程的通信
        std::unique_lock<std::mutex> lock(taskQueMtx_);
        notEmpty_.notify_all();
        exitCond_.wait(lock, [&]()->bool {return threads_.size() == 0; });
    }
	// 禁止线程池的拷贝和复制
	ThreadPool(const ThreadPool&) = delete;
	ThreadPool& operator=(const ThreadPool&) = delete;

	// 设置线程池模式
	void setMode(PoolMode mode) {
        // 如果线程池已经启动了，则不能设置工作模式了
        if (checkRunningState()) return;
        poolMode_ = mode;
    }

	// 开启线程池，并设置初始的线程数量，为cpu系统的核心数量
	void start(size_t initThreadSize = std::thread::hardware_concurrency()) {
        // 设置线程池的启动状态
        isPoolRunning_ = true;

        // 设置初始的线程数量
        initThreadSize_ = initThreadSize;
        // 记录线程总数
        curThreadSize_ = initThreadSize;

        // 创建线程对象
        for (size_t i = 0; i < initThreadSize_; i++) {
            // 创建thread线程对象的时候，需要把线程函数给到thread类
            // 这样在Thread::start中才能启动这个线程函数
            // 通过构造函数，将threadFunc放进去
            // 这里我们使用bind。对于类的成员函数，前面要取个地址
            // 且需要绑定一个类对象才能使用，这里绑定了this即当前对象
            // 这里使用智能指针创建线程对象，让其能自动析构
            auto ptr = std::make_unique<Thread>(std::bind(&ThreadPool::threadFunc, this, std::placeholders::_1));  // c++14
            // 使用move将左值转换为对应的右值引用类型
            int threadId = ptr->getId();
            threads_.emplace(threadId, std::move(ptr));
            // unique_ptr是不允许拷贝构造的，仅支持一个智能指针指向它
            // 因此 emplace_back(ptr) 的操作会报错
            // unique_ptr虽然关闭了左值引用的拷贝和赋值，但支持右值引用的操作！
        }

        // 启动所有线程
        for (size_t i = 0; i < initThreadSize_; i++) {
            // 注意，这里threads_[i]是指针
            // 调用了线程类里的start函数创建并启动线程
            threads_[i]->start();
            idleThreadSize_++;
        }
    }

	// 设置cached模式下线程阈值
	void setThreadSizeThreshHold(int threshhold) {
        if (checkRunningState()) return;
        if (poolMode_ == PoolMode::MODE_CACHED) {
            threadSizeThreshHold_ = threshhold;
        }
    }
	
    // 任务相关
	// 设置task任务队列上限阈值
	void setTaskQueMaxThreshHold(int threshhold) {
        // 如果线程池已经启动了，则不能设置了
        if (checkRunningState()) return;
        taskQueMaxThreshHold_ = threshhold;
    }
	
    // 给线程池提交任务
    // 使用可变参模板编程，实现pool.submitTask(sum1, 10, 20);
    template<typename Func, typename... Args> 
    // Func&&引用折叠，可以接收左值和右值引用
    // 配合auto写成尾置返回类型
    // 返回值为future<>类型，而future中的类型需要decltype进行推导
	auto submitTask(Func&& func, Args&&... args) 
        -> std::future<decltype(func(args...))>
    {  
        // 打包任务，放入任务队列
        using RType = decltype(func(args...));
        // 通过智能指针延长生命周期
        // packaged_task需要传入返回值类型和参数类型，这里参数类型直接绑定上
        // 需要使用std::forward进行完美转发
        auto task = std::make_shared<std::packaged_task<RType()>>(std::bind(std::forward<Func>(func), std::forward<Args>(args)...));
        std::future<RType> result = task->get_future();

        // 原来的submitTask的内容
        // 获取锁
        std::unique_lock<std::mutex> lock(taskQueMtx_);

        // 线程的通信 等待任务队列有空余
        // 没有空余才等待，因此需要等待notFull_
        // 这里使用了lambda表达式的隐式捕获的引用捕获，让编译器根据函数体中代码推断捕获列表
        //// notFull_.wait(lock, [&]()->bool {return taskQue_.size() < taskQueMaxThreshHold_; });
        // 与下面三行等价
        //while (taskQue_.size() == taskQueMaxThreshHold_) {
        //	notFull_.wait(lock);
        //}
        // 增加一个要求：用户提交任务，最长不能阻塞超过1s，否则判断提交任务失败，返回
        // wait()：一直等待到条件满足；wait_for()：等一段时间；wait_until()：等到一个时间点
        /*notFull_.wait_for(lock, std::chrono::seconds(1), [&]()->bool {return taskQue_.size() < taskQueMaxThreshHold_; });*/
        if (!notFull_.wait_for(lock, std::chrono::seconds(1), [&]()->bool {return taskQue_.size() < taskQueMaxThreshHold_; })) {
            // 等待1s，条件仍不满足
            std::cerr << "task queue is full, submit task fail." << std::endl;
            // 若任务提交失败，则返回一个空值
            auto task = std::make_shared<std::packaged_task<RType()>>(
                []()->RType { return RType(); }
                );
            (*task)();
            return task->get_future();
        }

        // 有空余，将任务放入任务队列
        // 任务队列中的类型我们写成了如下的形式，是一个没有返回值的
        // using Task = std::function<void()>;
        // 我们通过写成无返回值的lambda表达式的形式调用task来实现
        taskQue_.emplace([task]() {
            // 执行下面的任务
            (*task)();  // task解引用后就是packaged_task的函数对象
        }
        );
        taskSize_++;

        // 任务队列不空，通知notEmpty_
        notEmpty_.notify_all();

        // cached模式需要根据任务数量和空闲线程的数量，判断是否需要创建新的线程出来
        // 且需要当前线程总数小于我们设定的最大线程数
        if (poolMode_ == PoolMode::MODE_CACHED && taskSize_ > idleThreadSize_ && curThreadSize_ < threadSizeThreshHold_) {
            std::cout << "create new thread" << std::endl;
            // 创建新线程
            auto ptr = std::make_unique<Thread>(std::bind(&ThreadPool::threadFunc, this, std::placeholders::_1));  // c++14
            int threadId = ptr->getId();
            threads_.emplace(threadId, std::move(ptr));
            // 启动线程
            threads_[threadId]->start();
            // 修改线程个数相关的变量
            curThreadSize_++;
            idleThreadSize_++;
        }
        // 对于Result，可以通过task类里面的函数返回，也可以用Result类进行封装
        // return task->getResult();  // 不行！task对象被线程取出来用完后就析构了，再想使用这个task对象是不行的
        // return Result(task);  // 因此通过Result来维持task的生命周期，保证我们想要task返回值的时候task对象还在
        return result;
    }

private:
	// 定义线程函数
    // threadFunc负责在线程池中获取并执行任务
    // 在线程池类中定义线程函数，由线程类执行
    // 线程函数需要的那些锁和条件变量，都定义在线程池中
    // 这里线程函数若是定义在Thread类中，则不方便访问ThreadPool里的那些私有的锁和条件变量
    // 因此将线程函数定义在ThreadPool类中
    void threadFunc(int threadid) {
        auto lastTime = std::chrono::high_resolution_clock().now();

        // 所有任务必须执行完成，线程池才可以回收所有线程资源，所以还是必须用for(;;)
        // 相当于while(true)。线程执行threadFunc后便一直在此函数中尝试获取任务
        // while (isPoolRunning_){
        for (;;) {
            // 注意，我们仅需要在取任务的时候获取锁，取到任务后释放锁，再执行任务
            Task task;
            {
                // 获取锁
                std::unique_lock<std::mutex> lock(taskQueMtx_);

                std::cout << "tid:" << std::this_thread::get_id()
                    << "尝试获取任务!" << std::endl;

                // cached模式下，有可能已经创建了很多的线程，但是空闲时间超过60s
                // 对于超过初始线程数量initThreadSize_的线程，需要看情况进行回收
                while (taskQue_.size() == 0) {
                    // 线程池要结束，回收线程资源，后面的这些都不执行了，直接跳出while循环，来执行删除线程操作
                    if (!isPoolRunning_) {
                        // 若是线程池结束时还有任务没执行完，则等其结束wait状态后，跳出while循环，在这里进行析构
                        threads_.erase(threadid);
                        std::cout << "threadid:" << std::this_thread::get_id() << " exit!" << std::endl;
                        // 结束时通知下pool所在的主线程
                        exitCond_.notify_all();
                        return;
                    }
                    // 每一秒返回一次
                    // while来区分是超时返回还是有任务待执行返回
                    // 任务队列有任务，就跳过while去消费，没任务才等待任务
                    if (poolMode_ == PoolMode::MODE_CACHED) {
                        // wait_for函数的返回值cv_status有两个状态，超时和不超时
                        if (std::cv_status::timeout == 
                            notEmpty_.wait_for(lock, std::chrono::seconds(1))) {
                            auto now = std::chrono::high_resolution_clock().now();
                            auto dur = std::chrono::duration_cast<std::chrono::seconds>(now - lastTime);
                            if (dur.count() >= THREAD_MAX_IDLE_TIME
                                && curThreadSize_ > initThreadSize_) {
                                // 回收线程
                                // 记录线程数量的相关变量的值
                                idleThreadSize_--;
                                curThreadSize_--;

                                // 将线程对象从线程列表中删除 但没法将threadFunc对应到thread对象
                                // threadid => thread对象 => 删除
                                threads_.erase(threadid);
                                std::cout << "threadid:" << std::this_thread::get_id() << " exit!" << std::endl;
                                return;
                            }
                        }
                    }
                    else {
                        notEmpty_.wait(lock);
                    }
                }

                idleThreadSize_--;

                std::cout << "tid:" << std::this_thread::get_id()
                    << "成功获取任务!" << std::endl;

                task = taskQue_.front(); taskQue_.pop();
                taskSize_--;

                // 为什么用了两个条件变量呢，这便于进行更精细的操作
                // 如果任务队列仍有任务，则通知其他wait在notEmpty_的线程执行任务
                if (taskQue_.size() > 0) {
                    notEmpty_.notify_all();
                }
                
                // 通知 wait在notFull_上的生产者，可以继续提交任务
                notFull_.notify_all();
            }  // 取完任务，释放锁
            if (task != nullptr) {
                // 执行任务
                task();
            }
            idleThreadSize_++;
            lastTime = std::chrono::high_resolution_clock().now();
        }
    }

	// 检查线程池的运行状态
	bool checkRunningState() const {
        return isPoolRunning_;
    }
private:
	

	// 线程相关
	// 线程列表。对于线程的创建，是在ThreadPool::start中new出来的，还需要delete
	// 因此直接使用智能指针。线程的话unique就行
	// std::vector<std::unique_ptr<Thread>> threads_;
	// 为了实现通过threadId_查询到对应的线程，这里最后使用了map
	std::unordered_map<int, std::unique_ptr<Thread>> threads_;

	size_t threadSizeThreshHold_;  // 线程数量的上限
	// 为什么新增一个变量而不是用threads_.size()呢，因为vector不是线程安全的
	std::atomic_int curThreadSize_;  // 记录当前线程池里面线程的总数量
	std::atomic_int idleThreadSize_;  // 记录空闲线程的数量
	int initThreadSize_;  // 初始的线程数量。size_t增强了可移植性，表示任何对象所能达到的最大长度
	
	// Task任务就是个函数对象
    using Task = std::function<void()>;
	std::queue<Task> taskQue_;  // 任务队列
	std::atomic_uint taskSize_;  // 任务的数量。考虑到线程安全问题，使用轻量化的原子类型实现线程互斥
	size_t taskQueMaxThreshHold_;  // 任务队列数量的上限

	// 实现线程通信
	std::mutex taskQueMtx_;  // 保证任务队列的线程安全
	std::condition_variable notEmpty_;  // 任务队列不空
	std::condition_variable notFull_;  // 任务队列不满
	std::condition_variable exitCond_;  // 等待线程资源全部回收

	PoolMode poolMode_;  // 当前线程池的工作模式

	std::atomic_bool isPoolRunning_;  // 表示当前线程池的启动状态
	
};


#endif // !THREADPOOL_H

```



# 服务器项目

> reference：https://github.com/Liluoquan/a-high-concurrency-webserver-in-linux
>
> 代码随想录webserver讲义
>
> 也可以参照https://github.com/linyacool/WebServer和https://github.com/qinguoyi/TinyWebServer和这个有视频的https://github.com/sylar-yin/sylar https://www.bilibili.com/video/av53602631/?from=www.sylar.top&vd_source=7dcf9f735236cc832d3f0a4c30b974f3

## 介绍

> https://github.com/Liluoquan/a-high-concurrency-webserver-in-linux/tree/master/WebServer

​	Linux 下开发的基于C++11标准的多线程 Web 服务器，在应用层实现了一个简单的HTTP服务器，支持多个客户端访问服务器的图片和视频等资源。

* 使用线程池、非阻塞socket、ET实现的epoll以及模拟Proactor（单Reactor多线程）的并发模型，并仿照Muduo网络库实现了主从Reactor的并发模型；
* 在应用层面实现心跳机制，通过小根堆实现的定时器关闭超时的非活跃连接；
* 使用状态机解析HTTP请求报文，支持解析GET请求，支持HTTP长连接与短连接。
* 使用双缓冲区技术实现了异步日志系统。

## 大体流程

> 实现在应用层

​	在浏览器中键入IP地址:端口号，浏览器根据提供的IP地址向服务器发送一个HTTP请求。这一过程首先要通过TCP协议的三次握手建立与 WebServer 的连接，然后将HTTP请求报文发送到服务器端。

​	服务器的框架采用的是主从Reactor的并发模型。每个Reactor中都有一个epoll实现的Poller和 poller监听的若干文件描述符及其事件封装的Channel。在主Reactor里循环检测监听的文件描述符，有连接事件到来就将channel分发给从Reactor，从Reactor检测通信的文件描述符，有事件发生就调用这个事件channel的事件处理函数：即读取数据，将HTTP报文采用有限状态机进行解析等。处理完之后返回给客户端响应报文，如文字图片视频等。

​	在应用层面实现心跳机制，通过定时器来清除不活跃的连接减少高并发场景下不必要的系统资源的占用【文件描述符的占用、维护一个TCP连接所需要的资源】。最后加入日志模块实现服务器日常运行情况的记录。

疑问一：如何派发？选择的依据是什么？

​	会将处理函数放到一个vector中，即一个等待执行函数区，然后执行wakeup函数，通过event_fd唤醒其他的subreactor。然后会执行loop函数，处理vector中待处理的函数。

疑问二：如何处理的读写事件？http_connection.cpp

​	调用read函数将数据读出到一个string中，然后解析请求行、请求头。如果解析请求头发现是Post，则继续解析请求体，即读content_length字段看请求体有多少字节的数据，然后读取。

这里读写的数据都存在HttpConnection中，每个channel都有个`std::weak_ptr<http::HttpConnection> holder_;`的指针

## 如何实现==高并发==

​	对于多个客户端访问服务器的场景，并不是每个客户端都由一个线程或进程进行业务处理，这样的话可能大量的client连接都堵塞在IO上，而服务端能建立的线程数是有限的，这样容易导致服务器的崩溃

* 首先使用了**IO多路复用**来同时检测多个文件描述符，这里使用了EPOLL，因为其支持更高效的ET边沿触发模式。通过IO多路复用，就可以在一个线程中监听多个文件描述符的读写IO事件，这样只需要堵塞一个线程就能进行多个文件描述符的监听。这里将文件描述符和对应的事件封装为channel类，将epoll封装为Poll类，一个Poll类中包含若干个channel类进行监听。
* 这里还用了非堵塞IO，即将socket设置为非堵塞，因为使用了ET边沿触发模式
* 对于工作线程，使用了线程池进行任务的分配及线程的维护。使用线程池的话可以避免线程频繁创建和销毁造成的开销、也便于对任务进行管理，比如设置优先级、通过任务队列缓冲任务等。
* 对于事件处理模式，第一版代码采用了**模拟Proactor**的事件处理模式，主线程进行文件描述符的监听及数据的读写，得到完整的HTTP请求后再唤醒线程池中的工作线程来执行HTTP请求的解析、HTTP响应报文的生成，与客户端的通信操作。对于工作线程来说，就模拟了一种异步的操作，即被唤醒时直接得到数据进行操作。但这个问题也很明显，就是所有的读写文件描述符的轮询以及读写操作全由这个主线程完成，变成了性能瓶颈
* 改进：模仿了muduo网络库中的Multi-Reactor并发框架，使用了主从Reactor模式，MainReactor负责检测监听的文件描述符及向SubReactor派发新连接，在SubReactor中对通信的文件描述符进行监听、处理读写等事件

![项目整体框架](E:\MarkDown\picture\主从Reactor模式.svg)

## 并发框架

> reference:《Linux多线程服务端编程》的第八章——Muduo网络库的设计与实现

核心：EventLoop类、Channel类、Poller类

![image-20230528151100044](E:\MarkDown\picture\image-20230528151100044.png)

<img src="E:\MarkDown\picture\image-20230528151136299.png" alt="image-20230528151136299" style="zoom:70%;" />

> 为什么分这么多类？
>
> 为了解耦，减少类之间的依赖关系，提高程序的可维护性和可扩展性

* **EventLoop**类是Reactor模式的核心，负责不断epoll_wait监听，然后调用fd对应的Channel的相应回调函数进行处理。其中主Reactor对监听的文件描述符进行检测，将通信的文件描述符派发给从Reactor
* 具体操作：
  * 类成员变量：shared_ptr 包装的 `Poller` 指针，包装了 epoll；int 型的`event_fd_` 用于进程间通信，用于异步唤醒 SubLoop 的 Loop 函数中的Poll (epoll_wait 因为还没有注册fd会一直阻塞)；shared_ptr 包装的 `Channel`，这是 event_fd 的 channel；线程ID；锁；`vector<Function>` 存放等待处理的函数；
  * mainReactor 向 subReactor 分配连接是轮询（从`vector<EventLoop*>`数组中），而主Reactor如何唤醒从Reactor？因为这些Reactor都是堵塞的，堵塞在epoll_wait上等待新事件的发生。这里通过**eventfd**实现
  * 初始化poller，event_fd，给event_fd设置事件以及读写操作的回调函数，并将event_fd注册到epoll中
    * 文件描述符有socket fd、pipe fd等很多种，而**eventfd**就是事件fd。[详解](https://zhuanlan.zhihu.com/p/393748176)
    * eventfd是一个专门用于事件通知的文件描述符，可以被用于一个事件的wait/notify，不仅可以用于进程间的通信，还能用于用户态和内核态的通信。eventfd 是一个计数相关的fd。计数不为零是有可读事件发生，`read` 之后计数会清零，`write` 则会递增计数器。（注意要设置为非堵塞
    * 这里的主要作用是当主Reactor获取一个新用户的channel，通过轮询算法选择一个从Reactor，**通过eventfd唤醒 从Reactor**。（即向eventfd中写入事件，就会唤醒注册有eventfd的从Reactor，使其解除堵塞）解除堵塞后，从Reactor就可以执行正在等待的函数，即处理连接套接字及其绑定事件的函数
  * 在EventLoop中进行事件的注册、修改、删除等操作。**EventLoop 并不直接管理各个连接的 Channel （文件描述符的封装），而是通过 Poller 来进行的。**
  * EventLoop 中最核心的函数就是 EventLoop::Loop()，开启while事件循环。
    * 调用Poller::poll()函数监听文件描述符：epoll_wait阻塞，等待就绪事件（没有注册其他fd时，可以通过event_fd来异步唤醒）
    * 处理每个就绪事件，即调用监听结果 `vector<shared_ptr<Channel>>` 中每一个Channel的处理函数channel->HandleEvents();每一个 Channel 的处理函数会根据 Channel 中封装的实际发生的事件，执行 Channel 中封装的各事件处理函数。
    * fd注册到epoll内核事件表
    * 处理超时事件，到期了就从定时器小根堆中删除





* 每个channel负责一个文件描述符的IO事件（EPOLLIN EPOLLOUT）分发，会把不同的IO事件分发为不同的回调，根据就绪的事件来分发

* Channel是对文件描述符及对应事件的封装，Channel类封装了Channel的文件描述符fd、Channel正在监听的事件（或者说感兴趣的事件）（如event_fd）、具体的已经发生的事件（由 Poller 给channel返回的具体发生的事件），以及各个事件（读、写、更新、错误）回调函数的 Function 对象。在channel中可以通过poller获取fd最终发生的具体的事件revents，因此由channel负责调用具体事件的回调。
* 总的来说，Channel 就是对 fd 事件的封装，包括注册它的事件以及回调。 EventLoop 通过调用 Channel::handleEvent() 来执行 Channel 的读写事件。 Channel::handleEvent() 的实现就是比较已经发生的事件（由 Poller 给channel设置就绪的事件），来调用对应的回调函数（读、写、错误）

同时Channel类还提供了设置该 fd 的感兴趣事件（要监听的文件描述符），以及将该fd及其感兴趣事件注册到事件监听器或从事件监听器上移除，以及保存了该 fd 的每种事件对应的处理函数





<img src="E:\MarkDown\picture\image-20230528194537091.png" alt="image-20230528194537091" style="zoom:80%;" />

* Poller类是对epoll的封装，单独抽象出一个类，也可以实现poll和select
* 内部维护一个epoll内核事件表，对其进行监听。成员变量包括epoll的文件描述符、【就绪事件的数组、对应的就绪fd的channel、对应的http连接对象】、定时器小顶堆等
* 作用就是负责监听文件描述符事件是否触发，并返回发生事件的文件描述符以及具体事件，同时包括注册新文件描述符、修改描述符状态、从epoll中删除描述符、添加定时器、处理超时等。所以一个 Poller 对象对应一个 IO 多路复用模块。在 muduo 中，一个 EventLoop 对应一个 Poller 。  
* 成员变量：

  * epoll_fd_：用 epoll_create 方法创建的 epoll 文件描述符
  * ready_events_：存放 epoll_wait() 返回的epoll_event类型的就绪事件的数组
  * ready_channels_：数组类型，存放shared_ptr包装的Channel，保管所有注册在这个 Poller 上的 Channel 。  
  * http_connections_：数组类型，存放shared_ptr包装的HttpConnection，保管连接对象
  * timer_heap_：定时器小顶堆



## 线程ID的获取

线程ID获取的两种方法：
1）gettid()函数
2）直接调用pthread_self()

pthread_self 是posix描述的线程ID（并非内核真正的线程id），相对于进程中各个线程之间的标识号，对于这个进程内是唯一的，而不同进程中，每个线程的 pthread_self() 可能返回是一样的。
而 gettid 获取的才是内核中线程ID

```cpp
// __thread: TLS线程局部存储 每个当前线程都有一个该变量的实例
extern __thread int tls_thread_id;              //线程id
extern __thread const char* tls_thread_name;    //线程名字

//得到线程id syscall 
inline int thread_id() {
    if (__builtin_expect(tls_thread_id == 0, 0)) {
        tls_thread_id = static_cast<pid_t>(::syscall(SYS_gettid)); // 调用了gettid
    }
    return tls_thread_id;
}
```

## ==日志==

> **同步日志**
>
> ​	同步日志是一种日志记录方式，它在写入日志时会**阻塞**当前操作，直到日志写入完成并确认。这意味着在写入日志时，程序或系统会暂停处理其他任务，日志直到写入操作完成。同步日志的主要特点包括：
>
> * 数据安全性高：由于读取操作阻塞，确保数据在写入日志后**立即持久化**，减少了数据丢失的可能性。
> * 较低的并发性能：因为每次读取日志都需要等待确认，所以对系统的并发性能造成一定的影响，特别是在高负载情况下。
>
> **异步日志**
>
> ​	在写入日志时不会阻止当前操作，而是将日志写入到屏幕或队列中，然后在**后台**异步地进行实际的日志持久化操作。这意味着读取日志的操作不会立即影响当前任务的执行。异步日志的主要特点包括：
>
> * **较低的读取延迟**：由于日志读取不会阻止当前操作，因此可以提高系统的响应速度和并发性能。
> * 数据丢失的风险：因为日志写入是在后台异步进行的，如果系统在写入日志之前崩溃，可能会导致部分日志丢失，从而降低数据的安全性。
> * 需要额外的处理逻辑：由于采用异步方式，可能需要引入额外的处理逻辑来处理日志写入的状态、错误恢复等。

​	磁盘I/O操作是很慢的。因此通常是工作线程把日志写在缓冲区队列里。然后专门有一个线程负责磁盘IO操作，即从缓冲区队列中取出日志信息，写入到磁盘中。这样就不会把磁盘IO的消耗计入到框架的业务处理过程中。

> 日志系统的运行机制：
>
> 1. **日志级别：** 定义不同的日志级别(enum类)
>    * **Debug：** 用于调试目的，记录详细的程序执行信息。
>    * **Info：** 记录一般的信息，例如服务器启动、请求处理完成等。
>    * **Warning：** 记录警告信息，表示可能出现问题但并不严重。
>    * **Error：** 记录错误信息，表示出现了一个可恢复的错误。
>    * **FATAL：** 记录严重错误，可能导致服务器崩溃或无法正常工作。
> 2. **日志格式：** 每条日志通常包括时间戳、日志级别、来源（如模块或文件名）、具体信息等内容。格式可以根据实际需求进行定义，常见的格式包括文本格式、JSON 格式等。
> 3. **日志输出：** 日志可以输出到不同的地方，如：
>    * **文件：** 将日志记录到文件中，通常每天生成一个新的日志文件，便于管理和分析。
>    * **控制台：** 在终端输出日志，用于调试和实时观察。
>    * **远程日志服务器：** 将日志发送到远程的日志服务器，集中存储和分析日志数据。
> 4. **多线程安全：** 在多线程环境中，需要确保多线程同时写入日志时不会造成竞态条件或数据错乱。可以使用互斥锁等机制来保证线程安全。

对于日志类，包含设置日志级别、写日志等成员函数。

![image-20230606165448781](E:\MarkDown\picture\image-20230606165448781.png)

kSmallBufferSize=4000

kLargeBufferSize = 4000 * 1000;

小buffer负责每个log message的复制，大buffer包括1000个小buffer，会进行buffer A buffer B间的复制

​	LogStream类主要是将各个类型的数据转化为char的形式放入buffer数组中，就是将日志写入每个4KB buffer的过程。(这里对左移运算符<<进行了重载，用于将int、浮点数、指针等各种类型转换为char类型写入。)其中FixedBuffer类是对char buffer_[buffer_size];进行了封装，其中这里的buffer_size = 4000

对于各种整形，都是转化为字符串类型

```cpp
//用于format int
static const char digits[] = "9876543210123456789";
static const char* zero = digits + 9;

template <typename T>
static size_t IntToString(char buffer[], T number) {
    char* buf = buffer;

    //从数字的个位开始 去每个字 将其转成char
    do {
        int index = static_cast<int>(number % 10);
        number /= 10;
        *buf++ = zero[index];
    } while (number != 0);

    //如果这个值是负数 就加上-号
    if (number < 0) {
        *buf++ = '-';
    }
    *buf = '\0';
    //前面是从个位开始往上算的 ，这里要反转过来(begin, end)
    std::reverse(buffer, buf);

    return buf - buffer; // size_t
}
```



对于浮点数，会通过`snprintf(buffer_.current_buffer(), kMaxNumberSize, "%.12g", number);`格式化输出字符串，将结果写入buffer_

g格式符用于输出浮点数，会自动选择f或e的格式输出，其中`%.12g`就是保留12位小数。



​	AsynLogging 类的作用则是将从前端获得的 Buffer A 放入 后端的 Buffer B 中，并且将 Buffer B 的内容最终写入到磁盘中（也就是整个后端所作的内容）。这个类中管理了一个日志线程来将buffer的内容写入文件，并维持了两个缓冲区（bufferA 和 B），减小前端等待的开销。还维持了一个缓冲区数组 vector<Buffer> ，实际写入文件的内容从缓冲区数组中取出。 

​	这个日志线程绑定了Worker() 函数，Worker() 线程函数中通过while(）循环不断的将 Buffer 数组中的数据写入到磁盘中。具体是将 vector<Buffer> 复制到内存中，然后遍历其中每个Buffer写到日志文件中

<img src="E:\MarkDown\picture\image-20230626124753544.png" alt="image-20230626124753544" style="zoom:60%;" />



## 长连接

​	这里的长连接，其实是tcp的长连接，就是进行一次数据传输后不立马关闭连接，而是直到一方不再传输数据后，经过一个超时时间后关闭连接。

​	长连接的优势在于，对于多次的HTTP请求（这些请求包括请求网页内容，CSS文件，JS文件，图片等等），其实使用的都是一个TCP连接，很显然是可以节省很多消耗的。

​	对于我们的服务器项目，在我们的http_connection.cpp中，如果收到的url中Connection为keep-alive 则超时时间就设为5分钟，否则就是5秒。这里超时时间是定时器的，每隔超时时间就对连接进行检测。

​	压测时，长连接QPS是5w，短连接1.2w。（具体操作就是在url中加入Keepalive选项）。显然长连接的QPS更高，因为每隔5min才会判断是否要断开连接，没有了连接建立和断开的开销，不需要频繁accept和shutdown\close等系统调用，也不需要频繁建立和销毁对应的结构体。	

## Socket

​	socket套接字是一种进程间通信的方式，支持网络上两台以上的设备进行通信。可以当作文件描述符来使用

​	socket网络编程是在linux等unix系统中实现TCP、UDP协议，核心是 `socket` 函数，用于创建一个套接字，这个函数通过传入的参数指定是ipv4和tcp/udp协议，返回的是监听/传输数据的文件描述符。其他还有 `bind` 函数将文件描述符绑定到IP和端口，其中会使用sockaddr_in的数据结构保存ip地址和端口号，这里还用到了htons htonl将小端的主机序转为网络序。`listen `函数给监听的套接字设置监听、`accept` 函数接收客户端的连接请求，会检测监听文件描述符的读缓冲区，有数据后就会解除堵塞，返回一个通信的文件描述符。还有接收和发送数据的 `read recv write send` 等，堵塞到读写缓冲区有数据。

> 大端小端

主机字节序是小端。`低位字节`存储在内存的`低地址位`

网络字节序是大端。反过来

> socket提供的对IP和端口进行大小端转换的函数

```cpp
#include <arpa/inet.h>
// u:unsigned
// 16: 16位, 32:32位
// h: host, 主机字节序
// n: net, 网络字节序
// s: short
// l: int

// 这套api主要用于 网络通信过程中 IP 和 端口 的 转换
// 将一个短整形（port）从主机字节序 -> 网络字节序
uint16_t htons(uint16_t hostshort);	
// 将一个整形（ip）从主机字节序 -> 网络字节序
uint32_t htonl(uint32_t hostlong);	

// 将一个短整形从网络字节序 -> 主机字节序
uint16_t ntohs(uint16_t netshort)
// 将一个整形从网络字节序 -> 主机字节序
uint32_t ntohl(uint32_t netlong);
```



> 介绍一下 Socket 的 API

  套接字相关的函数被包含在头文件 sys/socket.h 中

<img src="E:\MarkDown\picture\image-20230626193121340.png" alt="image-20230626193121340" style="zoom:67%;" />

```cpp
int main()
{
    // 1. 创建用于监听的套接字
    // SOCK_STREAM TCP   AF_INET ipv4
    int fd = socket(AF_INET, SOCK_STREAM, 0);

    // socket地址的数据接口
    struct sockaddr_in addr;
    addr.sin_family = AF_INET;          // 地址族协议为ipv4
    addr.sin_port = htons(8989);        // 端口，转网络字节序
    // INADDR_ANY代表本机的所有IP, 假设有三个网卡就有三个IP地址
    addr.sin_addr.s_addr = INADDR_ANY; // == 0, 获取IP的操作交给了内核
    
    // 2. 将套接字的文件描述符与ip和端口号绑定
    int ret = bind(fd, (struct sockaddr*)&addr, sizeof(addr));

    // 3. 设置监听
    // 这个100 是同时能处理的最大连接要求
    ret = listen(fd, 100);

    // 4. 等待接受连接请求，传出参数cliaddr存储了建立连接的客户端的地址信息
    // accept函数会检测监听文件描述符的读缓冲区。有数据后就会解除堵塞，返回一个通信的文件描述符
    struct sockaddr_in cliaddr;
    int clilen = sizeof(cliaddr);
    int cfd = accept(lfd, (struct sockaddr*)&cliaddr, &clilen);

    // 打印客户端的地址信息
    char ip[24] = {0};
    printf("客户端的IP地址: %s, 端口: %d\n",
           inet_ntop(AF_INET, &cliaddr.sin_addr.s_addr, ip, sizeof(ip)),
           ntohs(cliaddr.sin_port));

    // 5. 和客户端通信
    while(1)
    {
        char buf[1024];
        memset(buf, 0, sizeof(buf));
        
        // 6. 接收数据 read / recv
        // 数据如何进入到内核程序猿不需要处理，数据进入到通信的文件描述符的读缓冲区中
        // read将数据从通信的文件描述符的读缓冲区中读出
        int len = read(cfd, buf, sizeof(buf));
        if(len > 0)
        {
            printf("客户端say: %s\n", buf);
            // 7. 发送数据 write send
            // 将数据写入到通信的文件描述符对应的写缓冲区中
            // 内核检测到通信的文件描述符写缓冲区中有数据，会将数据发送到网络中
            write(cfd, buf, len);
        }
    }

    close(cfd);
    close(lfd);

    return 0;
}
```



## TCP套接字

> setsockopt(fd, SOL_SOCKET, SO_REUSEADDR,xxx, xxx)

### **端口复用 SO_REUSEADDR**

​	实现在linux下多个进程**监听**同一个端口

​	在http中需要进行端口复用，因为可能有多个客户端连接到服务端的这个端口上。通常是将监听的socket设置为端口复用

```cpp
// 端口复用
int reuse = 1;
// SOL_SOCKET:通用套接字选项；SO_REUSEADDR：允许重用本地地址和端口
setsockopt( m_sockfd, SOL_SOCKET, SO_REUSEADDR, &reuse, sizeof( reuse ) );
```

### 优雅关闭SO_LINGER

​	设置函数close()关闭TCP连接时的行为。缺省close()的行为是，如果有数据残留在socket发送缓冲区中则系统将继续发送这些数据给对方，等待被确认，然后返回。

​	这里将l_onoff和l_linger都设置为非0：将连接的关闭设置一个超时，如果socket发送缓冲区中仍残留数据，进程进入睡眠，内核进入定时状态去尽量去发送这些数据。在超时之前，如果所有数据都发送完且被对方确认，内核用正常的FIN|ACK|FIN|ACK四次挥手来关闭该连接，close()成功返回。如果超时之时，数据仍然未能成功发送及被确认，立即关闭该连接，通过发送RST分组来关闭该连接。至于发送缓冲区中如果有未发送完的数据，则丢弃。主动关闭一方的TCP状态则跳过TIMEWAIT，直接进入CLOSED。close()返回EWOULDBLOCK。

```cpp
//优雅关闭套接字 也就是套接字在close的时候是否等待缓冲区发送完成
void SetSocketNoLinger(int fd) {
    struct linger linger_struct;
    linger_struct.l_onoff = 1;
    linger_struct.l_linger = 30;
    setsockopt(fd, SOL_SOCKET, SO_LINGER, (const char*)&linger_struct, sizeof(linger_struct));
}
```



### SO_RCVBUF、SO_SNDBUF

调整接收、发送的缓冲区的大小

太大也不好，要将数据先放到缓冲区，会有个延迟





## 部署

部署在了云服务器上

> 网络IO是网卡与内存之间的输入输出
>
> 当网络上的数据到来时，网卡需要将数据拷贝到内存中。当要发送数据给网络上的其他人时，需要将数据从内存拷贝到网卡里。

## linux上的五种IO模型

<img src="E:\MarkDown\picture\image-20230407231627857.png" alt="image-20230407231627857" style="zoom: 70%;" />

<img src="E:\MarkDown\picture\image-20230407232016648.png" alt="image-20230407232016648" style="zoom:67%;" />

比如将文件描述符设置为非堵塞

<img src="E:\MarkDown\picture\image-20230407232456806.png" alt="image-20230407232456806" style="zoom:67%;" />

IO复用不是用于处理高并发的，主要是用于同时检测多个IO操作。想要实现高并发，需要多线程或多进程

<img src="E:\MarkDown\picture\image-20230407233216112.png" alt="image-20230407233216112" style="zoom:67%;" />

<img src="E:\MarkDown\picture\image-20230407233456227.png" alt="image-20230407233456227" style="zoom:67%;" />

## 同步IO和异步IO的区别

> 当请求被阻塞，就是同步IO，否则就是异步IO

比如要读一个数据，就分等待数据和数据从内核空间拷贝到用户空间两步。

* 等待数据的话，比如IO多路复用，会堵塞在epoll_wait上，而信号驱动的IO，可以在数据准备好时直接执行信号处理函数，就能实现异步；
* 数据从内核空间拷贝到用户空间，比如read操作，同步IO都会堵塞在这里直到数据读完，而异步IO就可以在数据拷贝完后再通知应用程序，应用程序就相当于直接得到了这个数据。

<img src="E:\MarkDown\picture\image-20230606205011234.png" alt="image-20230606205011234" style="zoom:67%;" />

<img src="E:\MarkDown\picture\image-20230606205307091.png" alt="image-20230606205307091" style="zoom:67%;" />

## 框架

![image-20230408000428775](E:\MarkDown\picture\image-20230408000428775.png)

![image-20230408093848872](E:\MarkDown\picture\image-20230408093848872.png)



## **==事件处理模式==**/采用的线程模型

> reference:https://mp.weixin.qq.com/s/m53_V0Q2fOYPbofxq8sHhQ
>
> 主要有三类线程模型：
>
> 1. **阻塞 I/O 模型（Blocking I/O Model）**：为每一个请求分配一个线程。当一个线程执行一个 I/O 操作时，它会一直等待，直到 I/O 操作完成并返回结果。在这个过程中，该线程会被阻塞，无法执行其他任务。并且请求增多的话会创建大量线程
>
> 2. **Reactor 模型**：IO多路复用 + 线程池
>    两个关键组成：
>    
>    * Reactor：负责监听和分发事件，分发给适当的 Handler 来对 IO 事件做出反应
>    * Handler：处理程序执行 I/O 事件要完成的实际任务
>    
>    三种经典实现：
>    
>    * 单 Reactor 单线程
>    
>    * 单 Reactor 多线程：一个reactor监听并分配任务，handler读取数据，线程池做业务处理
>    
>    * 主从 Reactor 多线程：Reactor 在单线程中运行，高并发场景下容易成为性能瓶颈
>    
>      * Reactor 主线程（MainReactor）通过 `select` 监控**建立连接**事件，即监听的文件描述符，收到事件后通过 Acceptor 接收，处理建立连接事件
>      * Acceptor 处理建立连接事件后，MainReactor 将连接分配给 Reactor 子线程（SubReactor）进行处理
>      * SubReactor 将**通信的文件描述符**加入 select 进行监听，并创建一个 Handler 用于处理该连接的响应事件
>      * 当有新的事件发生时，SubReactor 会调用连接对应的 Handler 进行响应
>      * Handler 通过 read 读取数据后，会分发给后面的 Worker 线程池进行业务处理
>      * Worker 线程池会分配独立的线程完成真正的业务处理，如何将响应结果发给 Handler 进行处理
>      * Handler 收到响应结果后通过 send 将响应结果返回给 Client
>    
>      ![图片](E:\MarkDown\picture\640.png)
>    
> 4. **Proactor 模型**



<img src="E:\MarkDown\picture\image-20230408094133230.png" alt="image-20230408094133230" style="zoom: 60%;" />
<img src="E:\MarkDown\picture\image-20230408095747109.png" alt="image-20230408095747109" style="zoom:50%;" />

<img src="E:\MarkDown\picture\image-20230408095927260.png" alt="image-20230408095927260" style="zoom:67%;" />

<img src="E:\MarkDown\picture\image-20230408100125620.png" alt="image-20230408100125620" style="zoom:67%;" />

<img src="E:\MarkDown\picture\image-20230409142237329.png" alt="image-20230409142237329" style="zoom:67%;" />



**在我们的项目中，是用同步IO模拟Proactor模式**

原理：主线程执行数据读写操作，读写完成后主线程向工作线程通知这一“完成事件”，那么从工作线程的角度来看，工作线程就获得了数据读写的结果，只要对这些读写结果做逻辑处理（即业务逻辑）

* 主线程往 epoll 内核事件表中注册socket上的读就绪事件
* 主线程调用epoll_wait等待socket上有数据可读
* 当socket上有数据可读时，epoll_wait通知主线程，主线程从socket循环去读数据，直到没有数据可读，然后将读取到的数据封装成一个任务对象，放入到线程池中
* 在线程池中，若有空闲线程，则执行这个任务：通过状态机解析读到的HTTP请求，然后根据结果生成响应。然后往epoll内核事件表中注册socket上的写就绪事件
* 主线程调用epoll_wait等待socket可写
* 当socket可写时，epoll_wait通知主线程。主线程往socket上写入服务器处理客户请求的结果



<img src="E:\MarkDown\picture\image-20230413194931086.png" alt="image-20230413194931086" style="zoom:57%;" />



> 为什么没用proactor模式

​	在Linux下的异步I/O是不完善的，aio 系列函数是由POSIX定义的异步操作接口，不是真正的操作系统级别支持的，而是在用户空间模拟出来的异步，并且仅仅支持基于本地文件的 aio 异步操作，网络编程中的socket是不支持的，也有考虑过使用模拟的proactor模式来开发，但是这样需要浪费一个线程专门负责I0的处理。
​	而Windows里实现了一套完整的支持socket的异步编程接口，这套接口就是 IOCP，是由操作系统级别实现的异步I/O，真正意义上异步I/O，因此在 Windows 里实现高性能网络程序可以使用效率更高的 Proactor 方案。

## IO多路复用

> IO多路复用是异步还是**同步**？

​	在同步编程中，程序会在请求某个操作（如读取文件或网络数据）时阻塞，直到操作完成并返回结果，然后继续执行后续的代码。这种方式在一些情况下可能导致程序在等待 I/O 操作完成时出现阻塞，造成资源浪费。

​	**I/O 多路复用是一种用于处理多个 I/O 事件的技术，它通过一个系统调用来监视多个 I/O 句柄（如文件描述符、套接字）的状态，然后在有可用数据时通知应用程序。**

​	虽然 I/O 多路复用可以让程序在等待多个 I/O 事件时不必阻塞在单个 I/O 上，但它仍然是同步的，因为它需要程序通过系统调用来主动查询 I/O 句柄的状态，而不是在事件完成时自动异步通知。是一种同步的编程模型。

* epoll 是同步的，epoll_wait就是堵塞的，同步的
* 而底层用了 epoll 的封装后的框架，可以是异步的，只要你暴露给外部的接口，无需等待你的返回值即可。




​	与之相比，异步编程模型允许程序在发起一个 I/O 请求后，可以继续执行其他任务，而不需要等待 I/O 操作完成。当 I/O 操作完成时，系统会通知应用程序，然后执行相应的回调函数。

> 介绍一下IO多路复用，和之前的方法相比有什么优点

​	**进程可以通过一个系统调用函数从内核中获取多个事件**。当某条连接有新的数据可以处理时，操作系统通知应用程序，线程从阻塞状态返回，开始进行业务处理

​	IO多路复用可以同时监测多个文件描述符并且这个过程是阻塞的。在获取事件时，先把所有连接（文件描述符）传给内核，再由内核返回产生了事件的连接，然后在用户态中再处理这些连接对应的请求即可。一旦检测到有文件描述符就绪（可以读数据或者可以写数据），程序的阻塞就会被解除，之后就可以基于这些（一个或多个）就绪的文件描述符进行通信了。通过这种方式在单线程 / 进程的场景下也可以在服务器端实现并发。常见的 IO 多路转接方式有：select、poll、epoll。

下面先对多线程 / 多进程并发和 IO 多路转接的并发处理流程进行对比（服务器端）：

* 多线程 / 多进程并发
  * 主线程 / 父进程：调用 accept() 监测客户端连接请求
    * 如果没有新的客户端的连接请求，当前线程 / 进程会阻塞
    * 如果有新的客户端连接请求解除阻塞，建立连接
  * 子线程 / 子进程：和建立连接的客户端通信
    * 调用 read() / recv() 接收客户端发送的通信数据，如果没有通信数据，当前线程 / 进程会阻塞，数据到达之后阻塞自动解除
    * 调用 write() / send() 给客户端发送数据，如果写缓冲区已满，当前线程 / 进程会阻塞，否则将待发送数据写入写缓冲区中
* IO 多路转接并发
  * 使用 IO 多路转接函数委托内核检测服务器端所有的文件描述符，这个检测过程会导致线程的阻塞，如果检测到已就绪的文件描述符则阻塞解除，并将这些已就绪的文件描述符传出
  * 根据类型对传出的所有已就绪文件描述符进行判断，并做出不同的处理
    * 监听的文件描述符：和客户端建立连接。此时调用 accept() 是不会导致程序阻塞的，因为监听的文件描述符是已就绪的（有新请求）
    * 通信的文件描述符：调用通信函数和已建立连接的客户端通信。此时调用 read() / write() 不会阻塞程序，因为通信的文件描述符是就绪的，读缓冲区内已有数据 / 写缓冲区不满，可以往里面写数据
    * 对这些文件描述符继续进行下一轮的检测

**与多进程和多线程技术相比，I/O 多路复用技术的最大优势是系统开销小，系统不必创建进程 / 线程，也不必维护这些进程 / 线程，从而大大减小了系统的开销。**

### select poll epoll

> epoll全称eventpoll
>
> 说一下为什么用epoll，还有其他复用方式吗？区别是什么？

* 对于待检测集合select和poll是基于线性方式处理的，每次都会线性扫描整个待检测集合，来知道哪些文件描述符是就绪的，时间复杂度O(n)；
  epoll是基于红黑树来管理待检测集合的，用红黑树存储epoll_ctl传来的fd，并通过链表来存储准备就绪的事件，当某个 socket 有事件发生时，通过**回调函数**内核会将其加入到这个就绪事件链表中，epoll_wait调用时，仅观察这个list链表里有没有数据即可，无需再次检测。
* epoll底层是红黑树，poll是链表，都没有最大文件描述符的限制，仅受系统中进程能打开的最大文件数目限制；而 select 一般是 1024。
* select和poll都只能工作在相对低效的LT模式；epoll则可以工作在ET高效模式，并且epoll还支持EPOLLONESHOT事件，该事件能进一步减少可读、可写和异常事件被触发的次数。
* 在 `epoll` 使用中，主要的数据拷贝通常发生在两个地方：
  1. **注册事件时的数据拷贝：** 在用户态调用 `epoll_ctl` 函数来注册要监听的文件描述符和事件时，需要将这些信息传递给内核。这就涉及到将用户空间中的事件数据拷贝到内核空间，以便内核可以识别和管理这些事件。这个拷贝通常只在注册时进行一次。
  2. **等待事件时的数据拷贝：** 在用户态调用 `epoll_wait` 函数等待事件时，内核需要将已经准备就绪的事件信息传递回用户空间，以便应用程序可以处理这些事件。这就涉及到将内核空间中的事件数据拷贝到用户空间，以供应用程序使用。这个拷贝会在每次调用 `epoll_wait` 时发生。
* 应用场景
  * 当所有的fd都是活跃连接，使用epoll需要建立红黑树和链表，效率反而不高，不如selece和poll
  * 当监测的fd数目较小，且各个fd都比较活跃，建议使用select或者poll
  * 当监测的fd数目非常大，成千上万，且单位时间只有其中的一部分fd处于就绪状态，这个时候使用epoll能够明显提升性能

### epoll的工作模式：ET和LT

> * LT 水平触发模式
>   
>   ​	是缺省的工作方式，并且同时支持 block 和 no-block socket。内核通知使用者哪些文件描述符已经就绪，之后就可以对这些已就绪的文件描述符进行 IO 操作了。只要仍然有未处理的事件，epoll就会通知你，调用epoll_wait就会立即返回。
>   ​	例如对于读事件，如果文件描述符对应的读缓冲区还有数据，读事件就会不断的被触发，epoll_wait() 解除阻塞。
>   
> * ET 边沿触发模式
>   
>   ​	ET是高速工作方式，只支持**no-block socket**。在这种模式下，当文件描述符从未就绪变为就绪时，内核会通过epoll通知使用者，并且**不会再为那个文件描述符发送更多的就绪通知**。ET模式在很大程度上减少了epoll事件被重复触发的次数，因此效率要比LT模式高。（需要通过**EPOLLET**设置）
>   ​	如对于读事件，当读缓冲区有新的数据进入，读事件被触发一次，没有新数据不会触发该事件，因此必须要一次性将数据全部从读缓冲区中读出，使用非阻塞I/O，读取到出现 EAGAIN 

本项目采用的监听的文件描述符和管道都为边缘触发模式ET



> 为什么ET模式要设置为非堵塞的socket呢？

​	因为ET模式只通知一次，为了保证数据的全部读出，采用循环读的方式。注意套接字操作默认是阻塞的，当读缓冲区数据被读完之后，读操作就阻塞了，当前线程被阻塞之后就无法处理其他操作了。要解决阻塞问题，就需要**将套接字修改为非阻塞**，需要使用 fcntl() 函数进行处理：

```c++
// 设置完成之后, 读写都变成了非阻塞模式
int flag = fcntl(cfd, F_GETFL);
flag |= O_NONBLOCK;                                                        
fcntl(cfd, F_SETFL, flag);
```

​	但是，这样就会引发另外的一个 bug，在非阻塞模式下，循环地将读缓冲区数据读到本地内存中，当缓冲区数据被读完了，调用的 read()/recv() 函数还会继续从缓冲区中读数据，此时函数调用就失败了，返回 - 1，对应的**全局变量 errno 值为 EAGAIN 或者 EWOULDBLOCK** ,如果打印错误信息会得到如下的信息：Resource temporarily unavailable
​	因此在读到recv()的返回值为-1时，如果errno为EAGAIN || EWOULDBLOCK时表示没有数据了，就说明已经读到完整的数据了，此时执行提交任务到线程池的操作

### epoll事件

#### EPOLLIN EPOLLOUT

有事件来/往外写

#### EPOLLHUP EPOLLRDHUP EPOLLERR

挂起、对端断开连接、epoll读写出错

#### EPOLLONESHOT事件

​	即使可以使用ET模式，一个socket上的某个事件还是可能被触发多次。这在并发程序中就会引起一个问题。比如一个线程在读完某个socket上的数据后开始处理这些数据，而在数据的处理过程中该socket上又有新数据可读(EPOLIN再次被触发)，此时另外一个线程被唤醒来读取这些新的数据。于是就出现了**两个线程同时操作一个socket的局面**。想要实现一个socket连接在任一时刻都只被一个线程处理，可以使用epoll的EPOLLONESHOT事件实现。将文件描述符设置为**EPOLLONESHOT**
​	对于注册了EPOLLONESHOT事件的文件描述符，操作系统最多触发其上注册的一个可读、可写或者异常事件，且只触发一次，除非我们使用epoll_ctl 函数重置该文件描述符上注册的EPOLLONESHOT事件。这样，当一个线程在处理某个socket时，其他线程是不可能有机会操作该socket的。但反过来思考，**注册了EPOLLONESHOT事件的socket一旦被某个线程处理完毕，该线程就应该立即重置这个socket上的EPOLLONESHOT事件，以确保这个socket下一次可读时，其EPOLLIN事件能被触发，进而让其他工作线程有机会继续处理这个socket。**

#### EPOLLRDHUP事件

​	可以通过增加EPOLLRDHUP来得知客户端是否关闭socket连接。将文件描述符的事件增加上EPOLLRDHUP后，当对端关闭连接时，recv函数会返回0，此时就可以通过对recv的返回值进行判断来处理不同的情况

​	在我们这个程序中，删掉EPOLLRDHUP这个也没有什么影响

```cpp
// 因为用了oneshot，所以每一次都需要重新去添加这个事件，即在为这次请求生成响应发送过去关闭连接后，再重新添加上这个文件描述符，继续监听有没有其他请求。
modfd(m_epollfd, m_sockfd, EPOLLOUT);  // 重新监听是否可以写数据

// 修改文件描述符，重置socket上的EPOLLONESHOT事件，以确保下一次可读时，EPOLLIN事件能被触发
void modfd(int epollfd, int fd, int ev) {
    epoll_event event;
    event.data.fd = fd;
    event.events = ev | EPOLLET | EPOLLONESHOT | EPOLLRDHUP;
    epoll_ctl( epollfd, EPOLL_CTL_MOD, fd, &event );
}
```

​	明明是对方断开请求，系统却报告一个查询失败的错误，但从用户角度来看请求的结果正常返回，没有任何问题。

​	在使用 epoll 时，对端正常断开连接（调用 close()），在服务器端会触发一个 epoll 事件。在低于 2.6.17 版本的内核中，这个 epoll 事件一般是 EPOLLIN，即 0x1，代表连接可读。	连接池检测到某个连接发生 EPOLLIN 事件且没有错误后，会认为有请求到来，将连接交给上层进行处理。这样一来，上层尝试在对端已经 close() 的连接上读取请求，只能读到 EOF，会认为发生异常，报告一个错误。
​	2.6.17 版本内核中增加了 EPOLLRDHUP 事件，代表对端断开连接。在使用 2.6.17 之后版本内核的服务器系统中，对端连接断开触发的 epoll 事件会包含 EPOLLIN | EPOLLRDHUP，即 0x2001。有了这个事件，对端断开连接的异常就可以在底层进行处理了，不用再移交到上层。

重现这个现象的方法很简单，首先 telnet 到 server，然后什么都不做直接退出，查看在不同系统中触发的事件码。

## 异步事件的惊群现象

> ​	一个 server 有很多其他网络 IO 事件要处理，我们并不希望 server 阻塞在 accept 调用上，为提高服务器的并发处理能力，我们一般会使用 select/poll/epoll I/O 多路复用技术，同时为了充分利用多核 CPU，服务器上会起多个进程(线程)同时提供服务。于是，在某一时刻多个进程(线程)阻塞在 select/poll/epoll_wait 系统调用上，**当一个请求上来的时候，多个进程都会被 select/poll/epoll_wait 唤醒去 accept，然而只有一个进程(线程 accept 成功**，其他进程(线程 accept 失败，然后重新阻塞在 select/poll/epoll_wait 系统调用上。可见，尽管 accept 不存在"惊群"，但是我们还是没能摆脱"惊群"的命运。难道真的没办法了么？我只让一个进程去监听 listen socket 的可读事件，这样不就可以避免"惊群"了么？
>
> ​	要注意，LT模式会存在惊群问题，而ET模式是没有的。在一个 epoll 上睡眠的多个 task，如果在一个 LT 模式下的 fd 的事件上来，会唤醒 epoll 睡眠队列上的所有 task，而 ET 模式下，仅仅唤醒一个 task，这是 epoll"惊群"的根源。

如何解决惊群现象：

1、监听的socket只放在一个进程中处理，但连接量比较大的话这个线程的负担会比较大。如这个HTTP服务器就是采用master/worker线程模式，即只让其中一个线程（master线程）在epoll_wait监听socket,当有新的连接请求进来之后，由epoll_wait的线程调用accept，建立新的连接，然后交给其他线程（worker线程）处理后续的数据读写请求，这样就可以避免了由于多线程环境下的epoll_wait惊群效应问题。

2、分担出去，但一个时刻只有一个epoll管理监听。在不同的epoll中轮询（没懂）

3、nginx的解决思路：在同一时刻，永远都只有一个子进程在监听的socket上epoll_wait，其做法是，创建一个全局的pthread_mutex_t，在子进程进行epoll_wait前，则先获取锁。

## ==有限状态机==

> 有限状态机是什么？为什么要用？

​	有限状态机（FSM）是一种数学模型和计算机科学中的概念，用于描述对象的不同状态以及在不同状态之间转换的规则。FSM 是一种抽象的计算模型，广泛应用于编程、软件设计、自动控制等领域。

FSM 包含以下基本要素：

1. **状态（State）：**系统或对象可以处于不同的状态。每个状态代表对象的一个特定条件或状态。例如，在一个自动售货机中，可能有“待机”状态、"售出" 状态等。
2. **转移（Transition）：**转移表示状态之间的变换。转移发生的条件可以是输入事件、条件达成等。转移从一个状态导向另一个状态，表示对象在不同状态之间的切换。
3. **事件（Event）：**事件是触发状态转移的触发器。当特定事件发生时，系统可以根据当前状态和定义的规则进行状态转移。
4. **动作（Action）：**动作是与状态转移关联的操作。在状态转移发生时，可以执行特定的动作，例如输出消息、调用函数等。

​	**在编程中，使用有限状态机（FSM）可以将复杂的逻辑分解为多个状态和转移，使代码更加清晰和易于理解。**FSM 在编写编译器、解析器、游戏 AI、网络协议等方面有广泛的应用。状态机的设计和使用需要考虑合适的状态、转移、事件和动作，以及正确处理状态之间的关系和转移规则。

​	在我们的项目中：主状态机先解析请求方法，然后根据是正在分析请求行、头部字段还是请求体分别调用从状态机进行处理。从状态机将处理状态和数据传给主状态机。
​	在HTTP类中，我们定义了很多enum类型的状态，如HTTP请求方法、解析客户端请求时主状态机的状态、从状态机的状态等。服务器通过while循环内的这个switch...case，实现状态之间的相互转移，可以根据不同状态或者消息类型进行相应的处理逻辑，使得程序逻辑清晰易懂。

```c++
// 状态机，定义了一些状态
// 1、HTTP请求方法，这里只支持GET
enum METHOD {GET = 0, POST, HEAD, PUT, DELETE, TRACE, OPTIONS, CONNECT};

/*
    2、解析客户端请求时，主状态机的状态
    CHECK_STATE_REQUESTLINE:当前正在分析请求行
    CHECK_STATE_HEADER:当前正在分析头部字段
    CHECK_STATE_CONTENT:当前正在解析请求体
*/
enum CHECK_STATE { CHECK_STATE_REQUESTLINE = 0, CHECK_STATE_HEADER, CHECK_STATE_CONTENT };


// 3、从状态机的三种可能状态，即行的读取状态，分别表示
// 1.读取到一个完整的行 2.行出错 3.行数据尚且不完整
enum LINE_STATUS { LINE_OK = 0, LINE_BAD, LINE_OPEN };

/*
    服务器处理HTTP请求的可能结果，报文解析的结果
    NO_REQUEST          :   请求不完整，需要继续读取客户数据
    GET_REQUEST         :   表示获得了一个完成的客户请求
    BAD_REQUEST         :   表示客户请求语法错误
    NO_RESOURCE         :   表示服务器没有资源
    FORBIDDEN_REQUEST   :   表示客户对资源没有足够的访问权限
    FILE_REQUEST        :   文件请求,获取文件成功
    INTERNAL_ERROR      :   表示服务器内部错误
    CLOSED_CONNECTION   :   表示客户端已经关闭连接了
*/
enum HTTP_CODE { NO_REQUEST, GET_REQUEST, BAD_REQUEST, NO_RESOURCE, FORBIDDEN_REQUEST, FILE_REQUEST, INTERNAL_ERROR, CLOSED_CONNECTION };
```

<img src="E:\MarkDown\picture\image-20230408154513324.png" alt="image-20230408154513324" style="zoom:50%;" />



<img src="E:\MarkDown\picture\image-20230829093921383.png" alt="image-20230829093921383" style="zoom:50%;" />

解析每一行：每行的结束都会有个\r和\n，回车符和换行符

http报文怎么检测头部和包体的间隔：每个响应头部都是以回车符和换行符结束。当一个响应头部结束，检测到下一个数据是空行\0时，说明空行后为响应包体

怎么检测包体/消息体的结束：在头部有一个content-length，然后你收内容为这个长度即可



> 状态机的转移图

![image-20230829100447857](E:\MarkDown\picture\image-20230829100447857.png)

## ==定时器==

> Linux下提供的定时的方法:

* socket套接字选项
  
  ​	SO_RECVTIMEO 和 SO_SNDTIMEO分别是socket接收和发送数据的超时时间，仅对send、sendmsg、recv、recvmsg、accpet和connect有效，超时后返回-1，设置errno为EGAIN或EWOULDBLOCK。
  使用场景：比如，一般情况下，调用accept/connect/send/recv, 进程会阻塞，但是如果对端异常，进行可能无法正常退出等待。因此可以通过超时时间来让这些调用自动定时退出
  
  ```cpp
  struct timeval timeout;  // 高精度的一个时间类
  // tv_sec成员为秒，tv_usec为微秒
  timeout.tv_sec = time;
  timeout.tv_usec = 0;
  setsockopt(sockfd, SOL_SOCKET, SO_SNDTIMEO, &timeout, sizeof(timeout));
  ```
  
* **SIGALRM信号**（webserver

  ​	定时器信号，默认终止进程。但以秒为单位，精度有点粗

  ​	其中在HTTP服务器项目里就用到了SIGALRM信号，在定时器部分通过alarm函数设置信号传送闹钟，即用来设置信号SIGALRM在经过参数seconds秒数后发送给目前的进程。如果未设置信号SIGALARM的处理函数，那么alarm()默认处理终止进程。

  ```cpp
  // webserver
  // 对SIGALRM设置信号处理函数
  addsig(SIGALRM, sig_handler);
  
  // 信号处理函数，将信号发送到了一个管道当中
  void sig_handler( int sig )
  {
      int save_errno = errno;
      int msg = sig;
      send( pipefd[1], ( char* )&msg, 1, 0 );
      errno = save_errno;
  }
  
  // 添加信号捕捉
  void addsig(int sig, void(handler)(int)){
      struct sigaction sa;
      memset(&sa, '\0', sizeof(sa) );  // 将sa的数据清空
      sa.sa_handler = handler;
      sigfillset(&sa.sa_mask);  // 设置临时阻塞信号集
      assert(sigaction(sig, &sa, NULL) != -1);
  }
  
  
  // mywebserver中也是通过sigaction函数设置闹钟信号处理函数
  struct sigaction signal_action;
  signal_action.sa_handler = AlarmHandler;
  signal_action.sa_flags = 0;
  // sigaction函数，成功返回0
  // 参数1：要捕获的信号 参数2：接收到信号之后对信号进行处理的结构体
  if (sigaction(SIGALRM, &signal_action, NULL)) {
      exit(1);
  }
  alarm(request_time);  // request_time=30
  ```

* I/O复用系统调用的超时参数

> 为什么要用定时器

​	高并发的服务器通常会面临的一个问题就是有大量的连接建立，但是实际活跃的连接并不多，由于非活跃连接占用了连接资源，严重影响服务器的性能，通过实现一个服务器定时器，处理这种非活跃连接，释放连接资源。

> unsigned int alarm(unsigned int seconds); // 设置定时器(闹钟)。

​	**利用 alarm 函数周期性地触发 SIGALRM 信号**，该信号的信号处理函数利用管道通知主循环，**主循环**接收到该信号后对升序链表上的定时器进行处理。若该段时间内没有交换数据，则将该连接关闭，释放所占用的资源。
​	信号处理函数仅仅发送信号通知程序主循环，将信号对应的处理逻辑放在程序主循环中，由主循环执行信号对应的逻辑代码。具体的，信号处理函数使用管道将信号传递给主循环，信号处理函数往管道的写端写入信号值，主循环则从管道的读端读出信号值。使用I/O复用系统调用来监听管道读端的可读事件，这样信号事件与其他文件描述符都可以通过epoll来监测，从而实现统一处理。

```c++
// webserver
alarm(TIMESLOT);

// 对SIGALRM设置信号处理函数
addsig(SIGALRM, sig_handler);

// 信号处理函数，将信号发送到了一个管道当中
void sig_handler( int sig )
{
    int save_errno = errno;
    int msg = sig;
    send( pipefd[1], ( char* )&msg, 1, 0 );
    errno = save_errno;
}

// 添加信号捕捉
void addsig(int sig, void(handler)(int)){
    struct sigaction sa;
    memset(&sa, '\0', sizeof(sa) );  // 将sa的数据清空
    sa.sa_handler = handler;
    sigfillset(&sa.sa_mask);  // 设置临时阻塞信号集
    assert(sigaction(sig, &sa, NULL) != -1);
}
```



> 定时器的实现

​	定时器是由双向链表实现的升序链表，存放超时时间、回调函数、上一个和下一个定时器等

> 双向链表删除和添加的时间复杂度？还可以优化吗？

O(k)，最差O(N)

> 小根堆实现的定时器

优先队列实现小根堆

定义了一个Timer类和一个Timerheap类，timer类实现更新到期时间、判断是否到期等功能，heap类包括priority_queue优先队列，提供将timer添加到小根堆中和处理到期事件的回调。在poller的循环中会不断调用这个回调

小根堆是因为根据到期时间排序的，越小则越接近到期

时间复杂度：

增加元素：将新元素添加到堆的末尾、重新调整堆，将新元素向上移动，以满足堆的性质。时间复杂度：O(log n)

>  定时器的工作原理 / 整个流程：

1、alarm函数每隔5s会发送一个SIGALARM信号

2、统一事件源：收到ALARM信号后，通过回调函数对信号进行处理 这里的处理是往管道内写数据

3、epoll监听的时候，会检测管道读端事件，当检测到管道有内容可读时，会判断是哪种信号

4、如果是SIGTERM信号(ctrl+c，即进程被kill) ，那么会将 stop_server 置为1 表示要关闭服务器
	但是这里注意，置为1后并没有立马关闭，而是会继续遍历其他发生改变的文件描述符，表示有其他用户的请求，会全部处理完之后才会在while循环条件里判断，while ( !stop_server ) 这个时候会终止循环，服务器运行结束

5、如果是SIGALARM信号，会将timeout置为1，也同样会等其他事件检测完毕后才会进行判断，因为处理非活跃连接不是紧急事件，不需要实时处理

6、如果timeout为1，开始遍历定时器链表(依据超时事件升序排列)。如果某个节点没有超时 那么后续的也不用检测了 因为是升序的；如果超时了(判断依据就是当前时间是否小于超时时间 如果小于表示不超时 break后续不用检测 如果大于表示超时 需要移除 继续向后遍历)，那么把该节点对应的客户端资源释放(移除epoll监听 断开连接)

7、最后需要重新指定SIGALARM alarm(m_TIMESLOT)



​	其中比较重要的是**socketpair函数**。在linux下，使用socketpair函数能够创建一对套接字进行通信，项目中使用管道通信。

```cpp
// 创建管道，一端读一端写，0读1写
ret = socketpair(PF_UNIX, SOCK_STREAM, 0, pipefd);
// PF_UNIX表示协议族；SOCK_STREAM表示协议，这个属于TCP；pipefd是一个两个元素的数组，即两个套接字。
// pipefd[0]为读端，会检测读端是否有信号；pipefd[1]为写端，即信号处理函数将信号发送到这个管道中
```

​	信号处理函数仅仅发送信号通知程序主循环，将信号对应的处理逻辑放在程序主循环中，由主循环执行信号对应的逻辑代码。具体的，信号处理函数使用管道将信号传递给主循环，信号处理函数往管道的写端写入信号值，主循环则从管道的读端读出信号值。使用I/O复用系统调用来监听管道读端的可读事件，这样信号事件与其他文件描述符都可以通过epoll来监测，从而实现统一处理。

​	这里主要是用信号处理函数处理**SIGALRM**这个定时信号以及**SIGTERM**这个关闭程序的信号。



## 信号

对于信号，可以忽略、捕获、默认处理

> 可以通过man手册查看linux下的信号
>
> man 7 signal
>
> ![image-20230523191816810](E:\MarkDown\picture\image-20230523191816810.png)
>
> <img src="E:\MarkDown\picture\image-20230523191835335.png" alt="image-20230523191835335" style="zoom:50%;" />

### SIGCHLD

​	子进程结束或停止时发送。父进程不处理就会造成僵尸进程。

​	可以对其接管或wait等待。僵尸进程在进程表中仍占有位置，会占用进程表数量

### SIGALARM

​	定时器信号，默认终止进程。但以秒为单位，精度有点粗

​	其中在HTTP服务器项目里就用到了SIGALRM信号，在定时器部分通过alarm函数设置信号传送闹钟，即用来设置信号SIGALRM在经过参数seconds秒数后发送给目前的进程。如果未设置信号SIGALARM的处理函数，那么alarm()默认处理终止进程。

```cpp
// 对SIGPIE管道中止信号进行处理
// 客户端程序向服务器端程序发送了消息，然后关闭客户端，
// 服务器端返回消息的时候就会收到内核给的SIGPIPE信号，导致进程退出
// 我们通过addsig函数，使得收到SIGPIPE信号时不让进程退出，
// 而是调用SIG_IGN回调函数，这个回调函数的作用是忽视信号
addsig(SIGPIPE, SIG_IGN);
// 对SIGALRM、SIGTERM设置信号处理函数
addsig(SIGALRM,sig_handler);
addsig(SIGTERM,sig_handler);  // SIGTERM是一个终止进程的信号，可以被阻塞,忽略,捕获,也就是说可以进行信号处理程序,那么这样就可以让进程很好的终止,允许清理和关闭文件

// 信号处理函数，将信号发送到了一个管道当中
void sig_handler( int sig )
{
    int save_errno = errno;
    int msg = sig;
    send( pipefd[1], ( char* )&msg, 1, 0 );
    errno = save_errno;
}

// 添加信号捕捉
void addsig(int sig, void(handler)(int)){
    struct sigaction sa;
    memset(&sa, '\0', sizeof(sa) );  // 将sa的数据清空
    sa.sa_handler = handler;
    sigfillset(&sa.sa_mask);  // 设置临时阻塞信号集
    assert(sigaction(sig, &sa, NULL) != -1);
}
```



### SIGUSR1/SIGUSR2

自定义信号，默认终止进程。

### SIGINT

键盘输入的退出信号

### SIGHUP

控制终端的挂起状态

### 屏蔽SIGPIPE信号

> SIGPIPE管道中止，当写入无人读取的管道时产生该信号，默认终止进程

​	在整个epoll监听循环开始之前，需要先屏蔽掉SIGPIPE信号。
​	客户端程序向服务器端程序发送了消息，然后**关闭客户端**，服务器端向原来socket发送数据的时候就会收到内核给的SIGPIPE信号，导致进程退出。默认**读写一个关闭的socket会触发sigpipe信号**。该信号的默认操作是关闭进程，这明显是我们不想要的。所以我们需要重新设置sigpipe的信号回调操作函数，比如忽略操作等，可以防止调用它的默认操作。

<img src="E:\MarkDown\picture\image-20230523193408838.png" alt="image-20230523193408838" style="zoom:50%;" />

<img src="E:\MarkDown\picture\image-20230523193931214.png" alt="image-20230523193931214" style="zoom:47%;" />

```cpp
addsig(SIGPIPE, SIG_IGN);

// 添加信号捕捉
void addsig(int sig, void(handler)(int)){
    struct sigaction sa;  // 信号处理结构体
    memset(&sa, '\0', sizeof(sa) );  // 将sa的数据清空
    sa.sa_handler = handler;  // 设置信号的处理回调函数，传入的这个 SIG_IGN宏 代表的操作就是忽略该信号 
    sigfillset(&sa.sa_mask);  // 设置临时阻塞信号集，作用就是当来了一个信号，我们进行处理，当处理的时候再有这个信号产生，就屏蔽掉.sigfillset就是将所有位都置1，就是都屏蔽掉
    assert(sigaction(sig, &sa, NULL) != -1);
}
```

## linux命令

netstat查看端口状态、socket信息等

```cpp
Proto RefCnt Flags       Type       State         I-Node   Path
unix  2      [ ]         DGRAM                    20116    /var/run/chrony/chronyd.sock
unix  4      [ ]         DGRAM                    11414    /run/systemd/notify
unix  2      [ ]         DGRAM                    11416    /run/systemd/cgroups-agent
unix  12     [ ]         DGRAM                    11428    /run/systemd/journal/dev-log
unix  7      [ ]         DGRAM                    11436    /run/systemd/journal/socket
unix  2      [ ]         DGRAM                    27858    /run/user/0/systemd/notify
unix  2      [ ]         STREAM     CONNECTED     25742    
unix  3      [ ]         STREAM     CONNECTED     19977    /run/systemd/journal/stdout
```

虽然 `netstat` 与 `ss` 命令查看的信息都差不多，但是如果在生产环境中要查看这类信息的时候，尽量不要使用 `netstat` 命令，因为它的性能不好，在系统比较繁忙的情况下，如果频繁使用 `netstat` 命令则会对性能的开销雪上加霜，所以更推荐你使用性能更好的 `ss` 命令。

![image-20230424212516558](E:\MarkDown\picture\image-20230424212516558.png)

可以发现，输出的内容都差不多， 比如都包含了 socket 的状态（*State*）、接收队列（*Recv-Q*）、发送队列（*Send-Q*）、本地地址（*Local Address*）、远端地址（*Foreign Address*）、进程 PID 和进程名称（*PID/Program name*）等。

**ping**

要测试本机与远程主机的连通性和延时，通常是使用 `ping` 命令，它是基于 ICMP 协议的，工作在网络层。

比如，如果要测试本机到 `192.168.12.20` IP 地址的连通性和延时：

![img](E:\MarkDown\picture\ping-16823426978933.png)

显示的内容主要包含  `icmp_seq`（ICMP 序列号）、`TTL`（生存时间，或者跳数）以及 `time` （往返延时），而且最后会汇总本次测试的情况，如果网络没有丢包，`packet loss` 的百分比就是 0。

不过，需要注意的是，`ping` 不通服务器并不代表 HTTP 请求也不通，因为有的服务器的防火墙是会禁用 ICMP 协议的。



​	

## 压测

> 压力测试工具本身会占用一定的资源，导致本地进行压测出来的结果不一定会准确（这个问题面试的时候遇到过）

开启1000客户端进程，时间为60s

* 没有memory_pool和lfu
  * 长连接：5.1w
  * 短连接：1.2w

* 加上：5.57w

​	**QPS**的概念如下所示: **QPS**（Query Per Second）：每秒处理的请求数量，就是说服务器在一秒的时间内处理了多少个请求，即并发访问的请求数量。**QPS = req/sec = 请求数/秒**

​	**QPS（TPS）= 并发数/平均响应时间**。并发数：系统同时处理的请求/事务数。

​	一个客户机向服务器发送请求然后服务器做出反应就是一个事务。每秒的request/事务

**压测基本原理**

​	Webbench 首先 fork 出多个子进程，每个子进程都循环做 web 访问测试，即每个客户端发送一个或多个HTTP请求到目标网站的指定页面。这些请求可能包括GET、POST等不同的HTTP方法，以及需要的请求头和参数。客户端等待接收来自目标网站的HTTP响应，然后解析响应以获取状态码、响应时间等信息。

​	最后子进程把访问的结果通过管道 pipe 告诉父进程，父进程做最终的统计结果。

```
webbench -c 1000 -t 60 http://139.224.239.211:10000/index.html
webbench -c 10000 -t 5 http://139.224.239.211:10000/
```



![image-20230409171716264](E:\MarkDown\picture\image-20230409171716264.png)



别人：云服务器是2核4G，最大也就支持8000多的并发，qps只能到1000多

## ==改进==

> 进行了哪些优化

为了减少程序等待IO的时间，采用了非堵塞socket和IO多路复用

为了减小在高并发场景下频繁的创建和销毁线程，并方便对线程数量进行管理，实现了一个线程池



![image-20230525162542927](E:\MarkDown\picture\image-20230525162542927.png)

初版：

* 定时器的实现用的比较简单的双向链表，改为基于小根堆priority_queue

* 单Proactor中由主线程完成数据的读取，容易成为性能瓶颈，因此后期优化为了muduo网络库的主从Reactor的形式
* 使用双缓冲区技术实现了简单的异步日志系统。

>   实现原理
>
>   将源文件按长度为分为N块文件,然后开辟N个线程,每个线程传输一块,最后合并所有线线程文件.比如
>   一个文件500M我们按长度可以分5个线程传输.第一线程从0-100M,第二线程从100M-200M......最后合并5个线程文件.
>
>   实现流程
>
>   1.客户端向服务端请求文件信息(名称,长度)
>   2.客户端跟据文件长度开辟N个线程连接服务端
>   3.服务端开辟新的线程与客户端通信并传输文件
>   4.客户端将每个线程数据保存到一个文件
>   5.合并所有线程文件

## 代码操作流程

### webserver

> 注意，在云服务器上运行的话，需要配置好安全组，增加了个这个，允许端口号10000的TCP连接
>
> ![image-20230408172219699](E:\MarkDown\picture\image-20230408172219699.png)

在linux环境下

1、编译代码：

```cpp
g++ *.cpp -pthread
```

会在目录文件夹下生成a.out文件

2、在命令行输入

```cpp
./a.out 指定端口号
```

关于在使用浏览器访问的时候出现页面访问不了的情况：

首先使用`netstat -napt` 查看运行的代码文件占用的端口号，再使用浏览器使用IP地址加端口号进行访问就可以了

eg http://139.224.239.211:10000/index.html

访问结果如下：

<img src="E:\MarkDown\picture\image-20230408171915784.png" alt="image-20230408171915784" style="zoom:50%;" />



牛客上这个讲解并没有融合定时器，下面是别人整合的一个代码，仅供参考

github整合了定时器的代码：

[项目地址](https://github.com/ChNanAn/-webserver)

### 大webserver

```shell
# 切换到主目录
cd ./WerServer/
# 使用脚本构建项目
sh ./build.sh
cd bin
# 直接输入参数启动，端口号默认是10000
./web_server
```

网页同样是访问http://139.224.239.211:10000/index.html

## 遇到的问题

1、在webserver项目中引入之前写的线程池时，由于线程池项目中的线程类里定义了一个static类型的成员变量，用于给不同的线程生成不断变化的threadId_。这个threadId是用来在unordered_map中通过id查找对应的线程，以启动或删除线程

但这个static定义和声明都在这个.h文件中，因此报错multiple definition of xxx。将定义放在了main.cpp中

2、webserver与线程池项目的匹配问题

​	在webserver中定义了http_conn这个大类，进行TCP通信以及http解析，并定义了一个run成员函数，交给线程池中的线程调用，这也是处理HTTP请求的入口函数。

​	在定义类的时候，本来是将这个run函数定义为了成员函数。但在将此成员函数传递给线程池的提交任务的接口时，发现对于这个run函数，报了invalid use of non-static member function的错误。
![image-20230408195415704](E:\MarkDown\picture\image-20230408195415704.png)因此想到应该将这个函数声明为静态成员函数，然后传入一个指向对象的指针参数，run函数内部调用其他成员函数和成员变量时用指针指一下
<img src="E:\MarkDown\picture\image-20230408195432017.png" alt="image-20230408195432017" style="zoom:67%;" />
<img src="E:\MarkDown\picture\image-20230408195444946.png" alt="image-20230408195444946" style="zoom:67%;" />

之后想起来完全可以继续使用无参的run函数，只需要使用std::bind将指向对象的指针绑定到run函数上就行<img src="E:\MarkDown\picture\image-20230408195639499.png" alt="image-20230408195639499" style="zoom:50%;" />

3、bind时报"Address already in use"错误

发现是忘了设置端口复用

4、程序报错Resource temporarily unavailable资源暂时不可用

​	发现是在非阻塞模式下，循环地将读缓冲区数据读到本地内存中，当缓冲区数据被读完了，调用的 read()/recv() 函数还会继续从缓冲区中读数据，此时函数调用就失败了，返回 - 1，对应的**全局变量 errno 值为 EAGAIN 或者 EWOULDBLOCK** ,如果打印错误信息会得到如下的信息：Resource temporarily unavailable
​	因此在读到recv()的返回值为-1时，如果errno为EAGAIN || EWOULDBLOCK时表示没有数据了，就说明已经读到完整的数据了，此时执行提交任务到线程池的操作

## RAII

Resource Acquisition Is Initialization，资源获取即初始化

​	RAII是一种C++编程技术，它将必须在使用前请求的资源（例如：分配的堆内存、执行线程、打开的套接字、打开的文件、锁定的互斥体、磁盘空间、数据库连接等——任何存在受限供给中的事物）的生命周期与一个对象的生存周期相绑定。

​	RAII保证资源可用于任何会访问该对象的函数。它亦保证所有资源在其控制对象的生存期结束时，以获取顺序的逆序释放。类似地，若资源获取失败（构造函数以异常退出），则为已构造完成的对象和基类子对象所获取的所有资源，会以初始化顺序的逆序释放。这有效地利用了语言特性以消除内存泄漏并保证异常安全。

RAII 可总结如下:

* 将每个资源封装入一个类，其中：
  	构造函数请求资源，在它无法完成时抛出异常；构函数释放资源并决不抛出异常；
* 始终经由 RAII 类的实例使用满足要求的资源，该资源
      自身拥有自动存储期或临时生存期，或具有与自动或临时对象的生存期绑定的生存期

## 主机上最多能保持多少个连接

知乎搜 闪客sum。根据该回答个人归纳总结如下：

连接通过5元组唯一识别**(源IP，源端口，目标IP，目标端口，协议)**。协议比如tcp，udp。只要五元组不同就是不同的socket连接。

* 申请连接时，源IP源端口可以不指定。
  * 源IP操作系统根据网卡自动选
    * **源端口自动分配** 
    * 返回文件描述符用于通信 

##### 瓶颈1 端口号限制

```shell
[root]# cat /proc/sys/net/ipv4/ip_local_port_range 
1024 65000
//修改范围
vim /etc/sysctl.conf
net.ipv4.ip_local_port_range = 60000 60009
```

理论端口号是16位，范围1~65535，但实际上是有限制的，并不是所有端口号都可用。如果始终向同一目标IP和同一目标端口发出连接请求，首先会遇到的是端口号限制。

此时如果不断更换目标IP和目标端口号，可以继续发出连接请求

##### 瓶颈2 文件描述符限制

linux对于文件描述符的限制有3个级别

* **系统级**：当前系统可打开的最大数量，通过 cat /proc/sys/fs/file-max 查看 
* **用户级**：指定用户可打开的最大数量，通过 cat /etc/security/limits.conf 查看 
* **进程级**：单个进程可打开的最大数量，通过 cat /proc/sys/fs/nr_open 查看 

##### 瓶颈3 线程并发过多

**C10K问题**，当服务器连接数达到1万且每个连接都需要消耗线程资源的时候，操作系统会忙于线程上下文切换，可能会导致系统崩溃，同时建立新连接会越来越慢。需要使用**IO多路复用**技术解决这一问题。简而言之，使得一个线程可以管理多个TCP连接的资源。

##### 瓶颈4 内存

##### 瓶颈5 CPU

| 资源        | 一台Linux服务器的资源 | 一个TCP连接占用的资源 | 占满了会发生什么                |
| ----------- | --------------------- | --------------------- | ------------------------------- |
| CPU         | 看你花多少钱买的      | 看你用它干嘛          | 电脑卡死                        |
| 内存        | 看你花多少钱买的      | 取决于缓冲区大小      | OOM                             |
| 临时端口号  | ip_local_port_range   | 1                     | cannot assign requested address |
| 文件描述符  | fs.file-max           | 1                     | too many open files             |
| 进程\线程数 | ulimit -n             | 看IO模型              | 系统崩溃                        |



http

http_conn*类型的user数组保存所有客户端信息

## 项目中用到过哪些==设计模式==

看看单例、工厂、观察者、适配者

#### ==创建型模式==

#### **单例模式**Singleton

##### 概念

​	在一个项目中，全局范围内，某个类的实例有且仅有一个，通过这个唯一实例向其他模块提供数据的全局访问，这种模式就叫单例模式。单例模式的典型应用就是任务队列。

**解决问题：一个全局使用的类的实例频繁地创建与销毁。**

优点：

- 在内存里只有一个实例，减少了内存的开销，尤其是频繁的创建和销毁实例（比如管理学院首页页面缓存）。
- 避免对资源的多重占用（比如写文件操作）。

缺点：

- 没有接口，不能继承，与单一职责原则冲突，一个类应该只关心内部逻辑，而不关心外面怎么样来实例化。

##### 实现

涉及一个类多对象操作的函数有以下几个：

* 构造函数私有化，只在类内部调用一次。
  * 类内部的这个唯一对象必须是静态的，这样就可以通过类名访问了
  * 同时这个对象的访问权限要设为私有的，以不破坏类的封装
  * 在类中只有它的静态成员函数才能访问其静态成员变量，所以可以给这个单例类提供一个静态函数用于得到这个静态的单例对象
* 拷贝构造函数 和 拷贝赋值操作符重载函数 私有化或者禁用(delete)

```cpp
// 定义一个单例模式的类
class Singleton {
public:
    // = delete 代表函数禁用, 也可以将其访问权限设置为私有
    Singleton(const Singleton& obj) = delete;
    Singleton& operator=(const Singleton& obj) = delete;
    static Singleton* getInstance();
private:
    Singleton() = default;
    static Singleton* m_obj;
};
```

在实现一个单例模式的类的时候，有两种处理模式：

* 饿汉模式：在类加载的时候立刻进行实例化

* 懒汉模式：在类加载的时候不去创建这个唯一的实例，而是在需要使用的时候再进行实例化。**存在线程安全问题**

```cpp
// 饿汉模式
class A {
public:
    // = delete 代表函数禁用, 也可以将其访问权限设置为私有
    A(const A& obj) = delete;
    A& operator=(const A& obj) = delete;
    static A* getInstance() {
        return m_taskQ;
    }
private:
    A() = default;
    static A* m_taskQ;
};

// 类的静态成员变量在使用之前必须在类的外部进行初始化才能使用
// 创建单例对象
A* A::m_taskQ = new A;

int main() {
    // 当使用者通过 getInstance() 获取这个单例对象的时候，它已经被准备好了
    A* obj = A::getInstance();
}
```



```cpp
// 懒汉模式
class TaskQueue {
public:
    // = delete 代表函数禁用, 也可以将其访问权限设置为私有
    TaskQueue(const TaskQueue& obj) = delete;
    TaskQueue& operator=(const TaskQueue& obj) = delete;
    static TaskQueue* getInstance() {
        if(m_taskQ == nullptr) {
            m_taskQ = new TaskQueue;
        }
        return m_taskQ;
    }
private:
    TaskQueue() = default;
    static TaskQueue* m_taskQ;
};

TaskQueue* TaskQueue::m_taskQ = nullptr;
```

懒汉模式的线程安全问题：

​	在调用 getInstance() 函数获取单例对象的时候，如果在单线程情况下是没有什么问题的，如果是多个线程，调用这个函数去访问单例对象就有问题了。假设有三个线程同时执行了getInstance() 函数，在这个函数内部每个线程都会 new 出一个实例对象。此时，这个任务队列类的实例对象不是一个而是 3 个，很显然这与单例模式的定义是相悖的。

* 互斥锁
  问题：不论有多少个线程，同时执行这个代码块的线程只能是一个

  ```cpp
  class TaskQueue {
  public:
      // = delete 代表函数禁用, 也可以将其访问权限设置为私有
      TaskQueue(const TaskQueue& obj) = delete;
      TaskQueue& operator=(const TaskQueue& obj) = delete;
      static TaskQueue* getInstance() {
          m_mutex.lock();
          if (m_taskQ == nullptr) {
              m_taskQ = new TaskQueue;
          }
          m_mutex.unlock();
          return m_taskQ;
      }
  private:
      TaskQueue() = default;
      static TaskQueue* m_taskQ;
      static mutex m_mutex;
  };
  TaskQueue* TaskQueue::m_taskQ = nullptr;
  mutex TaskQueue::m_mutex;
  ```

* 双重检查锁定：通过两个嵌套的 if 来判断单例对象是否为空

  为什么要两层嵌套if呢，这是因为如果有多个线程同时进入了第一个if的判定，此时其中一个线程取得了锁，进入了第二个if的判定，取得了 m_taskQ ，此时其他线程再取得锁后，此时由于实例已经创建，就进不了第二个if了，就可以直接使用已经创建好的 m_taskQ 。

  ```cpp
  class TaskQueue
  {
  public:
      // = delete 代表函数禁用, 也可以将其访问权限设置为私有
      TaskQueue(const TaskQueue& obj) = delete;
      TaskQueue& operator=(const TaskQueue& obj) = delete;
      static TaskQueue* getInstance() {
          // 当任务队列的实例被创建出来之后，访问这个对象的线程就不会再执行加锁和解锁操作了
          if (m_taskQ == nullptr) {
              m_mutex.lock();
              if (m_taskQ == nullptr) {
                  m_taskQ = new TaskQueue;
              }
              m_mutex.unlock();
          }
          return m_taskQ;
      }
  private:
      TaskQueue() = default;
      static TaskQueue* m_taskQ;
      static mutex m_mutex;
  };
  TaskQueue* TaskQueue::m_taskQ = nullptr;
  mutex TaskQueue::m_mutex;
  ```

  问题：
  m_taskQ = new TaskQueue; 在执行过程中对应的机器指令可能会被重新排序。正常过程如下：

  第一步：分配内存用于保存 TaskQueue 对象。

  第二步：在分配的内存中构造一个 TaskQueue 对象（初始化内存）。

  第三步：使用 m_taskQ 指针指向分配的内存。

  但是被重新排序以后执行顺序可能会变成这样：

  第一步：分配内存用于保存 TaskQueue 对象。

  第二步：使用 m_taskQ 指针指向分配的内存。

  第三步：在分配的内存中构造一个 TaskQueue 对象（初始化内存）。

  这样重排序并不影响单线程的执行结果，但是在多线程中就会出问题。如果线程 A 按照第二种顺序执行机器指令，执行完前两步之后失去 CPU 时间片被挂起了，此时线程 B 在第 3 行处进行指针判断的时候 m_taskQ 指针是不为空的，但这个指针指向的内存却没有被初始化，最后线程 B 使用了一个没有被初始化的队列对象就出问题了

* 原子变量
  使用原子变量 atomic 的 store() 方法来存储单例对象，使用 load() 方法来加载单例对象。

  ```cpp
  class TaskQueue {
  public:
      // = delete 代表函数禁用, 也可以将其访问权限设置为私有
      TaskQueue(const TaskQueue& obj) = delete;
      TaskQueue& operator=(const TaskQueue& obj) = delete;
      static TaskQueue* getInstance() {
          // load加载
          TaskQueue* queue = m_taskQ.load();  
          if (queue == nullptr) {
              // m_mutex.lock();  // 加锁: 方式1
              lock_guard<mutex> locker(m_mutex);  // 加锁: 方式2
              queue = m_taskQ.load();
              if (queue == nullptr) {
                  queue = new TaskQueue;
                  // store存储
                  m_taskQ.store(queue);
              }
              // m_mutex.unlock();
          }
          return queue;
      }
  
      void print() {
          cout << "hello, world!!!" << endl;
      }
  private:
      TaskQueue() = default;
      static atomic<TaskQueue*> m_taskQ;
      static mutex m_mutex;
  };
  atomic<TaskQueue*> TaskQueue::m_taskQ;
  mutex TaskQueue::m_mutex;
  
  int main() {
      TaskQueue* queue = TaskQueue::getInstance();
      queue->print();
      return 0;
  }
  ```

  > 对于atomic模板类，有两个成员函数
  >
  > * store：原子地加载并返回原子变量的当前值。按照 order 的值影响内存。直接访问原子对象也可以得到原子变量的当前值。
  >
  >   * desired：存储到原子变量中的值
  >   * order：强制的内存顺序
  >
  >   ```cpp
  >   // 使用默认的内存序
  >   void store( T desired, std::memory_order order = std::memory_order_seq_cst ) noexcept;
  >   void store( T desired, std::memory_order order = std::memory_order_seq_cst ) volatile noexcept;
  >   ```
  >
  > * load：原子地加载并返回原子变量的当前值。按照 order 的值影响内存。直接访问原子对象也可以得到原子变量的当前值。
  >
  >   ```cpp
  >   T load( std::memory_order order = std::memory_order_seq_cst ) const noexcept;
  >   T load( std::memory_order order = std::memory_order_seq_cst ) const volatile noexcept;
  >   ```
  >
  > * 默认采用memory_order_seq_cst的内存顺序约束，即这个操作前和这个操作后的数据操作的顺序绝对不会重排

  * 静态局部对象
    相较于双重检查锁定模式有一种更简单的实现方法并且不会出现线程安全问题，那就是使用静态局部对象
    线程安全是通过c++11的以下规定保证的：如果指令逻辑进入一个未被初始化的声明变量，所有并发执行应当等待该变量完成初始化。

  ```cpp
  class TaskQueue {
  public:
      TaskQueue(const TaskQueue& obj) = delete;
      TaskQueue& operator=(const TaskQueue& obj) = delete;
      static TaskQueue* getInstance() {
          // 静态局部对象，并且将这个对象作为了唯一的单例实例
          static TaskQueue taskQ;
          return &taskQ;
      }
      void print() {
          cout << "hello, world!!!" << endl;
      }
  
  private:
      TaskQueue() = default;
  };
  
  int main() {
      TaskQueue* queue = TaskQueue::getInstance();
      queue->print();
      return 0;
  }
  ```

> 总结：懒汉模式的缺点是在创建实例对象的时候有安全问题，但这样可以减少内存的浪费（如果用不到就不去申请内存了）。饿汉模式则相反，在我们不需要这个实例对象的时候，它已经被创建出来，占用了一块内存。对于现在的计算机而言，内存容量都是足够大的，这个缺陷可以被无视。

##### 2.项目中的应用

比如线程池中ThreadPool类中的任务队列`std::queue<Task> taskQue_`就是采用的单例模式，只有这一个队列作为实例，存储多个任务，然后通过互斥锁保证其线程安全

## 杂

### tcp/udp可以绑定同一个端口吗(镜像问题)

tcp/udp均**不可以**两个**同类**的监听socket绑定在同一个端口上。

但是**可以一个tcp一个udp同时绑定一个端口。**

由上述结果可知：TCP、UDP可以同时绑定一个端口8888，但是一个端口在同一时刻不可以被TCP或者UDP绑定2次。
原因如下：

1. tcp的端口不是物理概念，仅仅是协议栈中的两个字节； 
2. TCP和UDP的端口完全没有任何关系，完全有可能又有一种XXP基于IP，也有端口的概念，这是完全可能的； 
3. TCP和UDP传输协议监听同一个端口后，接收数据互不影响，不冲突。因为数据接收时时根据五元组**{传输协议，源IP，目的IP，源端口，目的端口}**判断接受者的。 

### 三次握手

> * 一开始，客户端和服务端都处于 `CLOSE` 状态。先是服务端主动监听某个端口，处于 `LISTEN` 状态。
> * 客户端将SYN标志置1，表示申请建立连接，并发送一个随机初始化的信号，此时客户端进入SYN-SENT状态
> * 服务端收到客户端的 `SYN` 报文后，将 ACK 和 SYN 标志位都置1，确认应答号为客户端的序列号+1，并随机初始化自己的序列号，发送到客户端。之后服务端处于 `SYN-RCVD` 状态。
> * 客户端收到这个报文后，再回复一个应答报文，将ACK置1，将确认应答号设为服务端的序列号+1。这个报文可以携带数据。发送报文后，客户端处于 `ESTABLISHED` 状态。
> * 服务端收到客户端的应答报文后，也进入 `ESTABLISHED` 状态。
>
> 
>
> * 客户端这边不需要调用 bind 操作，默认会选择源 IP 和随机端口。
>
> * accept、connect、read、write 这几个方法都可能会发生阻塞：
>
>   * connect：需要阻塞等待三次握手的完成。
>
>   * accept：需要等待可用的已完成的连接，如果已完成连接队列为空，则被阻塞。
>     ![image-20230415124032181](E:\MarkDown\picture\image-20230415124032181.png)
>
> * read和write也会发生堵塞
>
>   * read 读不到数据阻塞等待
>   * write 为什么还要阻塞，有数据不就直接发了吗？
>     TCP 协议需要保证数据可靠地、有序地传输，并且给予端与端之间的流量控制。所以说发送不是直接发出去，它有个发送缓冲区，需要把数据先拷贝到 TCP 的发送缓冲区，由 TCP 自行控制发送的时间和逻辑，有可能还有重传什么的。如果我们发的过快，导致接收方处理不过来，那么接收方就会通过 TCP 协议告知。发送缓存区是有大小限制的，由于无法发送，还不断调用 write ，则缓存区满时， write 也会发生阻塞。

> 为什么是三次握手

* 三次握手才可以阻止重复历史连接的初始化（主要原因）
  	一个「旧 SYN 报文」比「最新的 SYN」 报文早到达了服务端，服务端回复一个SYN+ACK报文，这样连接就建立了。而客户端收到报文后发现确认号不对，不是新的SYN连接，就又发送RST断开了这次连接。这就导致多建立了这个历史连接！之后等到新的SYN到达服务端后再次建立连接。
* 三次握手才可以同步双方的初始序列号
      来确保每次的请求消息都有正确的响应。当然四次握手也能满足，只是可以简化为三次握手

不使用「两次握手」和「四次握手」的原因：

* 「两次握手」：无法防止历史连接的建立，会造成双方资源的浪费，也无法可靠的同步双方序列号；
* 「四次握手」：三次握手就已经理论上最少可靠连接建立，所以不需要使用更多的通信次数。

### 四次挥手

* 客户端打算关闭连接，此时会发送一个 TCP 首部 `FIN` 标志位被置为 `1` 的报文，也即 `FIN` 报文，之后客户端进入 `FIN_WAIT_1` 状态。
* 服务端收到该报文后，就向客户端发送 `ACK` 应答报文，接着服务端进入 `CLOSE_WAIT` 状态。
* 客户端收到服务端的 `ACK` 应答报文后，之后进入 `FIN_WAIT_2` 状态。
* 等待服务端处理完数据后，也向客户端发送 `FIN` 报文，之后服务端进入 `LAST_ACK` 状态。
* 客户端收到服务端的 `FIN` 报文后，回一个 `ACK` 应答报文，之后进入 `TIME_WAIT` 状态
* 服务端收到了 `ACK` 应答报文后，就进入了 `CLOSE` 状态，至此服务端已经完成连接的关闭。
* 客户端在经过 `2MSL` 一段时间后，自动进入 `CLOSE` 状态，至此客户端也完成连接的关闭。

<img src="E:\MarkDown\picture\image-20230626201656475.png" alt="image-20230626201656475" style="zoom:37%;" />

**主动关闭连接的，才有 TIME_WAIT 状态。**

# HR项目问答



> 项目介绍一下  

​	动态线程池项目是在Linux下开发的基于c++11标准的线程池，支持线程数量的动态增长、任务优先级的调整、任意任务函数和任意数量参数的传递、以及异步获取任务处理结果。使用方法和c++中提供的thread相同。
​	其中使用STL容器管理线程对象和任务，通过互斥锁实现了线程安全的任务队列；对于向线程池提交任务的接口，通过packaged_task对任务函数进行包装，并通过future类模板获取异步任务处理结果，最后基于可变参模板和引用折叠、完美转发等原理实现了这个提交任务的接口。

​	基于Linux的轻量级多线程Web服务器项目支持多个客户端访问服务器的图片视频等资源。使用线程池、非阻塞socket、ET实现的epoll以及主从 Reactor 的并发模型；使用有限状态机的方式解析HTTP请求，支持解析GET请求；通过小根堆实现的定时器关闭超时的非活跃连接；使用双缓冲区技术实现了简单的异步日志系统。

> 如果同时有1000个客户端进行访问请求

​	首先项目中使用了IO多路复用技术，主线程对监听和通信的文件描述符进行检测，比如同时有若干个连接来了后，主线程epoll_wait中检测到有读写事件，就依次进行处理，每读取到一个完整的请求报文后，就将报文和连接处理的任务交给线程池，线程池会将任务保存到任务队列中，并唤醒线程进行处理。

​	如果线程池的线程都用掉后，如果是cached模式，会自动进行线程数量的增长，处理任务。如果超出了cached模式的最大线程数量，或者处于fixed固定线程数量的模式，就只能等有空闲线程了才能去处理，处理不了的任务会保存到任务队列中等待。

​	我现在再对这个项目进行改进，主从Reactor的模式。

​	主Reactor对客户端的连接进行监听，有连接事件发生后，就调用相应的事件处理函数，建立连接，然后将通信的文件描述符打包成channel分发给子Reactor。子Reactor对这些通信的文件描述符进行监听，有事件发生后调用相应的事件处理函数，负责与客户端进行通信，解析HTTP请求报文、生成响应报文、发送报文等。

> 如果一个客户请求要占用线程很长的时间，会不会影响接下来的客户请求？

<img src="E:\MarkDown\picture\image-20230525174808970.png" alt="image-20230525174808970" style="zoom:60%;" />

> 是自己申请的域名么

​	没有申请域名，用的阿里云服务器上自带的公网ip，可以直接通过公网ip和端口号来访问服务器

> 面向对象特性在项目中的体现

C++面向对象特性有封装、继承、多态。

* 首先是封装，我在项目中将各个模块使用类进行封装，比如 socket 连接用 http_conn 类来封装，定义了处理客户端请求、读写、解析HTTP请求等操作；定时器相关定义了util_timer定时器类；以及线程池类、线程类、任务类等；
  将类的属性私有化，比如请求的解析状态，并且对外的接口设置为公有，比如连接的重置，不对外暴露自身的私有方法，比如读写的回调函数等。
  
* 然后是继承，初版代码中用继承很少，第二版代码中实现了一个 uncopyable类，即一个删除拷贝构造函数、拷贝赋值运算符的基类。然后其中一些类就会去继承这个基类，这样比如有的类忘了编写拷贝构造函数，或者不需要实现这个函数，编译器默认生成的版本会自动调用基类的拷贝构造函数，然后被禁用，就可以避免浅拷贝等问题。相比 =delete 来删除的好处就是可以节省很多代码

  ```cpp
  // 删除拷贝构造和拷贝赋值
  // 子类继承此父类后，进行拷贝构造和赋值时会先调用父类的，然后才是派生类自己的拷贝构造和赋值，而基类的被delete了，这就使得派生类不能拷贝构造和赋值
  class NonCopyAble {
   public:
      NonCopyAble(const NonCopyAble&) = delete;
      NonCopyAble& operator=(const NonCopyAble&) = delete;
  
      NonCopyAble(NonCopyAble&&) = default;
      NonCopyAble& operator=(NonCopyAble&&) = default;
  
   protected:
      NonCopyAble() = default;
      ~NonCopyAble() = default;
  };
  
  // class默认私有继承，当一个类派生自私有基类时，基类的公有和保护成员将成为派生类的私有成员。
  class channel : NonCopyAble {
  }
  ```

* 最后是多态，项目中的多态主要用了静态多态，动态多态没有涉及。静态多态主要是模板，比如线程池中的可变参模板实现任意数量参数的传递等



> 做这个项目的目的？（有开源现成的为啥重复造轮子？）

​	像是服务器框架的话，比较出名的有 Nginx（读 恩静埃克斯）轻量级 Web 服务器、Muduo 网络库等。做这个项目一个是复习一下所学的知识，毕竟涉及到了线程池、socket 网络编程、C++ 一些语法糖的使用等；另一个目的是打算在这个框架上进行后续的开发，比如实现分布式，然后再实现一些功能，比如流媒体服务器等，这个框架是自己实现的，使用起来就更熟悉，改动也比较方便



> 项目难点和解决方法

对于服务器项目：

​	像这个HTTP服务器项目的话，他更多的是一个拼接，就是把几个轮子合在一起，里面就是线程池部分、HTTP解析部分、定时器部分和socket网络编程这四个部分组合在一起。
​	其中定时器部分就是个小根堆来每隔5s看一下连接情况；
​	HTTP部分就是一个有限状态机的理论模型，主状态机解析请求，根据是正在分析请求行、头部字段还是请求体分别调用从状态机进行处理。从状态机将处理状态和数据传给主状态机。在HTTP连接程序中，我们定义了很多enum类型的状态，如HTTP请求方法、解析客户端请求时主状态机的状态、从状态机的状态等。服务器可以根据不同状态或者消息类型进行相应的处理逻辑，使得程序逻辑清晰易懂。
​	线程池部分就是用的线程池项目。
​	比较有难度的就是主从Reactor事件处理模式的一个设计，最后选择参照了Muduo网络库而不是完全自己去设计，因为感觉很难有思路，所以参照了这个比较成熟的架构，但在具体实现上的逻辑也还是比较复杂。



对于线程池项目：

​	一个难点是我这个项目一开始是在 win 下开发的，结果移植到 Linux 下后发现又出现了死锁问题

​	当时是看着测试程序出现了堵塞，然后 `ps -aux | grep a.out` 看了下，发现这个程序处在休眠状态，就感觉应该是死锁了，然后 `top -Hp 338821` 看了下这个线程的运行情况，发现所有线程都进入到了阻塞状态，CPU占用率都为0.0，**可以排除是死循环的问题**，因为死循环会造成 CPU 使用率居高不下，而且线程的状态也不会是S。那么接下来有可能是由于I/O网络事件没有发生使线程阻塞，或者是线程发生死锁问题了。

​	使用gdb的三种调试中的attach

```shell
# 将gdb attach到一个PID号中
gdb attach PID
# 查看所用线程堆栈信息
thread apply all bt
```

​	之后发现这个子线程堵塞在了notify_all中

> 在 pthread 中，**条件变量的析构不会自动唤醒等待在该条件变量上的线程**。如果在条件变量上等待的线程没有被唤醒，而条件变量被销毁，这可能导致等待的线程无法被唤醒，进而可能导致资源泄漏或阻塞。

​	程序的执行是需要时间的，但这些result对象很快的就会离开作用域，然后析构，此时result中我们实现的信号量等也会析构，因此在 windows 下程序的执行是没有问题的

​	在linux下，由于我们实现的信号量是由锁和条件变量组成的，而条件变量的析构函数什么也不会做，资源没有被释放，使用的是超过生命周期的资源，因此在post函数中的cond_.notify_all()中的状态失效。

改动：在Semaphore类中增加了个离开的状态，使得在这个类析构时，不再执行wait和post（即不再访问条件变量和锁）

```cpp
class Semaphore {
public:
	Semaphore(int count = 0) : resLimit_(count), isExit_(false) {}
	~Semaphore() {
		isExit_ = true;
	}
	// 获取一个信号量资源
	void wait() {
		if (isExit_) return;
		std::unique_lock<std::mutex> lock(mtx_);
		// 等待信号量有资源
		cond_.wait(lock, [&]()->bool { return resLimit_ > 0; });
		resLimit_--;
	}
	// 增加一个信号量资源
	void post() {
		if (isExit_) return;
		std::unique_lock<std::mutex> lock(mtx_);
		resLimit_++;
		cond_.notify_all();
	}
private:
	std::atomic_bool isExit_;
	int resLimit_;
	std::mutex mtx_;
	std::condition_variable cond_;
};
```



​	另外的一些难点就比较小了，比如没有屏蔽SIGPIPE信号，就是没设置这个信号的回调函数，就会导致客户端发送完消息关闭后，服务器向客户端返回消息时，因为读写了一个关闭了的socket，就会触发这个SIGPIPE信号，默认操作是关闭进程。这些都是属于细节上的疏漏，但其实排查起来还都是有点困难的，因为刚做的时候对这个也没那么理解，有时候就根本想不到是因为什么原因导致程序莫名的堵塞或者自己关闭了，就得查半天文献、看看别人代码咋写的之类的

还比如用ET模式的时候忘了加`EPOLLONESHOT`

​	在一些特殊的应用场景中，如果涉及多个线程同时处理某个`socket`上的事件，则为了避免数据乱序，我们不得不使用复杂的多线程同步机制；但是有了`EPOLLONESHOT`选项，我们就可以减少线程同步逻辑。以`EPOLLIN`为例，多个线程同时从一个`socket`上读数据，可以使某个线程先处理，在该线程处理完之后再重新给该`socket`添加读事件，这样读事件再次触发时，就可以被其他线程继续处理。这种做法本质上还是保证同一个时刻只有一个线程在处理某个`socket`上的事件。



> 哪个项目经历比较特别，详细讲讲你开发的内容，有什么亮点 

​	线程池项目吧。一开始写的线程池项目是手动的设计一个Result类来保存线程执行的结果，然后整个程序搞得非常麻烦

​	亮点就是后续使用了c++11的新特性....



# 扩展

## WebFileServer

> [WebFileServer](https://github.com/shangguanyongshi/WebFileServer)
>
> 主要功能包括：
>
> * 以 HTML 页面形式返回该文件夹下的所有文件
> * 可以选择本地文件上传到服务器
> * 可以对列表中的文件文件执行下载操作
> * 可以删除服务器中的指定文件
>
> 框架
>
> * 使用 HTTP **GET** 方法获取文件列表，发起下载文件、删除文件的请求。使用 **POST** 方法向服务器上传文件
> * 服务端使用 `sendfile` 函数实现**零拷贝**数据发送

message/message.h

event/myevent.cpp

event/myevent.h

## TinyWebServer

[TinyWebServer](https://github.com/qinguoyi/TinyWebServer)

数据库连接池、注册和登录功能



# csapp

**项目描述：**此项目为学习操作系统时做的实验项目，完成了CSAPP中不涉及汇编部分的LAB。

**项目实现：**

- Cache lab：实现了一个cache模拟器，模拟cache memory的行为，输出命中、错过和驱逐的总数；并优化矩阵转置函数，最小化cache miss的数量。
- Shell lab：实现了一个带有作业控制的 Shell 程序，支持解析前后台命令并执行、等待前台作业执行完成、信号处理。
- Malloc lab：设计了分离的空闲链表的结构对堆空间进行管理，实现c语言中malloc、free函数。



其他的涉及汇编的没做，那个web服务器的也没做

[hallo world的详细流程](https://zhuanlan.zhihu.com/p/513307151)

## data lab

```c
// 异或。异或的符号为 ^
int bitXor(int x, int y) {
  return ~(~x & ~y) & ~(x & y);
}

// 2 ^ 31- 可以使用左移运算符，1<<2 ==> 4  1<<31 ==> 2^31
int tmin(void) {
  return 1<<31;
}
// 写法2，这里u表示无符号
// 0x80为1000 0000，已经左移7位了
#define INTMIN (0x80u << 24)  // 1个op
int tmin(void) { return INTMIN; }

// 判断x是否是最大值
// 如四位的最大值x=0111 然后x+1之后就会变成1000 我们对1000 取非 0111    就会重新变回x值
// 自己与自己异或会得到0，也就是说我们可以用异或来判断等于!((~(x+1)^x)) 判断这个是否为1即可判断是否为最大值
// 这里有一个例外就是x=-1 由于-1=1111 他利用上面的式子判断也符合，故要特判-1 利用!!(x+1) 这个操作-1和最大值并不相同
int isTmax(int x) {
  return !((~(x+1)^x))&!!(x+1);
}
```



## cache lab

> 对应**第六章：存储器层次结构**

### cache

​	cache 结构如图，高速缓存 cache 包含 S 个高速缓存组(cache set)，每个组包含E个高速缓存行(cache line)，每个 cache line 包含 有效位、标记 和 B个数据块。组索引确定是哪个组，而标记必须与这个cache line中的标记相同

<img src="E:\MarkDown\picture\image-20230529232043068.png" alt="image-20230529232043068" style="zoom:50%;" />

<img src="E:\MarkDown\picture\image-20230530091202245.png" alt="image-20230530091202245" style="zoom:50%;" />



<img src="E:\MarkDown\picture\image-20230529230131335.png" alt="image-20230529230131335" style="zoom:47%;" />

![image-20230529230733810](E:\MarkDown\picture\image-20230529230733810.png)



比如s = 4，就有S=2^4=16组，E=1即每组一个cacheline,b=4即每组4个block。

### 任务1

> 实现了一个cache模拟器，模拟cache memory的行为，输出命中、错过和驱逐的总数；并优化矩阵转置函数，最小化cache miss的数量。

* 驱逐：从cache移出一个line从而为新的数据腾出空间。使用 LRU (最近使用最少的)替换策略来选择驱逐哪个缓存行。  

这个程序会对若干行内存访问进行跟踪，即操作字段、地址字段和size字段。

* 操作字段：Store表示数据存储，Load表示数据加载，Modify表示数据改变
* 地址字段：十六进制的一个内存地址
* Size 字段指定操作访问的字节数

这个程序接收以下命令行参数：S E B





### 分析1

若L 10 (16进制)，则写为二进制为10000，补全就是0001 0000，因为s=4，因此set是四位，即 0000000 | 0001 | 0000，其中0001为set，set前面是组标记tag，tag有若干0

0001表示set=1，是第一组，即第一组的这个cache line中存了 000000 若干个0的tag。初始时cache是空的，这是个miss。由于缓存不命中，高速缓存从内存中取出这个cache line的块，同时有效位置1



若M 20（也是16进制），对应十进制32，10 0000，补全是 0010 0000，这是第二组。而这里是 M ，对数据进行修改，是必 **HIT** 的



接下来是L 22，0010 0010，即第二组，由于第二组刚修改了数据，而tag也是000000，与之前对应，因此 HIT



s中每个E都对应一个tag

<img src="E:\MarkDown\picture\image-20230529225843878.png" alt="image-20230529225843878" style="zoom:50%;" /><img src="E:\MarkDown\picture\image-20230529231202341.png" alt="image-20230529231202341" style="zoom:50%;" />



### 思路1

* 对于cache的构造，由于使用LRU：最近最少使用策略，需要替换最后一次访问时间最久远的哪一行，因此创建了个Node双向链表存tag标记，作为我们的cache line，然后创建了个LRU作为一个组，包含多个Node，保存头Node、尾Node和Node的个数。然后一共有S组，即S个LRU
* 输入的内存地址就包含标记、索引和偏移量。我们通过一些位操作取得这些值，通过索引知道是第几组，找到那组的LRU后，就从头Node开始对比标记tag。只需要判断Node->tag和给的是否相等就知道是否Miss
  * 如果是Load的话，没找到就是Miss，将这个Node加到LRU双向链表的最前面，找到了就是Hit，将这个Node更新到LRU最前面
  * 如果是Modify，对数据进行修改，也同样操作。Store存储数据

* 如果miss，如果cache没满，就加到对应LRU的最前面，并size++；如果满了，就删除LRU的最后一个cache line，再将新的加到LRU的最前面
* 如果Hit，就删除对应的Node，再将其添加到LRU的最前面

### 代码1

```c
#define _GNU_SOURCE
#include "cachelab.h"
#include "stdlib.h"
#include <stdio.h>
#include "getopt.h"
#include <string.h>
#define addrLen 8

static int S;
static int E;
static int B;
static int hits = 0;
static int misses = 0;
static int evictions = 0;
static int totalSet;

typedef struct _Node {
    unsigned tag;
    struct _Node* next;
    struct _Node* prev;
} Node;

typedef struct _LRU{
    Node* head;
    Node* tail;
    int* size;
}LRU;

static LRU* lru;

void initializeLRU(int i){
    lru[i].head = malloc(sizeof(Node));
    lru[i].tail = malloc(sizeof(Node));

    lru[i].head->next = lru[i].tail;
    lru[i].tail->prev = lru[i].head;
    (lru[i].size)     = (int* )malloc(sizeof(int));
    *(lru[i].size)      = 0;
}

/**
 *
 * @param lru the lru we manupilate
 * @param pos the node position to be deleted usually 0 or 1
 *              0 means the first one
 *              1 means the last one
 */
void deleteElement(unsigned set, Node* nodeToDel, LRU* curLru){
    nodeToDel->next->prev = nodeToDel->prev;
    nodeToDel->prev->next = nodeToDel->next;
    *(curLru->size) = *(curLru->size) - 1;
}

void evict(unsigned set, LRU* curLru){
    deleteElement(set, curLru->tail->prev, curLru);
}

void addFirst(unsigned set, Node* node, LRU* curLru){
    node->next = curLru->head->next;
    node->prev = curLru->head;

    curLru->head->next->prev = node;
    curLru->head->next       = node;

    *(curLru->size) = *(curLru->size) + 1;
}

void parseOption(int argc, char** argv, char** fileName){
    int option;
    while( (option = getopt(argc, argv, "s:E:b:t:")) != -1){
        switch (option) {
            case 's':
                S = atoi(optarg);
            case 'E':
                E = atoi(optarg);
            case 'b':
                B = atoi(optarg);
            case 't':
                strcpy(*fileName, optarg);
        }
    }
    totalSet = 1 << S;
}

void update(unsigned address){
    unsigned mask = 0xFFFFFFFF;
    unsigned maskSet = mask >> (32 - S);  // 剩了S位的掩码，即最后S个1
    unsigned targetSet = ((maskSet) & (address >> B));  // 同时address右移B位，刚好S位的set在最后
    unsigned targetTag = address >> (S + B);

    LRU curLru = lru[targetSet];
    
    // to find if we have one
    Node* cur = curLru.head->next;
    int found = 0;
    while(cur != curLru.tail){
        if(cur->tag == targetTag){
            found = 1;
	        break;
        }

        cur = cur->next;
    }

    
    if (found) {
        hits++;
        deleteElement(targetSet, cur, &curLru);
        addFirst(targetSet, cur, &curLru);
	    printf("hit!, the set number %d \n", targetSet);
    } else {
        Node* newNode = malloc(sizeof(Node));
        newNode->tag = targetTag;
        if(*(curLru.size) == E){ // full, need to evict
            deleteElement(targetSet, curLru.tail->prev, &curLru);
            addFirst(targetSet, newNode, &curLru);

            evictions++;
            misses++;
	        printf("evic + miss set -> %d\n", targetSet);
        }else{
            misses++;
            addFirst(targetSet, newNode, &curLru);
            printf("only miss %d\n", targetSet);
        }    
    }
}

void cacheSimulateWhole(char* fileName) {
    // step1: new lru with s sets
    lru = malloc(totalSet * sizeof(*lru));
    for (int i = 0; i < totalSet; i++)
        initializeLRU(i);

    FILE* file = fopen(fileName, "r");
    char op;
    unsigned address;
    int size;
    // L 10, 1
    while (fscanf(file, " %c %x,%d", &op, &address, &size) > 0) {
        printf("%c, %x %d\n", op, address, size);
	switch (op) {
            case 'L':
                update(address);
                break;
            case 'M':
                update(address);
            case 'S':
                update(address);
                break;
        }

    }
}

int main(int argc, char** argv)
{
    char* fileName = malloc(100 * sizeof(char));

    // step1: parse option
    parseOption(argc, argv, &fileName);

    // step2: read all of the lines and analyze it
    cacheSimulateWhole(fileName);

    printSummary(hits, misses, evictions);
    return 0;
}

```

### 任务2

​	优化矩阵转置函数，最小化cache miss的数量。优化的矩阵转置函数在三个大小的输出矩阵上进行评估：32×32 64×64 61×67

### 思路2

> reference:https://zhuanlan.zhihu.com/p/484657229

原始trans：

```cpp
void trans(int M, int N, int A[N][M], int B[M][N])
{
    int i, j, tmp;

    for (i = 0; i < N; i++) {
        for (j = 0; j < M; j++) {
            tmp = A[i][j];
            B[j][i] = tmp;
        }
    }    

}
```

> 注意组号，这里组号循环是1-32，就横着来的四行一个循环。
>
> <img src="E:\MarkDown\picture\image-20230530122600876.png" alt="image-20230530122600876" style="zoom:50%;" />
>
> <img src="E:\MarkDown\picture\image-20230530122544962.png" alt="image-20230530122544962" style="zoom:67%;" />
>
> 只有对角线处的组号会冲突
>
> <img src="E:\MarkDown\picture\image-20230530122743155.png" alt="image-20230530122743155" style="zoom:67%;" />

## shell lab

> https://zhuanlan.zhihu.com/p/492645370
>
> https://www.bilibili.com/video/BV1EF411h791/

### 输入输出重定向（这里没有实现

​	在Shell中，可以使用输入输出重定向来改变命令的输入来源和输出目标。输入重定向用于改变命令的标准输入，而输出重定向用于改变命令的标准输出。

​	下面是常用的输入输出重定向符号和用法：

1. 输入重定向符号 `<`：用于将文件内容作为命令的输入。 示例：`command < input.txt` 该命令将`input.txt`文件的内容作为`command`命令的输入。
2. 输出重定向符号 `>`：用于将命令的标准输出重定向到文件中，如果文件不存在则创建新文件，如果文件存在则覆盖原文件。 示例：`command > output.txt` 该命令将`command`命令的标准输出写入`output.txt`文件中，如果文件已存在，则会被覆盖。
3. 追加输出重定向符号 `>>`：用于将命令的标准输出追加到文件中，如果文件不存在则创建新文件，如果文件存在则在文件末尾追加内容。 示例：`command >> output.txt` 该命令将`command`命令的标准输出追加到`output.txt`文件的末尾。
4. 错误输出重定向符号 `2>`：用于将命令的错误输出重定向到文件中。 示例：`command 2> error.txt` 该命令将`command`命令的错误输出写入`error.txt`文件中。
5. 合并标准输出和错误输出重定向符号 `&>` 或 `2>&1`：用于将命令的标准输出和错误输出合并，并重定向到文件中。 示例：`command &> output.txt` 或 `command 2>&1 > output.txt` 该命令将`command`命令的标准输出和错误输出合并，并写入`output.txt`文件中。

这些重定向符号可以结合使用，以实现更复杂的输入输出重定向需求。需要注意的是，重定向符号需要出现在命令行中的特定位置，以正确地改变输入输出的行为。	

### sigsuspend函数

> 可以用来实现同步，可以结合其他的信号机制和同步原语来实现同步操作。

​	`sigsuspend` 是一个系统调用函数，用于暂时阻塞当前进程，并等待指定的信号发生。当指定的信号发生时，`sigsuspend`函数会恢复进程的执行。

```c
#include <signal.h>
int sigsuspend(const sigset_t *mask);
```

* `mask`：一个指向`sigset_t`类型的指针，用于指定需要阻塞的信号集。在`sigsuspend`执行期间，这些信号将被阻塞。

​	`mask`参数指定了需要阻塞的信号集合后，`sigsuspend`函数会阻塞当前进程，直到指定的信号发生。一旦发生了指定的信号，进程会被唤醒，并且`sigsuspend`函数会返回-1，并设置`errno`为`EINTR`。

使用`sigsuspend`函数时，一般的步骤如下：

1. 创建一个信号集，并使用`sigemptyset`和`sigaddset`函数设置需要阻塞的信号集。
2. 使用`sigprocmask`函数将进程的信号屏蔽字设置为刚刚创建的信号集，以阻塞指定的信号。
3. 调用`sigsuspend`函数，传递刚刚创建的信号集作为参数。
4. 当指定的信号发生时，进程会被唤醒

###  sigaddset

`sigaddset`是一个宏，用于将指定的信号添加到信号集中。它可以用于设置信号集的成员。

```c
#include <signal.h>
int sigaddset(sigset_t *set, int signum);
// 
sigaddset(&mask_one, SIGCHLD);  // 对子进程结束或停止时发送的SIGCHLD信号添加到信号集中，后面来堵塞他
```

* `set`：指向要操作的信号集。
* `signum`：要添加到信号集中的信号编号。

### sigfillset

sigfillset(&mask_all);  // 将信号集中的所有的标志位置为1，使得这个集合包含所有可接受的信号，也就是阻塞所有信号。这个函数可以用于快速创建一个包含所有信号的信号集
    Sigemptyset(&mask_one);  // 将信号集中的所有的标志位置为0，使得这个集合不包含任何信号，也就是不阻塞任何信号

### sigprocmask

sigprocmask(SIG_BLOCK, &mask_one, &prev_one);       // Sigprocmask函数可以检测或更改信号堵塞集，SIG_BLOCK表示按照参数 set 提供的屏蔽字，屏蔽信号。并将原信号屏蔽保存到oldset中。mask_one的信号之前设置为了SIGCHLD，这里的目的是在fork前阻塞SIGCHLD信号

### 任务

> ​	Shell Lab 要求实现一个带有作业控制的 Unix Shell 程序，需要考虑基础的并发，进程控制以及信号和信号处理。
>
> * `eval`：解析命令行并执行 **[约 70 行]**
> * builtin_cmd：检测是否为内置命令`quit`、`fg`、`bg`、`jobs`**[约 25 行]**
> * do_bgfg：实现内置命令`bg`和`fg`**[约 50 行]**
> * waitfg：等待前台作业执行完成 **[约 20 行]**
> * `sigchld_handler`：处理`SIGCHLD`信号，即子进程停止或者终止 **[约 80 行]**
> * `sigint_handler`：处理`SIGINT`信号，即来自键盘的中断ctrl-c，发送给每个前台进程，默认的动作是终止该进程
> * `sigtstp_handler`：处理`SIGTSTP`信号，ctrl-z 会触发 SIGTSTP 信号并发送给每个前台进程，默认的动作是挂起该进程，直到再收到 SIGCONT 信号才继续

具体的实现规格：

* 每一行会输出一个 tsh>（就是tiny shell的意思，不用管），然后等待用户输入
* 用户的输入包括 name 加上零个或多个参数，这些参数之间用一个或多个空格分隔。如果 `name` 是内置命令，直接在当前进程执行；如果是一个可执行程序的路径，则 `fork一个子进程`，并在子进程中完成具体的工作
* 不需要支持管道，但是需要`支持输入输出重定向`，如 `tsh> /bin/cat < foo > bar`（必须支持在同一行重定向输入以及输出）(foo和bar是通常用作示例的占位符或标识符)
  * 也需要支持内置命令的重定向，如 `tsh> jobs > foo`
* 输入 `ctrl-c` 或 `ctrl-z` 会给当前的前台进程（包括其子进程）发送 SIGINT(SIGTSTP) 信号，如果没有前台任务，那么这俩信号没有任何效果
* 如果输入的命令以 `&` 结尾，那么就要以后台任务的方式执行，也就是说 shell 本身不会等待 job 执行完成，直接可以继续输入其他命令；而在其他情况下，则是在前台运行，shell 会等待 job 完成，用户才可以继续输入命令。也就是说同一个时间只可能有一个前台任务，但是后台任务可以有任意多个。
* 每个 job 都有其进程 ID(PID) 和 job ID(JID)，都是由 tsh 指定的正整数，JID 以 `%` 开头（如 `%5` 表示 JID 为 5，而 `5` 则表示 PID 为 5），这部分已提供了辅助函数
* 支持的内置命令有
  * `quit` 退出 shell
  * `jobs` 列出所有的后台任务
  * `bg job` 给后台 `job` 发送 SIGCONT 信号来继续执行该任务，具体的 `job` 数值可以是 PID 或 JID
  * `fg job` 给前台 `job` 发送 SIGCONT 信号来继续执行该任务，具体的 `job` 数值可以是 PID 或 JID
* tsh 应该回收所有的僵尸进程，如果任何 job 因为接收了没有 catch 的信号而终止，tsh 应该识别出这个时间并且打印出 JID 和相关信号的信息

### 进程终止

进程会以三种原因终止：

* 收到一个信号，该信号的默认行为是终止进程
* 从主程序返回
* 调用 exit 函数，以 status 退出状态来终止进程。status 为退出状态码，用于向操作系统传递程序的退出状态信息。通常情况下，返回值为0表示程序正常终止，而非零值表示程序异常终止，可以用来表示不同的错误或状态。`exit` 函数的调用会立即终止当前程序的执行，执行终止后，程序会退出，并将退出状态码传递给操作系统。此时，操作系统可以根据退出状态码进行相应的处理，如记录日志、终止父进程等。

### waitpid函数

> 回收子进程

​	当一个子进程结束执行但父进程没有回收其资源时，该子进程会成为一个僵尸进程。在这种情况下，内核会将子进程的相关信息保留在系统进程表中，但不再执行任何操作。

​	init进程会定期检查系统进程表中是否存在僵尸进程，如果发现僵尸进程，init进程会调用`wait`或`waitpid`函数回收僵尸进程的资源。这样，僵尸进程会被完全回收，其占用的系统资源会被释放。

​	需要注意的是，虽然init进程会负责回收僵尸进程，但这并不是一种理想的做法。更好的方式是在父进程中显式地调用`wait`或`waitpid`函数回收子进程的资源，以避免产生大量的僵尸进程。及时回收僵尸进程可以提高系统的性能和稳定性。

​	对于一个长时间运行的程序（比如 Shell）来说，内核不会安排`init`进程去回收僵死进程，而它虽不运行却仍然消耗系统资源，因此实验要求我们回收所有的僵死进程。

​	一个进程可以通过调用waitpid函数来等待它的子进程终止或者停止，并获取子进程的退出状态。

```cpp
pid_t waitpid(pid_t pid, int *wstatus, int options);
```

​	`WNOHANG` 是一个常量，用于在调用 `waitpid` 函数时设置特定的选项options。它用于在非阻塞模式下检查子进程的状态，即使子进程当前没有终止。当使用`WNOHANG`选项时，`waitpid`函数立即返回，而不会阻塞父进程的执行。如果没有任何子进程终止，`waitpid`返回0。如果有子进程终止，`waitpid`返回子进程的进程ID。

等待进程改变状态



这个函数用来挂起调用进程的执行，直到`pid`对应的等待集合的一个子进程的改变才返回，包括三种状态的改变：

* 子进程终止（如果没释放资源，会变成僵尸进程）
* 子进程收到信号停止
* 子进程收到信号重新执行

各参数含义及使用

* **pid：判定等待集合成员**
* * pid > 0 : 等待集合为 pid 对应的单独子进程
  * pid = -1: 等待集合为所有的子进程
  * pid < -1: 等待集合为一个进程组，ID 为 pid 的绝对值
  * pid = 0 : 等待集合为一个进程组，ID 为调用进程的 pid
* `options`：用于指定等待的选项，可以使用以下常量进行控制：
  * `WNOHANG(0x1)`：非阻塞模式，即如果没有符合条件的子进程退出状态可获取，则立即返回。即子进程没改变状态，就立即返回
  * `WUNTRACED`：阻塞，直到一个进程终止或停止，返回 PID
  * `WCONTINUED`：阻塞，直到一个停止的进程收到 SIGCONT 信号重新开始执行
  * 可以使用位操作符`|`组合多个选项。例如 WNOHANG | WUNTRACED 表示：立即返回，如果等待集合中的子进程都没有被终止，则返回值为 0；如果有一个停止或终止，则返回值为该子进程的 PID

* **statusp：检查已回收子进程的退出状态**

  * waitpid 会在 status 中放上关于导致返回的子进程的状态信息，很容易理解，这里就不再翻译了

  * 对于int型的statusp，有几个函数可以搭配使用

  * * WIFEXITED(statusp) 正常终止则返回true
    * WIFSIGNALED(statusp) 因为信号而终止terminated
    * WIFSTOPPED(statusp) 因为信号而停止stopped，如WCONTINUED堵塞

函数返回值：

* 若成功等待到子进程的状态改变，则返回子进程的进程ID。
* 若指定了`WNOHANG`选项且没有符合条件的子进程状态改变可获取，则返回0。
* 若发生错误，则返回-1，并设置`errno`来指示具体错误原因。



kill：发送一个信号

```cpp
kill(pid, SIGINT);  // thread
kill(-pid, SIGINT);  // thread group
```



### 竞争关系

![img](E:\MarkDown\picture\v2-5374b426b86ecb7c912783c964f02a94_1440w.webp)

这是一个 Unix Shell 的框架，父进程在一个全局列表中记录子进程，并设置了一个 SIGCHLD 处理程序来回收子进程，乍一看没问题，但是考虑如下可能的事件序列：

* 第 29 行，创建子进程运行
* 假设子进程在父进程运行到 32 行，即运行`addjob`函数(在jobs列表中添加job)之前就结束了，并发送一个 SIGCHLD 信号
* 父进程接收到信号，运行信号处理程序，调用`deletejob`函数(在jobs列表中删除pid对应的job，因为已经交给子进程执行了)，而这个`job`本来就没有添加入列表
* 返回父进程，调用`addjob`函数，而这个子进程已经终止并回收了，`job`早就不存在了

也就是说，在这里，`deletejob`函数的调用发生在了`addjos`之前，导致错误。我们称`addjob`和`deletejob`存在竞争。

解决办法也就很容易想到了，即在父进程`folk`之前就阻塞 SIGCHLD 信号：

<img src="E:\MarkDown\picture\v2-8d7ed8b29310292108044a8f4ab923f8_1440w.webp" alt="img" style="zoom:75%;" />

这样，父进程在`fork`后，`addjob`前一定不会处理 SIGCHLD 信号，保证了`addjob`一定在`deletejob`之前执行



Sigprocmask(SIG_BLOCK, &mask_one, &prev_one);       // Sigprocmask函数可以检测或更改信号堵塞集，SIG_BLOCK表示按照参数 set 提供的屏蔽字，屏蔽信号。并将原信号屏蔽保存到oldset中。mask_one的信号为SIGCHLD，这里的目的是在fork前阻塞SIGCHLD信号



### 代码

### eval

​	这个函数功能是解析命令行后判断为内置命令还是程序路径，分别执行。如果是前台作业，则要等待其完成，如果是后台作业，则要输出其相应信息

* 为什么调用`printf`时也阻塞信号？

* * 因为这里打印了全局变量，而`printf`函数是线程不安全的，比如可能会出现读内存的同时另一个线程修改它的情况

* 为什么要在执行前创建新线程组？

* * 因为这里主要是为了将子进程组与 tsh 进程组分开，防止发信号终止子进程组时也将 tsh 进程组终止了

```cpp
/* 
 * eval - Evaluate the command line that the user has just typed in
 * 
 * If the user has requested a built-in command (quit, jobs, bg or fg)
 * then execute it immediately. Otherwise, fork a child process and
 * run the job in the context of the child. If the job is running in
 * the foreground, wait for it to terminate and then return.  Note:
 * each child process must have a unique process group ID so that our
 * background children don't receive SIGINT (SIGTSTP) from the kernel
 * when we type ctrl-c (ctrl-z) at the keyboard.  
*/
void eval(char *cmdline) {  // 此函数的作用是解析命令行
    char *argv[MAXARGS];        //存放解析的参数
    char buf[MAXLINE];          //解析cmdline
    int bg;                     //判断程序是前台还是后台执行
    int state;                  //指示前台还是后台运行状态
    pid_t pid;                  //执行程序的子进程的pid

    strcpy(buf, cmdline);   
    bg = parseline(buf, argv);  //解析参数
    state = bg? BG:FG;          
    if(argv[0] == NULL)         //空行，直接返回
        return;
    sigset_t mask_all, mask_one, prev_one;  // sigset_t 信号集类型
    Sigfillset(&mask_all);  // 将信号集中的所有的标志位置为1，使得这个集合包含所有可接受的信号，也就是阻塞所有信号。这个函数可以用于快速创建一个包含所有信号的信号集
    Sigemptyset(&mask_one);  // 将信号集中的所有的标志位置为0，使得这个集合不包含任何信号，也就是不阻塞任何信号
    Sigaddset(&mask_one, SIGCHLD);  // 子进程结束或停止时发送。不进行处理就会出现僵尸进程
    if( !builtin_cmd(argv) ) {                            // 自己实现的函数，判断是否为内置命令
        Sigprocmask(SIG_BLOCK, &mask_one, &prev_one);       // 屏蔽mask_one信号，即SIGCHLD信号，这里的目的是在fork前阻塞SIGCHLD信号
        if((pid = Fork()) == 0) {                           //创建子进程
            Sigprocmask(SIG_SETMASK, &prev_one, NULL);      // 解除堵塞
            Setpgid(0, 0);                                  //创建新进程组，ID设置为进程PID
            Execve(argv[0], argv, environ);                 //执行argv[0]，argv为要调用的程序需要传入的参数
            exit(0);                                        //子线程执行完毕后一定要退出
        }
        if (state==FG){
            Sigprocmask(SIG_BLOCK, &mask_all, NULL);            //添加工作前阻塞所有信号
            addjob(jobs, pid, state, cmdline);                  //添加至作业列表
            Sigprocmask(SIG_SETMASK, &mask_one, NULL);
            waitfg(pid);                                        //等待前台进程执行完毕
        } else{
            Sigprocmask(SIG_BLOCK, &mask_all, NULL);            //添加工作前阻塞所有信号
            addjob(jobs, pid, state, cmdline);                  //添加至作业列表
            Sigprocmask(SIG_SETMASK, &mask_one, NULL);                                 
            printf("[%d] (%d) %s",pid2jid(pid), pid, cmdline);  //打印后台进程信息
        }
        Sigprocmask(SIG_SETMASK, &prev_one, NULL);          //解除阻塞 
    }
    return;
}
```

### **builtin_cmd**

这个函数就是简简单单判断是否为内置命令

```cpp
/* 
 * builtin_cmd - If the user has typed a built-in command then execute
 *    it immediately.  
 */
int builtin_cmd(char **argv) 
{
    if (!strcmp(argv[0], "quit"))  // strcmp比较两个字符串是否相等
        exit(0);
    if (!strcmp(argv[0], "bg") || !strcmp(argv[0], "fg")) {
        do_bgfg(argv);  // 自定义函数
        return 1;
    }
    if (!strcmp(argv[0], "jobs")) {
        listjobs(jobs);  // 打印jobs列表，这个函数不用管
        return 1;
    }
    if (!strcmp(argv[0], "&"))
        return 1;
    return 0;     /* not a builtin command */
}
```

### do_bgfg

这个函数要实现内置命令`bg`和`fg`，这两个命令的功能如下：

* `bg <job>`：通过向`<job>`对应的作业发送`SIGCONT`信号来使它重启并放在后台运行
* `fg <job>`：通过向 `<job>`对应的作业发送`SIGCONT`信号来使它重启并放在前台运行
* 输入时后面的参数有`%`则代表`jid`，没有则代表`pid`

```cpp
/* 
 * do_bgfg - Execute the builtin bg and fg commands
 */
void do_bgfg(char **argv) 
{
    struct job_t *job = NULL;        //要处理的job
    int state;                      //输入的命令
    int id;                         //存储jid或pid
    
    if(!strcmp(argv[0], "bg")) state = BG;
    else state = FG;  
    
    if(argv[1]==NULL){               //没带参数
        printf("%s command requires PID or %%jobid argument\n", argv[0]);
        return;
    }
    if(argv[1][0]=='%'){             //说明是jid
       if(sscanf(&argv[1][1], "%d", &id) > 0){
            job = getjobjid(jobs, id);  //获得job
            if(job==NULL){
                printf("%%%d: No such job\n", id);
                return;
            }
        }
    } else if(!isdigit(argv[1][0])) {  //其它符号，非法输入
        printf("%s: argument must be a PID or %%jobid\n", argv[0]);
        return;
    } else {                       //pid
        id = atoi(argv[1]);
        job = getjobpid(jobs, id);
        if(job==NULL){
            printf("(%d): No such process\n", id);
            return;
        }
    }
    
    
    Kill(-(job->pid), SIGCONT);       //重启进程, 这里发送到进程组
    job->state = state;
    if(state==BG)
        printf("[%d] (%d) %s",job->jid, job->pid, job->cmdline);
    else 
        waitfg(job->pid);  // 放到前台运行
    return;
}
```



### waitfg

​	这个函数从要求实现阻塞父进程，直到当前的前台进程不再是前台进程了。这里显然要显示地等待信号，我们先回顾一下相关知识

回顾：显式地等待信号

考虑如下代码：

```c
while( fgpid(jobs) != 0 ) // 返回前台运行的job的pid
    pause();
```

这里会有一个竞争，并且它可能引起致命的错误！考虑如下事件序列：

* 父进程调用`fgpid`函数，此时有一个子进程仍然在前台运行，所以判断条件为真，进入循环
* 假定父进程在进入循环后，而执行`pause`前，子进程终止
* 父进程接收到 SIGCHLD 信号，并处理结束后才调用`pause`

由于`pause`仅在捕捉到信号后返回，而之后不会再有任何信号抵达，那么父进程就会永远休眠！

解决办法是用`sleep`函数：因为它不依赖信号来返回，通过每次循环来监测子进程状态

也可以用`sigsuspend`函数，这个函数相当于如下代码：

```c
sigprocmask(SIG_SETMASK, &mask, &prev);
pause();
sigprocmask(SIG_SETMASK, &prev, NULL);
```

​	在调用`sigsuspend`之前阻塞 SIGCHLD 信号，调用时又通过`sigprocmask`函数，在执行`pause`函数之前解除对信号的阻塞，从而正常休眠。

​	`sigsuspend`相当于上述代码的原子版本，即第 1 行和第 2 行总是一起发生的，不会被中断！

```c
/* 
 * waitfg - Block until process pid is no longer the foreground process
 */
void waitfg(pid_t pid)
{
    sigset_t mask;
    Sigemptyset(&mask);   
    while (fgpid(jobs) != 0){
        sigsuspend(&mask);      //暂停时取消阻塞,见sigsuspend用法
    }
    return;
}
```

### 信号处理函数

sigchld_handler

实现一个 SIGCHLD 信号处理函数，能够回收所有僵死进程

利用`waitpid`函数，检测子进程的退出状态来实现相应操作，如回收子进程，打印相关信息等等。

```cpp
/* 
 * sigchld_handler - The kernel sends a SIGCHLD to the shell whenever
 *     a child job terminates (becomes a zombie), or stops because it
 *     received a SIGSTOP or SIGTSTP signal. The handler reaps all
 *     available zombie children, but doesn't wait for any other
 *     currently running children to terminate.  
 */
void sigchld_handler(int sig) 
{
    int olderrno = errno;   //由于errno是全局变量,注意保存和恢复errno
    int status;
    pid_t pid;
    struct job_t *job;
    sigset_t mask, prev;
    sigfillset(&mask);
    
    while ( ( pid = waitpid(-1, &status, WNOHANG | WUNTRACED) ) > 0 ) {      // 如果等待集合中的子进程都没有被终止，则返回值为 0；如果有一个停止或终止，则返回值为该子进程的 PID
        // 进入循环，说明Pid这个进程终止，需要进行回收
        sigprocmask(SIG_BLOCK, &mask, &prev);   //阻塞所有信号
        if ( WIFEXITED(status) ){                 //正常终止
            deletejob(jobs, pid);
        } else if ( WIFSIGNALED(status) ) {          //因为信号而终止, 打印
            printf ("Job [%d] (%d) terminated by signal %d\n", pid2jid(pid), pid, WTERMSIG(status));
            deletejob(jobs, pid);
        } else if (WIFSTOPPED(status)){           //因为信号而停止, 打印
            printf ("Job [%d] (%d) stoped by signal %d\n", pid2jid(pid), pid, WSTOPSIG(status));
            job = getjobpid(jobs, pid);
            job->state = ST;
        }
        sigprocmask(SIG_SETMASK, &prev, NULL);  // 解除堵塞
    }
    errno = olderrno;
    return;
}
```



## malloc lab

> 对应第九章：虚拟内存
>
> https://zhuanlan.zhihu.com/p/496366818
>
> https://www.bilibili.com/video/BV1aZ4y1P7fs

### 宏和内联函数

使用宏，可以避免函数调用，也就少了很多跳转和对应的栈处理

内联函数会在编译的时候被写入到代码中，同样因为不需要真实的函数调用，所以效率也很高。一般来说，比较小的函数都可以设置为内联。

两者之间的差别在于：

* 宏在编译前处理
* 内联函数在编译时处理（带有类型检查）
* 宏不能有返回值
* 宏可能会带来一些副作用
* 很难调试宏

### 原理

见c++备战



### 任务

> 实现c语言中malloc、free内存管理系统。
>
> 内存管理**实际上就是设计一个高效地管理一个字节数组中内容的数据结构**（这个数组在实际的进程中其实就是进程的堆空间）。

```c
// 实现以下函数
int mm_init(void);
void *malloc(size_t size);
void free(void *ptr);
void *realloc(void *ptr, size_t size);
void *calloc(size_t nmemb, size_t size);
void mm_checkheap(int);
```

* `mm-init`：在这里执行所有的初始化操作，包括分配初始的堆区域。注意，必须在这里重新初始化所有的全局变量，并且不要调用 `mem.init` 函数。成功的话返回 0 ，否则返回 -1
* `malloc`：至少需要分配 `size` 这么大的空间（可能因为对齐的原因会更大一点，8 byte 对齐），不能超出堆的范围，也不能覆盖其他已分配的区域
* `free`：释放 `ptr` 指针指向的区域（这个区域必须是已分配的），`free(NULL)` 什么都不做
* `realloc`：重新分配，根据传入指针的不同，有不同的表现
  * `ptr` 为 NULL 时，等同于 `malloc(size)`
  * `size` 为 0 时，等同于 `free(ptr)`，需要返回 NULL
  * `ptr` 不为 NULL 时，一定是指向一个已分配的空间的，就根据新的 size 的大小进行调整，并让 `ptr` 指向新的地址（如果是新地址的话），并且旧的区域应该被释放。另外需要注意的是，需要把原来 block 的值复制过去
* `calloc`：分配一个有 `nmemb` 个大小为 `size` 的数组，这个函数不评分，只要简单实现即可
* `mm_checkheap`：扫描堆并检查其状态，注意，只有在检测到错误时才输出内容并调用 `exit` 退出。`mm_heapchecker(__Line__);` 传入的参数是当前行数，方便大家找到错误位置。



### 思路

分离的空闲链表（分离适配 Segregated Free Lists）

​	脚部与头部是相同的，均为 4 个字节，用来存储块的大小，以及表明这个块是已分配还是空闲块，而指针为4字节，因此每个空闲块最小为16字节。

<img src="E:\MarkDown\picture\image-20230531213124448.png" alt="image-20230531213124448" style="zoom: 67%;" />

<img src="E:\MarkDown\picture\image-20230531213015814.png" alt="image-20230531213015814" style="zoom: 50%;" />

<img src="E:\MarkDown\picture\image-20230531213029469.png" alt="image-20230531213029469" style="zoom: 50%;" />

<img src="E:\MarkDown\picture\image-20230531214616703.png" alt="image-20230531214616703" style="zoom:50%;" />

* 堆结构的前面放置不同等价类空闲块的头指针



```c
/*
 * mm-naive.c - The fastest, least memory-efficient malloc package.
 * 
 * In this naive approach, a block is allocated by simply incrementing
 * the brk pointer.  A block is pure payload. There are no headers or
 * footers.  Blocks are never coalesced or reused. Realloc is
 * implemented directly using mm_malloc and mm_free.
 *
 * NOTE TO STUDENTS: Replace this header comment with your own header
 * comment that gives a high level description of your solution.
 */
#include <stdio.h>
#include <stdlib.h>
#include <assert.h>
#include <unistd.h>
#include <string.h>

#include "mm.h"
#include "memlib.h"

/*********************************************************
 * NOTE TO STUDENTS: Before you do anything else, please
 * provide your team information in the following struct.
 ********************************************************/
team_t team = {
    /* Team name */
    "haha",
    /* First member's full name */
    "deconx",
    /* First member's email address */
    "deconx@qq.com",
    /* Second member's full name (leave blank if none) */
    "",
    /* Second member's email address (leave blank if none) */
    ""
};

/* single word (4) or double word (8) alignment */
#define ALIGNMENT 8

/* rounds up to the nearest multiple of ALIGNMENT */
#define ALIGN(size) (((size) + (ALIGNMENT-1)) & ~0x7)


#define SIZE_T_SIZE (ALIGN(sizeof(size_t)))

/* 头部/脚部的大小 */
#define WSIZE 4
/* 双字 */
#define DSIZE 8

/* 扩展堆时的默认大小 */
#define CHUNKSIZE (1 << 12)

#define MAX(x, y) ((x) > (y)? (x) : (y))

/* 设置头部和脚部的值, 块大小+分配位 */
#define PACK(size, alloc) ((size) | (alloc))

/* 读写指针p的位置 */
#define GET(p) (*(unsigned int *)(p))
#define PUT(p, val) ( (*(unsigned int *)(p)) = (val) )

/* 从头部或脚部获取大小或分配位 */
#define GET_SIZE(p) (GET(p) & ~0x7)
#define GET_ALLOC(p) (GET(p) & 0x1)


/* 给定序号，找到链表头节点位置 */
#define GET_HEAD(num) ((unsigned int *)(long)(GET(heap_list + WSIZE * num)))
/* 给定bp,找到前驱和后继 */
#define GET_PRE(bp) ((unsigned int *)(long)(GET(bp)))
#define GET_SUC(bp) ((unsigned int *)(long)(GET((unsigned int *)bp + 1)))

/* 读地址存的指针 */
#define GET_PTR(p) ((unsigned int *)(long)(GET(p)))

/* 给定有效载荷指针, 找到头部和脚部 */
#define HDRP(bp) ((char*)(bp) - WSIZE)
#define FTRP(bp) ((char*)(bp) + GET_SIZE(HDRP(bp)) - DSIZE)

/* 给定有效载荷指针, 找到前一块或下一块 */
#define NEXT_BLKP(bp) ((char*)(bp) + GET_SIZE(((char*)(bp) - WSIZE)))
#define PREV_BLKP(bp) ((char*)(bp) - GET_SIZE(((char*)(bp) - DSIZE)))

#define CLASS_SIZE 20
/* 总是指向序言块的第二块 */
static char *heap_list;

/************************/
static void *extend_heap(size_t words);     //扩展堆
static void *coalesce(void *bp);            //合并空闲块
static void *find_fit(size_t asize);        //找到匹配的块
static void place(void *bp, size_t asize);  //分割空闲块
static void delete(void *bp);               //从相应链表中删除块
static void insert(void *bp);               //在对应链表中插入块
static int search(size_t size);             //根据块大小, 找到头节点位置
/* 
 * mm_init - initialize the malloc package.
 */
int mm_init(void)
{
    /* 申请四个字节空间 */
    if( (heap_list = mem_sbrk((4+CLASS_SIZE)*WSIZE)) == (void *)-1 )
        return -1;
    /* 初始化20个大小类头指针 */
    for(int i = 0; i < CLASS_SIZE; i++){
        PUT(heap_list + i*WSIZE, NULL);
    }
    /* 对齐 */
    PUT(heap_list + CLASS_SIZE * WSIZE, 0);
    /* 
     * 序言块和结尾块均设置为已分配, 方便考虑边界情况
     */
    PUT(heap_list + ((1 + CLASS_SIZE)*WSIZE), PACK(DSIZE, 1));     /* 填充序言块 */
    PUT(heap_list + ((2 + CLASS_SIZE)*WSIZE), PACK(DSIZE, 1));     /* 填充序言块 */
    PUT(heap_list + ((3 + CLASS_SIZE)*WSIZE), PACK(0, 1));         /* 结尾块 */


    /* 扩展空闲空间 */
    if(extend_heap(CHUNKSIZE/WSIZE) == NULL)
        return -1;
    return 0;
}


/*
 * 扩展heap, 传入的是字节数
*/
void *extend_heap(size_t words)
{
    /* bp总是指向有效载荷 */
    char *bp;
    size_t size;
    /* 根据传入字节数奇偶, 考虑对齐 */
    size = (words % 2) ? (words+1) * WSIZE : words * WSIZE;

    /* 分配 */
    if((long)(bp = mem_sbrk(size)) == -1)
        return NULL;
    
    /* 设置头部和脚部 */
    PUT(HDRP(bp), PACK(size, 0));           /* 空闲块头 */
    PUT(FTRP(bp), PACK(size, 0));           /* 空闲块脚 */
    PUT(HDRP(NEXT_BLKP(bp)), PACK(0, 1));   /* 片的新结尾块 */

    /* 判断相邻块是否是空闲块, 进行合并 */
    return coalesce(bp);
}


/*
 * 合并空闲块
*/
void *coalesce(void *bp)
{
    size_t prev_alloc = GET_ALLOC(FTRP(PREV_BLKP(bp)));     /* 前一块大小 */
    size_t next_alloc = GET_ALLOC(HDRP(NEXT_BLKP(bp)));     /* 后一块大小 */
    size_t size = GET_SIZE(HDRP(bp));                       /* 当前块大小 */

    /*
     * 四种情况：前后都不空, 前不空后空, 前空后不空, 前后都空
     */
    /* 前后都不空 */
    if(prev_alloc && next_alloc){
        insert(bp);
        return bp;
    }
    /* 前不空后空 */
    else if(prev_alloc && !next_alloc){
        /* 将后面的块从其链表中删除 */
        delete(NEXT_BLKP(bp));
        size += GET_SIZE(HDRP(NEXT_BLKP(bp)));  //增加当前块大小
        PUT(HDRP(bp), PACK(size, 0));           //先修改头
        PUT(FTRP(bp), PACK(size, 0));           //根据头部中的大小来定位尾部
    }
    /* 前空后不空 */
    else if(!prev_alloc && next_alloc){
        /* 将其前面的快从链表中删除 */
        delete(PREV_BLKP(bp));
        size += GET_SIZE(HDRP(PREV_BLKP(bp)));  //增加当前块大小
        PUT(FTRP(bp), PACK(size, 0));
        PUT(HDRP(PREV_BLKP(bp)), PACK(size, 0));
        bp = PREV_BLKP(bp);                     //注意指针要变
    }
    /* 都空 */
    else{
        /* 将前后两个块都从其链表中删除 */
        delete(NEXT_BLKP(bp));
        delete(PREV_BLKP(bp));
        size += GET_SIZE(HDRP(PREV_BLKP(bp))) + GET_SIZE(FTRP(NEXT_BLKP(bp)));  //增加当前块大小
        PUT(FTRP(NEXT_BLKP(bp)), PACK(size, 0));
        PUT(HDRP(PREV_BLKP(bp)), PACK(size, 0));
        bp = PREV_BLKP(bp);
    }
    /* 空闲块准备好后,将其插入合适位置 */
    insert(bp);
    return bp;
}
/*
 *  插入块, 将块插到表头
 */
void insert(void *bp)
{
    /* 块大小 */
    size_t size = GET_SIZE(HDRP(bp));
    /* 根据块大小找到头节点位置 */
    int num = search(size);
    /* 空的，直接放 */
    if(GET_HEAD(num) == NULL){
        PUT(heap_list + WSIZE * num, bp);
        /* 前驱 */
        PUT(bp, NULL);
		/* 后继 */
        PUT((unsigned int *)bp + 1, NULL);
	} else {
        /* bp的后继放第一个节点 */
		PUT((unsigned int *)bp + 1, GET_HEAD(num));
		/* 第一个节点的前驱放bp */
        PUT(GET_HEAD(num), bp);
        /* bp的前驱为空 */  	
		PUT(bp, NULL);
        /* 头节点放bp */
		PUT(heap_list + WSIZE * num, bp);
	}
}
/*
 *  删除块,清理指针
 */
void delete(void *bp)
{
    /* 块大小 */
    size_t size = GET_SIZE(HDRP(bp));
    /* 根据块大小找到头节点位置 */
    int num = search(size);
    /* 
     * 唯一节点,后继为null,前驱为null 
     * 头节点设为null
     */
	if (GET_PRE(bp) == NULL && GET_SUC(bp) == NULL) { 
		PUT(heap_list + WSIZE * num, NULL);
	} 
    /* 
     * 最后一个节点 
     * 前驱的后继设为null
     */
    else if (GET_PRE(bp) != NULL && GET_SUC(bp) == NULL) {
		PUT(GET_PRE(bp) + 1, NULL);
	} 
    /* 
     * 第一个结点 
     * 头节点设为bp的后继
     */
    else if (GET_SUC(bp) != NULL && GET_PRE(bp) == NULL){
		PUT(heap_list + WSIZE * num, GET_SUC(bp));
		PUT(GET_SUC(bp), NULL);
	}
    /* 
     * 中间结点 
     * 前驱的后继设为后继
     * 后继的前驱设为前驱
     */
    else if (GET_SUC(bp) != NULL && GET_PRE(bp) != NULL) {
		PUT(GET_PRE(bp) + 1, GET_SUC(bp));
		PUT(GET_SUC(bp), GET_PRE(bp));
	}
}
/* 
 * search - 找到块大小对应的等价类的序号
 */
int search(size_t size)
{
    int i;
    for(i = 4; i <=22; i++){
        if(size <= (1 << i))
            return i-4;
    }
    return i-4;
    // if (size <= (1 << 4)) {
	// 	return 0;
	// } else if (size <= (1 << 5)) {
	// 	return 1;
	// } else if (size <= (1 << 6)) {
	// 	return 2;
	// } else if (size <= (1 << 7)) {
	// 	return 3;
	// } else if (size <= (1 << 8)) {
	// 	return 4;
	// } else if (size <= (1 << 9)) {
	// 	return 5;
	// } else if (size <= (1 << 10)) {
	// 	return 6;
	// } else if (size <= (1 << 11)) {
	// 	return 7;
	// } else if (size <= (1 << 12)) {
	// 	return 8;
	// } else if (size <= (1 << 13)) {
	// 	return 9;
	// } else if (size <= (1 << 14)) {
	// 	return 10;
	// } else if (size <= (1 << 15)) {
	// 	return 11;
	// } else if (size <= (1 << 16)) {
	// 	return 12;
	// } else if (size <= (1 << 17)) {
	// 	return 13;
	// } else if (size <= (1 << 18)) {
	// 	return 14;
	// } else if (size <= (1 << 19)) {
	// 	return 15;
	// } else if (size <= (1 << 20)) {
	// 	return 16;
	// } else if (size <= (1 << 21)){
	// 	return 17;
	// } else if (size <= (1 << 22)){
    //     return 18;
    // } else {
    //     return 19;
    // }
}
/* 
 * mm_malloc - Allocate a block by incrementing the brk pointer.
 *     Always allocate a block whose size is a multiple of the alignment.
 */
void *mm_malloc(size_t size)
{
    // int newsize = ALIGN(size + SIZE_T_SIZE); //对齐后的大小
    // void *p = mem_sbrk(newsize);
    // if (p == (void *)-1)
	//     return NULL;
    // else {
    //     *(size_t *)p = size;
    //     return (void *)((char *)p + SIZE_T_SIZE);
    // }
    size_t asize;
    size_t extendsize;
    char *bp;
    if(size == 0)
        return NULL;
    if(size <= DSIZE)
        asize = 2*DSIZE;
    else
        asize = DSIZE * ((size + (DSIZE) + (DSIZE-1)) / DSIZE);
    /* 寻找合适的空闲块 */
    if((bp = find_fit(asize)) != NULL){
        place(bp, asize);
        return bp;
    }
    /* 找不到则扩展堆 */
    extendsize = MAX(asize, CHUNKSIZE);
    if((bp = extend_heap(extendsize/WSIZE)) == NULL)
        return NULL;
    place(bp, asize);
    return bp;

}

/*
 * 适配
 */
void *find_fit(size_t asize)
{
    int num = search(asize);
    unsigned int* bp;
    /* 如果找不到合适的块，那么就搜索下一个更大的大小类 */
    while(num < CLASS_SIZE) {
        bp = GET_HEAD(num);
        /* 不为空则寻找 */
        while(bp) {
            if(GET_SIZE(HDRP(bp)) >= asize){
                return (void *)bp;
            }
            /* 用后继找下一块 */
            bp = GET_SUC(bp);
        }
        /* 找不到则进入下一个大小类 */
        num++;
    }
    return NULL;
}

/*
 * 分离空闲块
 */
void place(void *bp, size_t asize)
{
    size_t csize = GET_SIZE(HDRP(bp));
    
    /* 块已分配，从空闲链表中删除 */
    delete(bp);
    if((csize - asize) >= 2*DSIZE) {
        PUT(HDRP(bp), PACK(asize, 1));
        PUT(FTRP(bp), PACK(asize, 1));
        /* bp指向空闲块 */
        bp = NEXT_BLKP(bp);
        PUT(HDRP(bp), PACK(csize - asize, 0));
        PUT(FTRP(bp), PACK(csize - asize, 0));
        /* 加入分离出来的空闲块 */
        insert(bp);
    }
    /* 设置为填充 */
    else{
        PUT(HDRP(bp), PACK(csize, 1));
        PUT(FTRP(bp), PACK(csize, 1));
    }
}
/*
 * mm_free - Freeing a block does nothing.
 */
void mm_free(void *ptr)
{
    if(ptr==0)
        return;
    size_t size = GET_SIZE(HDRP(ptr));

    PUT(HDRP(ptr), PACK(size, 0));
    PUT(FTRP(ptr), PACK(size, 0));
    coalesce(ptr);
}

/*
 * mm_realloc - Implemented simply in terms of mm_malloc and mm_free
 */
void *mm_realloc(void *ptr, size_t size)
{
    /* size可能为0,则mm_malloc返回NULL */
    void *newptr;
    size_t copysize;
    
    if((newptr = mm_malloc(size))==NULL)
        return 0;
    copysize = GET_SIZE(HDRP(ptr));
    if(size < copysize)
        copysize = size;
    memcpy(newptr, ptr, copysize);
    mm_free(ptr);
    return newptr;
}
```



# ==WebRTC流媒体服务器==

## 背景

> 为什么做？

一开始做了一个webserver，感觉过于简单，想在上面加一些功能。

> 功能

基于最著名的开源项目、支持多人互动、高负载、大并发、实时传输

WebRTC：

介绍：Google开源的项目；跨平台，所有系统都能运行；可以用于浏览器的一个实时通信；

功能：实时传输(500ms内)；音视频引擎(支持多种编解码器、实现音视频的同步(在延迟比较大的情况下保持声音和画面的同步))

流媒体服务器：
<img src="E:\MarkDown\picture\image-20230523190144392.png" alt="image-20230523190144392" style="zoom: 43%;" />

将WebRTC扩展为多对多的，如多人间的实时互动



<img src="E:\MarkDown\picture\image-20230523190558424.png" alt="image-20230523190558424" style="zoom:40%;" />



## 课程结构

![image-20230523190651228](E:\MarkDown\picture\image-20230523190651228.png)



<img src="E:\MarkDown\picture\image-20230523190747940.png" alt="image-20230523190747940" style="zoom:50%;" />

### 后台服务

Linux下服务要想长久，需要放到后台，就是没有界面的。要是前台的话，把终端关掉等操作就会造成程序的终止

如何将进程切换到后台/如何创建守护进程：

<img src="E:\MarkDown\picture\image-20230523194249521.png" alt="image-20230523194249521" style="zoom:33%;" />

#### fork

<img src="E:\MarkDown\picture\image-20230523194449016.png" alt="image-20230523194449016" style="zoom:50%;" />



注意这里把printf换为cout、且少了<fcntl.h>这个头文件

此时这个后台进程的父进程是init，进程号为1

<img src="E:\MarkDown\picture\image-20230523194722021.png" alt="image-20230523194722021" style="zoom: 50%;" />

<img src="E:\MarkDown\picture\image-20230523194809524.png" alt="image-20230523194809524" style="zoom:50%;" />

#### daemon(更简单)

调用一下这个API即可

第一个0表示切换到根目录下，第二个0表示重定向到Null下

<img src="E:\MarkDown\picture\image-20230523195748104.png" alt="image-20230523195748104" style="zoom:50%;" />









# 线程池项目代码

## 第一版

.cpp

```cpp
#include"threadpool.h"

const int TASK_MAX_THRESHHOLD = 1024;
const int THREAD_MAX_THRESHHOLD = 100;
const int THREAD_MAX_IDLE_TIME = 10;  // 等待的时间，s
//////////////////////  Task方法实现
Task::Task(): result_(nullptr) {}
// 在task对应的result类进行构造的时候调用，将新创建的result绑定到当前的task上
// 即为task中指向Result的成员变量result_赋值，之后就可以通过这个指针，将task的结果存到Result对象中了
void Task::setResult(Result* res) {
	result_ = res;
}
void Task::exec() {
	// run，并将任务的返回值保存在Result类中
	if (result_ != nullptr) {
		result_->setVal(run());  // run在这里发生多态调用
	}
}

//////////////////////  线程池方法实现
ThreadPool::ThreadPool()
	: initThreadSize_(4)
	, taskSize_(0)
	, taskQueMaxThreshHold_(TASK_MAX_THRESHHOLD)
	, threadSizeThreshHold_(THREAD_MAX_THRESHHOLD)
	, poolMode_(PoolMode::MODE_FIXED)
	, isPoolRunning_(false)
	, curThreadSize_(0)
	, idleThreadSize_(0)
{}

ThreadPool::~ThreadPool() {
	isPoolRunning_ = false;
	// 等待线程池中所有的线程返回
	// 两种状态：阻塞 / 执行中
	// 这里就需要进行线程的通信
	std::unique_lock<std::mutex> lock(taskQueMtx_);
	notEmpty_.notify_all();
	exitCond_.wait(lock, [&]()->bool {return threads_.size() == 0; });
}

// 设置cached模式下线程阈值
void ThreadPool::setThreadSizeThreshHold(int threshhold) {
	if (checkRunningState()) return;
	if (poolMode_ == PoolMode::MODE_CACHED) {
		threadSizeThreshHold_ = threshhold;
	}
}
// 设置线程池工作模式
void ThreadPool::setMode(PoolMode mode) {
	// 如果线程池已经启动了，则不能设置工作模式了
	if (checkRunningState()) return;
	poolMode_ = mode;
}

// 检查线程池的运行状态
bool ThreadPool::checkRunningState() const {
	return isPoolRunning_;
}

// 任务相关
// 设置task任务队列上限阈值
void ThreadPool::setTaskQueMaxThreshHold(int threshhold) {
	// 如果线程池已经启动了，则不能设置了
	if (checkRunningState()) return;
	taskQueMaxThreshHold_ = threshhold;
}

// 开启线程池，并设置初始的线程数量
void ThreadPool::start(size_t initThreadSize) {
	// 设置线程池的启动状态
	isPoolRunning_ = true;

	// 设置初始的线程数量
	initThreadSize_ = initThreadSize;
	// 记录线程总数
	curThreadSize_ = initThreadSize;

	// 创建线程对象
	for (size_t i = 0; i < initThreadSize_; i++) {
		// 创建thread线程对象的时候，需要把线程函数给到thread类
		// 这样在Thread::start中才能启动这个线程函数
		// 通过构造函数，将threadFunc放进去
		// 这里我们使用bind。对于类的成员函数，前面要取个地址
		// 且需要绑定一个类对象才能使用，这里绑定了this即当前对象
		// 这里使用智能指针创建线程对象，让其能自动析构
		auto ptr = std::make_unique<Thread>(std::bind(&ThreadPool::threadFunc, this, std::placeholders::_1));  // c++14
		// 使用move将左值转换为对应的右值引用类型
		int threadId = ptr->getId();
		threads_.emplace(threadId, std::move(ptr));
		// unique_ptr是不允许拷贝构造的，仅支持一个智能指针指向它
		// 因此 emplace_back(ptr) 的操作会报错
		// unique_ptr虽然关闭了左值引用的拷贝和赋值，但支持右值引用的操作！
	}

	// 启动所有线程
	for (size_t i = 0; i < initThreadSize_; i++) {
		// 注意，这里threads_[i]是指针
		// 调用了线程类里的start函数创建并启动线程
		threads_[i]->start();
		idleThreadSize_++;
	}
}

// threadFunc负责在线程池中获取并执行任务
// 在线程池类中定义线程函数，由线程类执行
// 线程函数需要的那些锁和条件变量，都定义在线程池中
// 这里线程函数若是定义在Thread类中，则不方便访问ThreadPool里的那些私有的锁和条件变量
// 因此将线程函数定义在ThreadPool类中
void ThreadPool::threadFunc(int threadid) {
	auto lastTime = std::chrono::high_resolution_clock().now();

	// 所有任务必须执行完成，线程池才可以回收所有线程资源，所以还是必须用for(;;)
	// 相当于while(true)。线程执行threadFunc后便一直在此函数中尝试获取任务
	// while (isPoolRunning_){
	for (;;) {
		// 注意，我们仅需要在取任务的时候获取锁，取到任务后释放锁，再执行任务
		std::shared_ptr<Task> task;
		{
			// 获取锁
			std::unique_lock<std::mutex> lock(taskQueMtx_);

			std::cout << "tid:" << std::this_thread::get_id()
				<< "尝试获取任务!" << std::endl;

			// cached模式下，有可能已经创建了很多的线程，但是空闲时间超过60s
			// 对于超过初始线程数量initThreadSize_的线程，需要看情况进行回收
			while (taskQue_.size() == 0) {
				// 线程池要结束，回收线程资源，后面的这些都不执行了，直接跳出while循环，来执行删除线程操作
				if (!isPoolRunning_) {
					// 若是线程池结束时还有任务没执行完，则等其结束wait状态后，跳出while循环，在这里进行析构
					threads_.erase(threadid);
					std::cout << "threadid:" << std::this_thread::get_id() << " exit!" << std::endl;
					// 结束时通知下pool所在的主线程
					exitCond_.notify_all();
					return;
				}
				// 每一秒返回一次
				// while来区分是超时返回还是有任务待执行返回
				// 任务队列有任务，就跳过while去消费，没任务才等待任务
				if (poolMode_ == PoolMode::MODE_CACHED) {
					// wait_for函数的返回值cv_status有两个状态，超时和不超时
					if (std::cv_status::timeout == 
						notEmpty_.wait_for(lock, std::chrono::seconds(1))) {
						auto now = std::chrono::high_resolution_clock().now();
						auto dur = std::chrono::duration_cast<std::chrono::seconds>(now - lastTime);
						if (dur.count() >= THREAD_MAX_IDLE_TIME
							&& curThreadSize_ > initThreadSize_) {
							// 回收线程
							// 记录线程数量的相关变量的值
							idleThreadSize_--;
							curThreadSize_--;

							// 将线程对象从线程列表中删除 但没法将threadFunc对应到thread对象
							// threadid => thread对象 => 删除
							threads_.erase(threadid);
							std::cout << "threadid:" << std::this_thread::get_id() << " exit!" << std::endl;
							return;
						}
					}
				}
				else {
					notEmpty_.wait(lock);
				}
				//// 判断一下是有任务才被唤醒的，还是因为线程池结束才唤醒的
				//if (!isPoolRunning_) {
				//	// 将线程对象从线程列表中删除 但没法将threadFunc对应到thread对象
				//	// threadid => thread对象 => 删除
				//	threads_.erase(threadid);
				//	std::cout << "threadid:" << std::this_thread::get_id() << " exit!" << std::endl;
				//	// 通知下主线程的条件变量，否则会阻塞在主线程
				//	exitCond_.notify_all();
				//	return;
				//}
			}

			idleThreadSize_--;

			std::cout << "tid:" << std::this_thread::get_id()
				<< "成功获取任务!" << std::endl;

			task = taskQue_.front(); taskQue_.pop();
			taskSize_--;

			// 为什么用了两个条件变量呢，这便于进行更精细的操作
			// 如果任务队列仍有任务，则通知其他wait在notEmpty_的线程执行任务
			if (taskQue_.size() > 0) {
				notEmpty_.notify_all();
			}
			
			// 通知 wait在notFull_上的生产者，可以继续提交任务
			notFull_.notify_all();
		}  // 取完任务，释放锁
		if (task != nullptr) {
			// 执行任务，并把任务的返回值setVal方法给到Result
			// task->run();
			// run是个需要重写的方法，我们不可能将增加的这部分功能写到run里面
			// 所以我们在Task类中增加了exec函数，在这个函数中执行run和新增加的功能
			task->exec();
		}
		idleThreadSize_++;
		lastTime = std::chrono::high_resolution_clock().now();
	}
}

// 给线程池提交任务
// 生产者：获取锁，while(满) {wait}，提交任务，notify_all
Result ThreadPool::submitTask(std::shared_ptr<Task> sp) {
	// 获取锁
	std::unique_lock<std::mutex> lock(taskQueMtx_);

	// 线程的通信 等待任务队列有空余
	// 没有空余才等待，因此需要等待notFull_
	// 这里使用了lambda表达式的隐式捕获的引用捕获，让编译器根据函数体中代码推断捕获列表
	//// notFull_.wait(lock, [&]()->bool {return taskQue_.size() < taskQueMaxThreshHold_; });
	// 与下面三行等价
	//while (taskQue_.size() == taskQueMaxThreshHold_) {
	//	notFull_.wait(lock);
	//}
	// 增加一个要求：用户提交任务，最长不能阻塞超过1s，否则判断提交任务失败，返回
	// wait()：一直等待到条件满足；wait_for()：等一段时间；wait_until()：等到一个时间点
	/*notFull_.wait_for(lock, std::chrono::seconds(1), [&]()->bool {return taskQue_.size() < taskQueMaxThreshHold_; });*/
	if (!notFull_.wait_for(lock, std::chrono::seconds(1), [&]()->bool {return taskQue_.size() < taskQueMaxThreshHold_; })) {
		// 等待1s，条件仍不满足
		std::cerr << "task queue is full, submit task fail." << std::endl;
		// 若任务提交失败，则
		return Result(sp, false);
	}

	// 有空余，将任务放入任务队列
	taskQue_.emplace(sp);
	taskSize_++;

	// 任务队列不空，通知notEmpty_
	notEmpty_.notify_all();

	// cached模式需要根据任务数量和空闲线程的数量，判断是否需要创建新的线程出来
	// 且需要当前线程总数小于我们设定的最大线程数
	if (poolMode_ == PoolMode::MODE_CACHED && taskSize_ > idleThreadSize_ && curThreadSize_ < threadSizeThreshHold_) {
		std::cout << "create new thread" << std::endl;
		// 创建新线程
		auto ptr = std::make_unique<Thread>(std::bind(&ThreadPool::threadFunc, this, std::placeholders::_1));  // c++14
		int threadId = ptr->getId();
		threads_.emplace(threadId, std::move(ptr));
		// 启动线程
		threads_[threadId]->start();
		// 修改线程个数相关的变量
		curThreadSize_++;
		idleThreadSize_++;
	}
	// 对于Result，可以通过task类里面的函数返回，也可以用Result类进行封装
	// return task->getResult();  // 不行！task对象被线程取出来用完后就析构了，再想使用这个task对象是不行的
	// return Result(task);  // 因此通过Result来维持task的生命周期，保证我们想要task返回值的时候task对象还在
	return Result(sp);
}


/////////////////////////////////// 线程方法实现
int Thread::generateId_ = 0;

Thread::Thread(ThreadFunc func)
	: func_(func)
	, threadId_(generateId_++)
{}

Thread::~Thread() {

}

int Thread::getId() const {
	return threadId_;
}

// 启动线程
void Thread::start() {
	// 创建线程
	// ThreadPool::start函数创建了thread，传入了func_
	// 因此创建线程的时候直接把func_放进去就行
	// 这里thread的构造函数通过完美转发将参数传递给线程函数
	
	std::thread t(func_, threadId_);
	// 注意，上面是将线程函数写到线程池类的写法
	// 若是将线程函数写到Thread类中，则应该写为
	// std::thread t(&Thread::threadFunc, &thread1);
	// thread1表示一个线程对象，相应的start函数也应该有形参：start(Thread& thread1)

	// 注意，这个线程对象t出了这个作用域就会自动销毁
	// 因此要设置为分离线程，使得此线程变为守护线程，驻留后台运行
	t.detach();
}



/////////////////////////////  Result的实现
Result::Result(std::shared_ptr<Task> task, bool isValid) 
	: task_(task), isValid_(isValid){
	// 顺便将result对象绑定到task上
	task_->setResult(this);
}

Any Result::get() {
	if (!isValid_) return "";  // 如果返回值无效，返回g个空
	sem_.wait();  // task任务如果没有执行完，则堵塞用户的线程
	return std::move(any_);

}

void Result::setVal(Any any) {
	// 存储task的返回值
	this->any_ = std::move(any);
	sem_.post();
}
```

.h

```cpp
#ifndef THREADPOOL_H
#define THREADPOOL_H
// 使用 #ifndef 而非 #pragma once ，因为后者需要编译器支持，在linux下不支持
#include<iostream>
#include<vector>
#include<queue>
#include<memory>  // 智能指针
#include<atomic>  // 原子类型，实现线程互斥
#include<mutex>  // 锁
#include<condition_variable>  // 条件变量，实现线程通信
#include<functional>
#include<thread>
#include<unordered_map>

// Any类型：可以接收任意数据的类型
// 将其作为函数返回值类型时，会看Any有没有一个合适的构造函数，来接收return返回的对象
class Any {
public:
	// 将任意类型的data包在派生类中，用基类指针指向
	template<typename T>
	Any(T data) : base_(std::make_unique<Derive<T>>(data)) {}

	// 定义一个方法，将Any对象存储的data_数据提取出来
	template<typename T>
	T cast_() {
		// 从base_指针中找到所指向的派生类对象，取出data_成员变量
		// 用智能指针提供的get方法取得裸指针，用 dynamic_cast 进行自动的类型转换至派生类指针
		Derive<T>* pd = dynamic_cast<Derive<T>*>(base_.get());
		if (pd == nullptr) {
			// dynamic_cast 转换失败，比如人家是int，你以为是long，就cast_<long>来调用，结果人家是Derive<int>，就转换失败了
			throw "type is unmatch";
		}
		return pd->data_;
	}
	Any() = default;
	~Any() = default;
	// Any类中的成员变量是unique_ptr类型的，对于这个智能指针，禁止了拷贝构造和赋值，仅支持移动构造
	// 因此Any类中也是这样的。这就是默认实现，不写也无所谓
	Any(const Any&) = delete;
	Any& operator=(const Any&) = delete;
	Any(Any&&) = default;
	Any& operator=(Any&&) = default;
private:
	// 基类类型
	class Base {
	public:
		// 对于多态用途的基类，需要虚析构函数
		// 若不是虚析构，在delete一个指向派生类的基类指针的时候，可能仅将派生类对象的基类部分西沟了，因此其结果将是未定义的
		// 定义为虚析构，才能确保delete基类指针时运行正确的析构函数版本
		virtual ~Base() = default;
	};
	// 派生类类型
	template<typename T>
	class Derive : public Base {
	public:
		Derive(T data) : data_(data) {};
		T data_;
	};
private:
	// 定义一个基类的指针
	std::unique_ptr<Base> base_;
};

// 实现一个信号量类，来实现Result类的线程通信
// 这个信号量默认的资源数为0
class Semaphore {
public:
	Semaphore(int count = 0) : resLimit_(count), isExit_(false) {}
	~Semaphore() {
		isExit_ = true;
	}
	// 获取一个信号量资源
	void wait() {
		if (isExit_) return;
		std::unique_lock<std::mutex> lock(mtx_);
		// 等待信号量有资源
		cond_.wait(lock, [&]()->bool { return resLimit_ > 0; });
		resLimit_--;
	}
	// 增加一个信号量资源
	void post() {
		if (isExit_) return;
		std::unique_lock<std::mutex> lock(mtx_);
		resLimit_++;
		cond_.notify_all();
	}
private:
	// 对于linux下的程序，由于锁和条件变量不会自动析构，会引起死锁
	// 因此增加了isExit_状态位
	std::atomic_bool isExit_;
	int resLimit_;
	std::mutex mtx_;
	std::condition_variable cond_;
};

class Task;  // Task对象的前置声明
// Result类：作为 submitTask 的返回值
// 实现接收提交到线程池的task任务执行完成后的返回值类型
// 主线程中的Result类通过get来获取任务线程的返回值，因此需要与任务线程进行线程通信
class Result {
public:
	Result(std::shared_ptr<Task> task, bool isValid = true);
	// 获取任务执行完的返回值，将task_ run()的返回值放到any_里
	void setVal(Any any);
	// 用户调用这个方法获取task的返回值
	Any get();

private:
	Any any_;  // 存储任务的返回值
	Semaphore sem_;  // 线程通信的信号量
	std::shared_ptr<Task> task_;  // 指向对应的需要获取返回值的task对象
	std::atomic_bool isValid_;  // 返回值是否有效
};


//////////////////////////////    任务抽象基类
class Task {
public:
	// 用户可以自定义任意任务类型，从 Task 继承，重写 run 方法，实现自定义任务处理
	Task();
	virtual Any run() = 0;
	void exec();
	void setResult(Result* res);
private:
	Result* result_;  // 这里用普通的指针就行，因为result的生命周期比task长
};


// 线程池支持的模式
// 这里使用了限定作用域的枚举类型
// 使用时必须显示的访问，PoolMode p = PoolMode::MODE_FIXED;
enum class PoolMode {
	MODE_FIXED,  // 固定数量的线程
	MODE_CACHED,  // 线程数量可动态增长
};


//////////////////////////////////   线程类型
class Thread {
public:
	// 线程函数对象类型，为function函数对象
	using ThreadFunc = std::function<void(int)>;

	Thread(ThreadFunc func);
	~Thread();
	void start();

	// 获取线程id
	int getId() const;
private:
	ThreadFunc func_;
	static int generateId_;  // 类的所有对象共享静态成员变量，通过它来得到变化的threadId_
	int threadId_;  // 保存线程ID
};


///////////////////////////////////   线程池类型
/*
example:
ThreadPool pool;
pool.start(4);

class MyTask : public Task
{
	public:
		void run() { // 线程代码... }
};

pool.submitTask(std::make_shared<MyTask>());
*/
class ThreadPool {
public:
	ThreadPool();
	~ThreadPool();
	// 禁止线程池的拷贝和复制
	ThreadPool(const ThreadPool&) = delete;
	ThreadPool& operator=(const ThreadPool&) = delete;

	// 设置线程池模式
	void setMode(PoolMode mode);

	// 开启线程池，并设置初始的线程数量，为cpu系统的核心数量
	void start(size_t initThreadSize = std::thread::hardware_concurrency());

	// 设置cached模式下线程阈值
	void setThreadSizeThreshHold(int threshhold);
	// 任务相关
	// 设置task任务队列上限阈值
	void setTaskQueMaxThreshHold(int threshhold);
	// 给线程池提交任务
	Result submitTask(std::shared_ptr<Task> sp);

private:
	// 定义线程函数
	void threadFunc(int threadid);

	// 检查线程池的运行状态
	bool checkRunningState() const;
private:
	

	// 线程相关
	// 线程列表。对于线程的创建，是在ThreadPool::start中new出来的，还需要delete
	// 因此直接使用智能指针。线程的话unique就行
	// std::vector<std::unique_ptr<Thread>> threads_;
	// 为了实现通过threadId_查询到对应的线程，这里最后使用了map
	std::unordered_map<int, std::unique_ptr<Thread>> threads_;

	size_t threadSizeThreshHold_;  // 线程数量的上限
	// 为什么新增一个变量而不是用threads_.size()呢，因为vector不是线程安全的
	std::atomic_int curThreadSize_;  // 记录当前线程池里面线程的总数量
	std::atomic_int idleThreadSize_;  // 记录空闲线程的数量
	int initThreadSize_;  // 初始的线程数量。size_t增强了可移植性，表示任何对象所能达到的最大长度
	
	// 需要使用基类的指针或引用才能实现多态
	// 而用户传入的通常会是临时的一个任务对象，出了submitTask语句后就析构了，用指针指向一个析构了的对象是没有意义的
	// 而我们是需要考虑来保持这个任务的生命周期的，当这个任务run执行以后在析构
	// 因此需要使用智能指针
	std::queue<std::shared_ptr<Task>> taskQue_;  // 任务队列
	std::atomic_uint taskSize_;  // 任务的数量。考虑到线程安全问题，使用轻量化的原子类型实现线程互斥
	size_t taskQueMaxThreshHold_;  // 任务队列数量的上限

	// 实现线程通信
	std::mutex taskQueMtx_;  // 保证任务队列的线程安全
	std::condition_variable notEmpty_;  // 任务队列不空
	std::condition_variable notFull_;  // 任务队列不满
	std::condition_variable exitCond_;  // 等待线程资源全部回收

	PoolMode poolMode_;  // 当前线程池的工作模式

	std::atomic_bool isPoolRunning_;  // 表示当前线程池的启动状态
	
};


#endif // !THREADPOOL_H

```

## 第二版

如何能让线程池提交任务更加方便

1. 我们希望直接传入函数和参数，而不是第一版那种定义一个类继承Task基类，通过类的构造函数传参，在类中定义任务函数
   pool.submitTask(sum1, 10, 20);
   pool.submitTask(sum2, 1 ,2, 3);
   submitTask:可变参模板编程
2. 我们自己造了一个Result以及相关的Any类型来接收数据，代码挺多
   2.1.用packaged_task代替function
   packaged_task与std::function很像，也是一个函数对象，可以很方便的获取线程的返回值
   2.2.使用future来代替Result节省线程池代码

第一版程序提交任务，需要自定义类，



[packaged_task](https://www.apiref.com/cpp-zh/cpp/thread/packaged_task.html)类似function，可以绑定一个可调用对象并执行。但其返回类型是void，需要用future获取返回值

std::future（c++11）是个类模板，提供访问异步操作结果的机制，相当于我们自己实现的Result + Any。通过`get()`获取结果

| 获取结果                                                     |                                                              |
| ------------------------------------------------------------ | ------------------------------------------------------------ |
| [get](https://www.apiref.com/cpp-zh/cpp/thread/future/get.html) | 返回结果                                                     |
| **状态**                                                     |                                                              |
| [valid](https://www.apiref.com/cpp-zh/cpp/thread/future/valid.html) | 检查 future 是否拥有共享状态                                 |
| [wait](https://www.apiref.com/cpp-zh/cpp/thread/future/wait.html) | 等待结果变得可用                                             |
| [wait_for](https://www.apiref.com/cpp-zh/cpp/thread/future/wait_for.html) | 等待结果，如果在指定的超时间隔后仍然无法得到结果，则返回。   |
| [wait_until](https://www.apiref.com/cpp-zh/cpp/thread/future/wait_until.html) | 等待结果，如果在已经到达指定的时间点时仍然无法得到结果，则返回。 |

```cpp
# include<future>
// packaged_task<函数对象>();
int sum1(int a, int b) {
	return a + b;
}

/////////////// 1. 创建一个 int(int, int) 类型的函数对象
// 用packaged_task打包一个任务。相比于用std::function方法来打包任务，packaged_task中可以通过 get_future() 方法获取任务的返回值
std::packaged_task<int(int, int)> task(sum1);
// 也可以通过std::bind将可调用对象与其参数一起绑定，并延迟调用到我们需要的时候
// std::packaged_task<int(int, int)> task(std::bind(sum1, _1, _2));

/////////////// 2. 通过get_future保存future类型打包的返回值对象
// 和我们自己实现的Result一样
std::future<int> res = task.get_future();

/////////////// 3. 通过包装的task来调用sum1
// task(10, 20);
// 将task放到一个新的线程中执行
thread t(std::move(task), 10, 20);  // 注意，packaged_task也删除了拷贝和赋值构造函数，需要通过右值传递
t.detach();

/////////////// 4. 通过future.get()获得返回值
// 任务会堵塞在get函数中，至任务执行完毕
cout << res.get();
```





> 重构：
> 删除了Result、Any、Semaphore(用于Result类线程通信)、Task类，重写submitTask函数
>
> 可变参模板编程：
> 通过Variadic Templates(c++11)接收任意数量和类型的参数
> submitTask函数返回值使用decltype(c++11)自动推导，并和auto配合写为了尾置返回类型(c++11)的形式
> 函数参数使用引用折叠Func&&
> 对于task，使用packaged_task进行包装，通过bind绑定形参，其中形参的传入使用std::forward完美转发。这样就可以用get_future获取到task任务的future类型的返回值
>
> 如果有任务的话，是需要将task放到任务队列的，而我们的任务队列存储的形式为
> using Task = std::function<void()>;
> std::queue<Task> taskQue_;  // 任务队列
> 即function<void()>的返回类型为void的函数对象，因此在放入任务的时候传入的是返回类型为void的、函数体中调用task的lambda表达式

使用

```cpp
#include"threadpool.h"

int sum1(int a, int b) {
	return a + b;
}

int main() {
    ThreadPool pool;
    pool.setMode(PoolMode::MODE_CACHED);
    pool.start(2);
    std::future<int> result = pool.submitTask(sum1, 1, 2);
    std::cout << result.get() << std::endl;
}
```









自己实现的Any类型和信号量、有依赖关系的Task类和其返回值类型Result类、线程类和线程池类、智能指针、锁、信号量、条件变量、bind等



遇到的问题：

设计上，如如何获取任务的返回值，如Any、Result类、信号量等

资源回收是...实现的，在fixed模式下，概率性遇到了死锁问题





问题1：主函数堵塞住了。主线程创建了个条件变量，与子线程进行通信，而子线程在线程池结束的时候，就顾着自己删除线程对象了，而忘记notify主线程的条件变量，导致堵塞



# 





























