@[toc]
#  基础概念
## 数字图像处理

 - 灰度：一幅图像可定义为一个二维函数f(x,y)，在任一空间坐标(x,y)处的赋值f称为图像在该点处的强度或灰度
 - 像素：每个元素都有一个特定的位置和赋值，这些元素称为图画元素，图像元素或像素
 - 取样：对坐标进行数字化
 - 量化：对赋值数字化
 - 图像噪声：会让赋值即灰度级产生随机变化
 - 空间域：一副图像的坐标张成的实平面部分称为空间域，x和y称为空间变量或空间坐标
 - 将连续图像取样为一个二维阵列(x,y)，该阵列包含有M行N列。数字图像的原点位于左上角，正X轴向下延伸，正y轴向右延伸
 - 离散灰度级数L=2^k，表示图像为一副“k比特图像”
 - 动态范围：由灰度跨越的值域非正式的称为动态范围。将图像系统的动态范围定义为系统中最大可度量灰度与最小可检测灰度之比。上限取决于饱和度，下限取决于噪声
 - 对比度：一幅图像中最高和最低灰度级间的灰度差为对比度
 - 存储数字图像所需的比特数b=M*N*k
 - 空间分辨率：每单位距离线对数和每单位距离点数是最通用的度量，其中线宽为W个单位(W可以小于1)，线对的宽度就是2W，每单位距离有1/2W个线对。
 - 图像分辨率：每单位距离可分辨的最大线对数量
 - 相邻像素：位于坐标(x,y)处的像素p有4个水平和垂直的相邻像素，其坐标由下式给出，(x+1,y),(x-1,y),(x,y+1),(x,y-1)，这组像素称为p的4邻域(为十字形)，用N<sub>4</sub>(p )表示；p的4个对角相邻像素的坐标为(x+1,y+1),(x+1,y-1),(x-1,y+1),(x-1,y-1)，并用N<sub>D</sub>(p )表示，这些点与4个邻点一起称为p的8邻域，用N<sub>8</sub>(p )表示
 - 邻接性：
![在这里插入图片描述](E:\MarkDown\picture\20201214013528816.jpg)![在这里插入图片描述](E:\MarkDown\picture\20201214013541974.jpg)![在这里插入图片描述](E:\MarkDown\picture\20201214014851643.png)

 - 连通性：令S是图像中的一个像素子集，如果S的全部像素之间存在一个通路，则可以说两个像素p和q在S中是连通的。对于S中的任何像素p，S中连通到该像素的像素集称为S的连通分量。如果S仅有一个连通分量，则集合S称为连通集
 - 距离度量：

 - 
# 一、图像内插
## 1.图像内插
这是基本的图像重取样方法，可用于调整图像的大小，是用已知数据来估计未知位置的数值的处理

### 最近邻内插法：

假设一幅大小为500* 500像素的图像要放大1.5倍到750 * 750像素。则可创建一个假想的750* 750网格，它与原始图像有相同的间隔，然后将其收缩使它准确的与原图像匹配，此时，其像素间隔小于原图像的像素间隔。因此，为了对覆盖的每一个点赋以灰度值，在原图像中寻找最接近的像素，并把该像素的灰度赋给750* 750网格中的新像素，当完成对网格中覆盖的所有点的灰度赋值后，就把图像扩展到原来规定的大小，得到放大后的图像

原理：把原图像中最近邻的灰度赋给了每个新位置

缺陷：某些直边缘的严重失真，产生棋盘格效应，即图像由深深浅浅的近黑方块组成。因此并不常用

### 双线性内插：

原理：用四个最近邻去估计给定位置的灰度

令(x,y)为我们想要赋以灰度值的位置的坐标，并令v(x,y)表示灰度值，则v(x,y)=ax+by+cxy+d（因为有xy项，因此并不是一种线性内插方法），其中，四个系数可由四个用(x,y)点最近邻点写出的未知方程确定

新图像的像素点对应输入图像的（u0 , v0）(u0,v0不是整数)，则其必定落在原始图像四个像素点中间。四个像素点分别是(u’ , v’ )、(u’ , v’ +1)、(u’+1 , v’ )、(u’ +1, v’+1 )
![在这里插入图片描述](E:\MarkDown\picture\20201211013835598.png)
![在这里插入图片描述](E:\MarkDown\picture\20201211015934138.jpg)![在这里插入图片描述](E:\MarkDown\picture\20201211022257315.jpg)这里不是很懂
![在这里插入图片描述](E:\MarkDown\picture\20201211022416285.jpg)
特点：更实用，但计算量有所增加


例程1
```
Mat matDst1,matSrc;
	matSrc = cv::imread("opencv.jpg",IMREAD_COLOR);
	int channel = matSrc.channels();
	matDst1 = Mat(1000,1000,CV_8UC3);
	float scale_x = matSrc.cols/1000.0,scale_y = matSrc.rows/1000.0;
 
	uchar* dataDst = matDst1.data; //目标图像
    int stepDst = matDst1.step;
    uchar* dataSrc = matSrc.data;//源图像
    int stepSrc = matSrc.step; //一行的宽度
    int iWidthSrc = matSrc.cols; 
    int iHieghtSrc = matSrc.rows;  
 
    for (int j = 0; j < matDst1.rows; ++j) //高度方向
    {
        float fy = (float)((j + 0.5) * scale_y - 0.5);
        int sy = cvFloor(fy);
        fy -= sy; //u = fy
        sy = std::min(sy, iHieghtSrc - 2);//边界限制
        sy = std::max(0, sy);
 
        short cbufy[2];
        cbufy[0] = cv::saturate_cast<short>((1.f - fy) * 2048);// 1-u 扩大2048倍，即左移11位
        cbufy[1] = 2048 - cbufy[0];
 
        for (int i = 0; i < matDst1.cols; ++i)//宽度方向
        {
            float fx = (float)((i + 0.5) * scale_x - 0.5);
            int sx = cvFloor(fx);
            fx -= sx;
			//以下两个if与上面的sy的两条语句（min和max)是一样的
            if (sx < 0) {
                fx = 0, sx = 0;
            }
            if (sx >= iWidthSrc - 1) {
                fx = 0, sx = iWidthSrc - 2;
            }
 
            short cbufx[2];
            cbufx[0] = cv::saturate_cast<short>((1.f - fx) * 2048);
            cbufx[1] = 2048 - cbufx[0];
 
            for (int k = 0; k < matSrc.channels(); ++k)
            {
                *(dataDst+ j*stepDst + 3*i + k) = (*(dataSrc + sy*stepSrc + 3*sx + k) * cbufx[0] * cbufy[0] + 
                    *(dataSrc + (sy+1)*stepSrc + 3*sx + k) * cbufx[0] * cbufy[1] + 
                    *(dataSrc + sy*stepSrc + 3*(sx+1) + k) * cbufx[1] * cbufy[0] + 
                    *(dataSrc + (sy+1)*stepSrc + 3*(sx+1) + k) * cbufx[1] * cbufy[1]) >> 22;
            }
        }
    }
	
    cv::imwrite("linear_1.jpg", matDst1);
```



```
#include <opencv2/opencv.hpp>//Opencv头文件的包含
#include <iostream>
#include <math.h>
int CImgProcess::InterpBilinear(double x, double y)
{
    //不是很懂
    if (int(y) == 300)
        int cc = 1;

    //4个最邻近像素的坐标
    int x1, x2;
    int y1, y2;

    //4个最邻近像素值
    unsigned char f1, f2, f3, f4;

    //两个插值中间值
    unsigned char f12, f34;
    //以此变量表示极小值
    double epsilon = 0.0001;//epsilon是希腊字母表第五个字母，代表一个任意的数

    //计算4个最临近像素的坐标
    x1 = (int)x;
    x2 = x1 + 1;
    y1 = (int)y;
    y2 = y1 + 1;

    /*
您可以使用rows和cols：

cout << "Width : " << src.cols << endl; 
cout << "Height: " << src.rows << endl; 

或size()：

cout << "Width : " << src.size().width << endl; 
cout << "Height: " << src.size().height << endl; 


    */

    int nHeight = GetHeight();
    int nWidth = GetWidthPixel();
    if ((x < 0) || (x > nWidth - 1) || (y < 0) || (y > nHeight - 1))
    {
        //如果计算的点不再原图内，返回-1
        return -1;
    }
    else
    {
        //fabs为取绝对值,需添加头文件math.h。这里即x+1<=nWidth，即x点临点即x+1点也在图像边缘内
        if (fabs(x - nWidth + 1) <= epsilon)
        {
            //如果计算的点在图像右边缘上
            if (fabs(y - nHeight + 1) <= epsilon)
            {
                //如果计算的点正好是图像最右下角那个元素，则直接返回该点像素值
                f1 = (unsigned char)GetGray(x1, y1);
                return f1;
            }
            else
            {
                //如果是在图像右边缘上且不是最后一点，直接一次插值即可
                f1 = (unsigned char)GetGray(x1, y1);
                f3 = (unsigned char)GetGray(x1, y2);

                //返回插值结果
                return((int)(f1 + (y - y1) * (f3 - f1)));
            }
        }
        else if (fabs(y - nHeight + 1) <= epsilon)
        {
            //如果计算的点在图像下边缘上且不是最后一点，直接一次插值即可
            f1 = (unsigned char)GetGray(x1, y1);
            f2 = (unsigned char)GetGray(x2, y1);

            //返回插值结果
            return((int)(f1 + (x - x1) * (f2 - f1)));
        }
        else
        {
            //计算4个最临近像素值
            f1 = (unsigned char)GetGray(x1, y1);
            f2 = (unsigned char)GetGray(x2, y1);
            f3 = (unsigned char)GetGray(x1, y2);
            f4 = (unsigned char)GetGray(x2, y2);

            //插值1
            f12 = (unsigned char)(f1 + (x - x1) * (f2 - f1));
            //插值2
            f34 = (unsigned char)(f3 + (x - x1) * (f4 - f3));
            //插值3
            return ((int) (f12 + (y - y1) * (f34 - f12)));
        }
    }
}
```

#### OpenCV例程

```
//opencv实现
/*
最优一个参数interpolation表示插值方式，有以下几种：
INTER_NEAREST - 最近邻插值
INTER_LINEAR - 线性插值（默认）
INTER_AREA - 区域插值
INTER_CUBIC - 三次样条插值
INTER_LANCZOS4 - Lanczos插值
*/
//使用resize函数对图像进行缩放操作
 
#include <iostream>
#include <opencv2\core\core.hpp>
#include <opencv2\highgui\highgui.hpp>
#include <opencv2\imgproc\imgproc.hpp>
 
using namespace std;
using namespace cv;
 
int main()
{
	Mat srcImg, dstImg1,dstImg2,dstImg3;
	srcImg = imread("1.jpg");
	imshow("原图像", srcImg);
	resize(srcImg, dstImg1, Size(0, 0), 1.5, 1.5, INTER_NEAREST);
	resize(srcImg, dstImg2, Size(0, 0), 1.5, 1.5, INTER_LINEAR);
	resize(srcImg, dstImg3, Size(0, 0), 1.5, 1.5, INTER_CUBIC);
 
 
	imshow("放大后的图像1", dstImg1);
	imshow("放大后的图像2", dstImg2);
	imshow("放大后的图像3", dstImg2);
 
	waitKey();
	return 0;
}
```
### 双三次/双立方内插：

原理：包括16个最近邻点
![在这里插入图片描述](https://img-blog.csdnimg.cn/20201210205002337.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NDc4MjUyNA==,size_2,color_FFFFFF,t_70 =200x60)
特点：保持细节方面更好


增大或降低空间分辨率
从阵列中插入或取出数据？ 改变灰度级呢？







# 二 算术操作
## 1.基础概念
### 1.阵列操作
图像间的算术操作是阵列操作。包含一幅或多幅图像的阵列操作是以逐像素为基础执行的。
![在这里插入图片描述](E:\MarkDown\picture\20201214115444731.png)一幅图像求幂，意味着每个像素均进行求幂操作
一幅图像除以另一幅图像时，意味着在相应的像素对之间进行相除
### 2.线性操作
![在这里插入图片描述](E:\MarkDown\picture\20201214115802452.png)![在这里插入图片描述](E:\MarkDown\picture\20201214115855980.png)
### 3.算术操作
图像间的算术操作是阵列操作，算术操作在相应的像素对之间执行
四种算术操作为：
![在f和](E:\MarkDown\picture\20201214120102768.png)
在f和g中相应的像素对之间执行操作

## 2.实例
### 1.图像相加

图像相加主要有两种用途，一种是消除图像的随机噪声，主要做是讲同一场景的图像进行相加后再取平均；另一种是用来做特效，把多幅图像叠加在一起，再进一步进行处理。
对于灰度图像，因为只有单通道，所以直接进行相应位置的像素加法即可，对于彩色图像，则应该将对应的颜色的分量分别进行相加。
针对降噪的带噪图像相加(平均)
![在这里插入图片描述](E:\MarkDown\picture\202012141204508.png)

#### 直接运用运算符操作
```
#include<opencv2/opencv.hpp>

using namespace cv;

int main()
{
    Mat srcImg1, srcImg2, dstImg;
    srcImg1 = imread("1.jpg");
    srcImg2 = imread("2.jpg");
    dstImg = (srcImg1 + srcImg2)/2;
    imshow("原图像1", srcImg1);
    imshow("原图像2", srcImg2);
    imshow("目标图像", dstImg);

    waitKey();
    return 0;
}

```
#### 使用迭代器进行图像的遍历进行相加和使用OpenCV中的addWeighted函数进行线性相加。
```
#include <iostream>
#include<opencv2/opencv.hpp>

using namespace cv;
using namespace std;

int main()
{
	Mat img1, img2, result1;
	img1 = imread("1.jpg");
	img2 = imread("2.jpg");
	result1 = img1.clone();

	/*图像的传递中，经常需要复制图像，Opencv使用了引用计数机制，让每个Mat对象有自己的信息头，
	但矩阵指针指向同一个地址，即共享一个矩阵，则在拷贝函数时只复制信息头和矩阵指针，不复制矩
	阵，此时通过任何一个对象所做的改变也会影响其他对象。若仍想复制矩阵本身，则可用clone() 
	或copyTo();*/

	Mat_<Vec3b>::iterator it = result1.begin<Vec3b>();	//result1初始位置的迭代器
	
    //Mat_<Vec3b>::iterator it;声明一个迭代器	
	//Vec3b是一个uchar类型的，长度为3的vector向量

	Mat_<Vec3b>::iterator itend = result1.end<Vec3b>();	//result1终止位置的迭代器
	Mat_<Vec3b>::iterator it1 = img1.begin<Vec3b>();   //img1初始迭代器
	Mat_<Vec3b>::iterator it2 = img2.begin<Vec3b>();	//img2初始迭代器
	
	//进行遍历
	for (; it != itend; it++)
	{
		//0 1 2分别是B G R通道的数据
		(*it)[0] = ((*it1)[0] + (*it2)[0]) / 2;
		(*it)[1] = ((*it1)[1] + (*it2)[1]) / 2;
		(*it)[2] = ((*it1)[2] + (*it2)[2]) / 2;
		it1++;
		it2++;
	}
	imshow("原图1", img1);
	imshow("原图2", img2);
	imshow("相加后的图像", result1);

	Mat result2 = result1.clone();
	addWeighted(img1, 0.5, img2, 0.5, 0, result2);
	/*
	void cvAddWeighted( const CvArr* src1, double alpha,const CvArr* src2, double beta,double gamma, CvArr* dst );
    参数1：src1，第一个原数组.
    参数2：alpha，第一个数组元素权重
    参数3：src2第二个原数组
    参数4：beta，第二个数组元素权重
    参数5：gamma，图1与图2作和后添加的数值。不要太大，不然图片一片白。总和等于255以上就是纯白色了。
    参数6：dst，输出图片*/
	imshow("addWeighted", result2);

	waitKey();
	return 0;
}

```
### 2.图像相减
图像相减常用于增强图像之间的差
![在这里插入图片描述](E:\MarkDown\picture\20201214145035920.png)![在这里插入图片描述](E:\MarkDown\picture\20201214145053106.png)![在这里插入图片描述](E:\MarkDown\picture\20201214145113230.png)![在这里插入图片描述](E:\MarkDown\picture\20201214145124962.png)
```
#include<opencv2/opencv.hpp>
using namespace cv;
int main()
{
    Mat srcImg1, srcImg2, dstImg;
    srcImg1 = imread("1.jpg");
    srcImg2 = imread("2.jpg");
    dstImg = srcImg1 - srcImg2;
    imshow("原图像1", srcImg1);
    imshow("原图像2", srcImg2);
    imshow("图像相减", dstImg);

    waitKey();
    return 0;
}
```

这个遍历法的result1一直有问题
```
#include<opencv2/opencv.hpp>
using namespace std;
using namespace cv;
uchar toZero(uchar a);//置零函数，小于零则为0
int main()
{
	Mat imag1, imag2, result1, result2;
	imag1 = imread("1.jpg");
	imag2 = imread("2.jpg");
	result1 = imag1.clone();
	result2 = imag2.clone();



	Mat_<Vec3b>::iterator it = result1.begin<Vec3b>();	//result1初始位置的迭代器

//Mat_<Vec3b>::iterator it;声明一个迭代器	
//Vec3b是一个uchar类型的，长度为3的vector向量

	Mat_<Vec3b>::iterator itend = result1.end<Vec3b>();	//result1终止位置的迭代器
	Mat_<Vec3b>::iterator it1 = imag1.begin<Vec3b>();   //img1初始迭代器
	Mat_<Vec3b>::iterator it2 = imag2.begin<Vec3b>();	//img2初始迭代器

	//进行遍历
	for (; it != itend; it++)
	{
		//0 1 2分别是B G R通道的数据
		(*it)[0] = (*it1)[0] - (*it2)[0];
		(*it)[1] = (*it1)[1] - (*it2)[1];
		(*it)[2] = (*it1)[2] - (*it2)[2];
		it1++;
		it2++;
	}


/*
	int rowNumber = result1.rows;
	int colNumber = result1.cols;
	for (int i = 0; i < rowNumber; i++)
	{
		for (int j = 0; j < colNumber; j++)
		{
			result1.at<Vec3b>(i, j)[0] = toZero(imag1.at<Vec3b>(i, j)[0]) - toZero(imag2.at<Vec3b>(i, j)[0]);
			result1.at<Vec3b>(i, j)[1] = toZero(imag1.at<Vec3b>(i, j)[1]) - toZero(imag2.at<Vec3b>(i, j)[1]);
			result1.at<Vec3b>(i, j)[2] = toZero(imag1.at<Vec3b>(i, j)[2]) - toZero(imag2.at<Vec3b>(i, j)[2]);
		}
	}
*/
	//addWeighted方法进行图像相减
	addWeighted(imag1, 1, imag2, -1, 0, result2);
	imshow("原图1", imag1);
	imshow("原图2", imag2);
	imshow("result1", result1);
	imshow("addWeighted", result2);

	waitKey();
	return 0;
}

uchar toZero(uchar a)
{
	if (a < 0)
		return 0;
	else
		return a;
}
```

### 3.图像相乘
#### 阴影校正
![在这里插入图片描述](E:\MarkDown\picture\20201214151058727.png)![在这里插入图片描述](E:\MarkDown\picture\20201214151123281.png)

#### 模板操作
![在这里插入图片描述](E:\MarkDown\picture\20201214151155955.png)![在这里插入图片描述](E:\MarkDown\picture\20201214151221234.png)









也有问题
https://blog.csdn.net/qq_35971623/article/details/77621719?utm_medium=distribute.pc_relevant.none-task-blog-baidulandingword-6&spm=1001.2101.3001.4242
```
#include<opencv2/opencv.hpp>

using namespace cv;

int main()
{
	Mat imag1, result1;
	imag1 = imread("1.jpg");
	result1 = imag1.clone();
	int cols = result1.cols;
	int rows = result1.rows;
	for (int i = 0; i < rows; i++)
	{
		for (int j = 0; j < cols; j++)
		{
			result1.at<Vec3b>(i, j)[0] = 0;
			result1.at<Vec3b>(i, j)[1] = 255;
			result1.at<Vec3b>(i, j)[2] =0;
		}
	}
/*	for (int i = 0; i < cols; i++)
	{
		uchar *data = imag1.ptr<uchar>(i);
		uchar *data2 = result1.ptr<uchar>(i);
		for (int j = 0; j < rows - 1; j++)
		{
			if (data[j + 1] - data[j] > 1)
			{
				data2[j] = 0;
			}
			else
                data2[j] = 255;
		}
	}
*/
	imshow("原图1", imag1);
	imshow("result1", result1);
	waitKey();
	return 0;
}


```