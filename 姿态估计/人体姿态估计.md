3D HPE

## 相关竞赛

### 1.LIP

但是没找到比赛网址

![image-20220331193047635](E:\MarkDown\picture\image-20220331193047635.png)

### 2.COCO Keypoints Challenge

[1](https://competitions.codalab.org/competitions/12061#:~:text=The%20COCO%20Keypoint%20Challenge%20requires%20localization%20of%20person,this%20task%20please%20read%20the%20keypoint%20evaluation%20page.)

但好像到2020之后就没再更新

### 3.kaggle























### 回归

数值坐标回归，采用全连接层直接回归坐标点。

疑问：为什么是用全连接层回归？
把分布式特征 representation 映射到样本标记空间，即**把特征representation整合到一起，输出为一个值。**
<img src="E:\MarkDown\picture\image-20220324144050636.png" alt="image-20220324144050636" style="zoom:50%;" />
全连接层的作用就是使得即使在输出的特征图中猫的位置不同，分类结果也一样。因为空间结构特性被忽略了，所以全连接层不适合用于在方位上找 Pattern 的任务，比如 segmentation。而且FC一般有两层，可以更好的拟合非线性信息



优点是输出即为坐标点，训练和前向速度可以很快，且是端到端的全微分训练；缺点是缺乏空间泛化能力，也就是说丢失了特征图上面的空间信息。



### PCK

PCK是mpii使用的人体关键点估计评价标准，在coco之前，PCK一直是比较主流的metric，包括deepfashion，fashionAI等，都是使用的此标准。

```
评价指标一般是用PCK（PCKh）和OKS+mAP，简单来说，前者就是计算predict和label点的距离再经过head size normalize，后者就是用类似于目标检测中IOU的OKS计算相似度，然后再算AP。虽然前者在学术界目前已经很少使用（主要是刷榜刷得太高了），但是我们场景只需要单人，加上工程化简单，肯定是选择PCK
```

设定的阈值是0.5

![image-20220224173021860](E:\MarkDown\picture\image-20220224173021860.png)

<img src="E:\MarkDown\picture\image-20220224173036643.png" alt="image-20220224173036643" style="zoom:50%;" />

```python
# from mmpose
def keypoint_pck_accuracy(pred, gt, mask, thr, normalize):
    """Calculate the pose accuracy of PCK for each individual keypoint and the
    averaged accuracy across all keypoints for coordinates.

    Note:
        PCK metric measures accuracy of the localization of the body joints.
        The distances between predicted positions and the ground-truth ones
        are typically normalized by the bounding box size.
        The threshold (thr) of the normalized distance is commonly set
        as 0.05, 0.1 or 0.2 etc.

        batch_size: N
        num_keypoints: K

    Args:
        pred (np.ndarray[N, K, 2]): Predicted keypoint location.
        gt (np.ndarray[N, K, 2]): Groundtruth keypoint location.
        mask (np.ndarray[N, K]): Visibility of the target. False for invisible
            joints, and True for visible. Invisible joints will be ignored for
            accuracy calculation.
        thr (float): Threshold of PCK calculation.
        normalize (np.ndarray[N, 2]): Normalization factor for H&W.

    Returns:
        tuple: A tuple containing keypoint accuracy.

        - acc (np.ndarray[K]): Accuracy of each keypoint.
        - avg_acc (float): Averaged accuracy across all keypoints.
        - cnt (int): Number of valid keypoints.
    """
    distances = _calc_distances(pred, gt, mask, normalize)

    acc = np.array([_distance_acc(d, thr) for d in distances])
    valid_acc = acc[acc >= 0]
    cnt = len(valid_acc)
    avg_acc = valid_acc.mean() if cnt > 0 else 0
    return acc, avg_acc, cnt

def _calc_distances(preds, targets, mask, normalize):
    """Calculate the normalized distances between preds and target.

    Note:
        batch_size: N
        num_keypoints: K
        dimension of keypoints: D (normally, D=2 or D=3)

    Args:
        preds (np.ndarray[N, K, D]): Predicted keypoint location.
        targets (np.ndarray[N, K, D]): Groundtruth keypoint location.
        mask (np.ndarray[N, K]): Visibility of the target. False for invisible
            joints, and True for visible. Invisible joints will be ignored for
            accuracy calculation.
        normalize (np.ndarray[N, D]): Typical value is heatmap_size

    Returns:
        np.ndarray[K, N]: The normalized distances.
          If target keypoints are missing, the distance is -1.
    """
    N, K, _ = preds.shape
    distances = np.full((N, K), -1, dtype=np.float32)
    # handle invalid values
    normalize[np.where(normalize <= 0)] = 1e6
    distances[mask] = np.linalg.norm(
        ((preds - targets) / normalize[:, None, :])[mask], axis=-1)
    return distances.T

def _distance_acc(distances, thr=0.5):
    """Return the percentage below the distance threshold, while ignoring
    distances values with -1.

    Note:
        batch_size: N
    Args:
        distances (np.ndarray[N, ]): The normalized distances.
        thr (float): Threshold of the distances.

    Returns:
        float: Percentage of distances below the threshold.
          If all target keypoints are missing, return -1.
    """
    distance_valid = distances != -1
    num_distance_valid = distance_valid.sum()
    if num_distance_valid > 0:
        return (distances[distance_valid] < thr).sum() / num_distance_valid
    return -1
```



### OKS

	Object Keypoint Similarity，相似性度量指标，用于度量检测到的关节点和标签中的关节点之间的相似性。
	设定一个阈值𝑡，若当前关节点的OKS大于𝑡，则表示该关节点被正确检出；若当前关节点的OKS小于𝑡， 则表示该关节点检测精度不够或被漏检。
	
	L2范数：向量所有元素的平方和的开平方

这里图片里有点错误，ki=δi，只是写法不同。
s的话，其面积按groundtruth里人的box的1.25倍计算

![image-20220224160049805](E:\MarkDown\picture\image-20220224160049805.png)

![image-20220224160736580](E:\MarkDown\picture\image-20220224160736580.png)



![image-20220224160114418](E:\MarkDown\picture\image-20220224160114418.png)

#### AP、AR

 Average Precision 平均准确率/查准率，统计被正确检出的关节点的数量在所有检测出的关节点中的比例
![image-20220224161427509](E:\MarkDown\picture\image-20220224161427509.png)

### 









## 师姐程序

第二章：[UDP-Pose](https://github.com/HuangJunJie2017/UDP-Pose)的程序

文件有黄有绿：git项目[git项目，VSCode显示不同颜色块含义](https://www.cnblogs.com/soyxiaobi/p/9708518.html)

test.py中需要的模型文件在yaml文件里配置了，有需要就自己改
evaluate.py中指标的计算好像不是OKS？看着像PCK

coco有自带的oks计算，看看用的是哪个

