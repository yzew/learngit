***

HRNet最后的输入是 64×64 大小的









CA-《Image Super-Resolution Using Very Deep Residual Channel Attention Networks》
CCA 2020-<Lightweight image super-resolution with information multi-distillation network>
ESA 2020-《Residual feature aggregation network for image super-resolution》
PA 2020-《Efficient image super-resolution using pixel attention》
ECA 2020-《ECA-Net: Efficient channel attention for deep convolutional neural networks》



***





***

中间过程转为一维向量

**ECCV 2022：SimDR**

heatmap缺点：
1、要输出2D heatmap，需要进行代价高昂的上采样操作,来将特征图分辨率由低向高进行恢复
2、为了减小heatmap到GT的投影误差，不可避免地需要额外的后处理来进一步细化结果，如DARK修正高斯分布，用argmax获取平面上的极值点坐标等
3、基于热图的方法的性能通常会随着输入分辨率的降低而急剧下降。降低输入分辨率时，如输入像从256x192降为64x64时，HRNet-W48的性能从75.1 AP下降到48.5 AP。在低输入分辨率的情况下，基于热图的方法的优点往往被其量化误差所掩盖，导致性能低下。

因此类比transformer中间的特征表示为一维向量形式，这里将网络的输出换为两个一维向量。在低分辨率下相比heatmap有着较大的提升，高分辨率下也能涨点0.8

***

注意力

ECCV2020：RSN，通过PRM与其他注意力模块的对比试验

***

backbone

连师兄：取3/4通道进行卷积，保留1/4进行级联。减小运算量并结合浅层信息

***



通过DSTN实现梯度的传播，可以避免对heatmap进行监督



***

姿态估计的标注是否有可见标注？

如果对关键点可见度的标签进行随机更改，在训练时是否可以增强其防遮挡能力

3、

连师兄：梯度分支