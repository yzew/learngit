[征文通知](https://mp.weixin.qq.com/s/-C52s3hYsb-7r-Z8v0GHXg)

[官网](http://www.mippr.cn/cn/)

[往年论文(收费)](https://spie.org/Publications/Proceedings/Volume/11430?SSO=1)



1.Papertitle:显式引入人体结构信息的轻量化人体姿态估计

2.Authorsand Institution:作者和机构 

3.Corresponding author:通讯作者

## 4.Purpose:目的

​	目前，基于深度学习的二维人体姿态估计方法已经有了较高的准确率。效果较好的人体姿态估计方法，通常采用HRNet与Transformer作为骨干网络，这类网络往往有着较高的参数量和计算量，存在着显存占用高、时间效率差等问题。因此如何在保持较高关键点检测的准确率的同时，使用更轻量化的网络，实现高精度的实时人体姿态估计，是研究的重点。

![image-20230619225705862](E:\MarkDown\picture\image-20230619225705862.png)



​	图片中清晰可见的人体做直立等简单姿势时，关键点的检测有着较高的精度，但当人体中出现遮挡以及一些较为特殊的姿势（如蹲姿、街舞等）时，关键点的位置往往难以预测。并且服饰、环境等因素会加剧相似身体部位的定位混淆问题。在自底向上任务中，图片中人体的尺寸不一也会影响定位精度。因此，本课题的研究目标为改善人体姿态任务中出现的遮挡问题、关键点高自由度引起的姿态多变问题以及相似身体部位的定位混淆问题，并对自底向上任务中尺度变化敏感的问题加以改善，提高人体关键点检测的准确度。

​	显式的引入结构信息-》GCN

关键点检测网络在定位图像中人体的关键点时使用了两种信息：外观信息和约束信息。外观信息是定位关键点的基础，而约束信息则在定位较为困难的关键点时具有重要的指导意义。约束信息主要包含人体关键点之间固有的人体结构信息，可以有效的帮助定位遮挡或因其他原因不可见的关键点，例如通过右臂的关键点预测被遮挡的右手处关键点。人体结构的先验信息也可以对高自由度的关键点进行约束，帮助网络更好的进行姿态估计。

对于卷积神经网络来说，其优势在于对于图像纹理信息的特征提取能力极强，能学习到高质量的视觉表征，但在约束信息的学习上则有所不足，因此需要结合解剖学约束信息，显式的引入人体结构信息，引导网络进行学习。目前人体结构信息的引入主要可以通过以下几种方法：

​	

## 5.Methods:

​	本文提出的轻量化人体姿态估计网络由三部分组成：去冗余的HRNet特征提取模块、编码模块、解码模块。

**特征提取模块**(hrnet+gau)

​	特征提取模块对输入的图片进行特征提取，输出多个尺度的特征图并进行融合，其结构如图所示。

​	使用去冗余的HRNet网络，在HRNet网络的基础上去除冗余层，在保持高分辨率的同时，融合不同尺度的特征；

​	GAU模块用于增强特征提取模块输出特征的表征能力，并进一步利用全局和局部特征。先将特征图在长、宽维度进行展平，再送入到GAU（Gated Attention Unit，门控线性单元）中，用于进一步利用全局和局部空间信息，与普通自注意力机制相比，它具有更快的速度、更低的内存成本和更好的性能；

**编码模块**（simcc+gcn)

​	包括两层全连接层，用于将注意力模块输出的特征编码为两条一维向量，并通过缩放因子增强其定位精度。

**解码模块**

嵌入位置信息，并进一步利用全局和局部特征；所述编码模块，

