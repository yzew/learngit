Multi-Instance Pose Networks: Rethinking Top-Down Pose Estimation

# 摘要

​	自顶向下的人体姿态估计方法的一个关键假设是期望输入边界框中存在单个人/实例。这通常会导致在拥挤的场景中出现遮挡。我们提出了一种新的解决方案来克服这一基本假设的局限性。我们的多实例姿态网络（MIPNet）允许预测给定边界框内的多个2D姿态实例。我们引入了一种**多实例调整模块（MIMB）**，它可以自适应地调整每个实例的通道特征响应，并且参数有效。我们通过对COCO、CrowdPose和OCHuman数据集进行评估，证明了我们方法的有效性。具体而言，我们在CrowdPose上实现了70.0 AP，在OCHuman测试集上实现了42.5 AP，分别比现有技术显著提高了2.4 AP和6.5 AP。当使用地面真实边界框进行推断时，与HRNet相比，MIPNet实现了COCO上0.7 AP、CrowdPose上0.9 AP和OCHuman验证集上9.1 AP的改进。有趣的是，当使用较少的高置信度边界框时，HRNet在OCHuman上的性能会降低（降低5 AP），而MIPNet在相同输入下保持相对稳定的性能（降低1 AP）。 

# 介绍

​	人体姿势估计旨在定位给定图像中的2D人体解剖关键点（例如，肘部、手腕等）。当前的人体姿势估计方法可以分为自上而下或自下而上的方法。自顶向下方法[6，13，33，40，41，43，44]将边界框内的图像区域（通常是人体检测器的输出）作为输入，并将问题简化为单个人类姿态估计的更简单任务。相反，自底向上的方法[3，22，29，32]从独立定位整个图像中的关键点开始，然后将它们分组为2D人类姿势实例。 

​	自上而下的方法所做的单一人类假设将推理限制在能够最好地说明输入的单个人体关节结构（单个实例）。 自顶向下的姿态估计方法[6，16，30，40，44]目前在COCO[25]，MPII[2]等数据集上表现最好。**然而，当呈现包含多个人类（如拥挤或被遮挡的实例）的输入时，自顶向下方法被迫为每个人类检测选择一个合理的配置/结构/外形。在这种情况下，自顶向下的方法可能错误地识别与前面的人相对应的姿势标志。**例如，见图1（中间）。因此，在CrowdPose[23]和OCHuman[48]等具有相对较高比例的遮挡实例（表1）的数据集上，由于单人假设，自顶向下方法的性能受到影响[8，23，48] 

​	在本文中，我们通过预测输入边界框的多个姿势实例来重新思考自顶向下2D姿态估计器的架构。我们提出的架构的关键思想是允许模型为每个边界框预测不止一个姿势实例。我们证明，这种概念上的改变提高了自顶向下方法的性能，特别是对于具有拥挤和严重遮挡的图像。预测每个边界框多个实例的一种新方法是将多个预测头添加到具有共享特征提取的主干网络的现有自上而下网络中。然而，这种方法无法学习对应于各种实例的不同特征。然后，一种蛮力方法将复制特征提取主干，尽管代价是N个实例的参数增加N倍。相比之下，我们的方法能够预测任何现有自顶向下架构的多个实例，而参数数量（<3%）和推断时间（<9ms，16%）略有增加。从技术上讲，我们的方法可以处理N>2个实例。然而，如图4所示，现有数据集中每个真值边界框具有3+注释姿态实例的示例数量非常少。因此，类似于[35，48]，我们主要关注涉及两个人的显性遮挡场景。 

​	为了实现给定边界框中多个实例的有效训练和推理，我们提出了一种新的多实例调整模块（MIMB）。MIMB基于标量实例选择器λ调制特征张量，并允许网络对N个实例之一进行索引（图2）。MIMB可以合并到任何现有的特征提取主干中，只需相对简单的（<15行）代码更改（请参阅补充）。在推断时，对于给定的边界框，我们改变实例选择器λ以生成多个姿势预测（图3）。 

​	由于自顶向下的方法依赖于目标检测器的输出，它们通常处理大量的边界框假设。例如，HRNet[40]使用来自Faster R-CNN[37]的超过100K个边界框来预测COCO val数据集中6000人的2D姿势。这些边界框有很多重叠，并且大多数具有低检测分数（<0.4）。这也会对推理时间产生不利影响，推理时间随输入边界框的数量线性增加。如图5所示，使用更少的高置信度边界框会使HRNet在OCHuman上的性能从37.8 AP降低到32.8 AP，性能降低了5 AP。相比之下，MIPNet是健壮的，并且对于相同的输入保持相对稳定的性能（下降1 AP）。直观地，我们的方法可以基于邻居的预测来预测对应于没有检测到的检测框的2D姿势实例 

​	总体而言，MIPNet在表1所示的各种数据集上优于自顶向下方法和遮挡特定方法。对于CrowdPose和OCHuman等具有挑战性的数据集，包含更大比例的杂乱场景（具有多个重叠的人），MIPNet创下了一个新的SOTA，在测试集上分别达到70.0 AP和42.5 AP，优于自下而上方法。我们的主要贡献是 

* 我们通过解决训练和推理过程中单人假设造成的限制，提出了自顶向下的2D姿态估计方法。我们的方法在CrowdPose和OCHuman数据集上取得了最先进的结果
* MIPNet允许通过独立调节每个实例的特征响应，有效预测给定边界框的多个姿势实例。
* 预测多个实例的能力使MIPNet对边界框置信度具有弹性，并允许它处理丢失的边界框，对性能的影响最小。 

# 2.相关工作

**有偏差的基准**：大多数人体姿势估计基准[1，2，12，20，25]并不统一地表示现实世界中可能的姿势和遮挡。COCO[25]和MPII[2]等流行数据集在IoU为0.3的拥挤场景下的注释少于3%，IoU为0.3[35]。COCO[25]中86%以上的注释有5个或更多关键点可见[38]。这些偏差已经渗透到我们最先进的数据驱动深度学习模型[45]中，不仅表现为对“尾部”数据的不良概括，而且令人惊讶的是，在网络架构的关键设计决策中。最近，有人提出了具有挑战性的数据集，如OCHuman[48]和CrowdPose[23]，这些数据集包含严重遮挡，以捕捉这些偏差。这些数据集证明了在严重闭塞情况下最先进模型的失效（第4.3节）。MIPNet在这种具有挑战性的条件下表现出显著的性能改善。 

# 3.方法

​	人体姿态估计旨在从输入图像x中检测K个关键点的位置。大多数自上而下的方法将此问题转化为估计K个热图。类似于[6，30，44]，我们定义了用于人体关键点检测的卷积姿态估计器P。训练和推理时的边界框缩放为H×W，并作为P的输入。y表示对应于给定输入x的地面真实关键点的K个热图。

## 3.1 训练

​	我们建议修改自上而下的姿态估计器P以预测多个实例。我们的姿态估计器P预测N个实例。这是通过在标量实例选择器λ(0—N-1)上调节网络P来实现的。P接受x和λ作为输入，并预测为^yi=P(x,λ=i)，其中i∈ {0，1，…，N−1}. 

​	设B_0表示用来对输入x进行裁剪的gt边界框。设Bi，i∈ ｛1，…n− 1} ，表示附加n− 1个与B0重叠的gt边界框，使得来自Bi的至少k＝3个关键点落在B0内。因此，B0，…，Bn−1表示x中存在的n个地面真实姿态实例的边界框。我们通过y0，…yn表示与这些n个实例对应的地面真实热图

​	为了定义损失，我们需要将预测的姿态实例分配给gt热图。将主实例^y0=P（x，λ=0）分配给y0，姿态实例对应于B0。 下一个N-1实例们被分配到剩下的根据其对应边界框与B0的距离排序的gt 概率图。我们训练网络P以最小化损失 

L=![image-20221211213947658](E:\MarkDown\picture\image-20221211213947658.png)

​	当n<=N时，可用的n个gt姿态实例用于计算n个预测的损失，使用y0计算剩余N-n个实例的损失。例如，当n＝1和N＝2时，这两个预测都被鼓励预测与x中存在的单个gt实例相对应的热图。 相反，当n>N时，仅使用N个gt姿势实例（最接近B0）来计算损失。 

​	根据我们的经验，采用其他启发式方法，例如不传播损失，即不关心剩余实例，会导致训练不稳定。此外，针对剩余实例的基于不关心的训练方案导致了显著更高的误报，特别是因为我们不知道运行时每个输入的有效的人员实例的数量。在推断过程中，我们改变λ以从相同的输入x中提取不同的姿态预测，如图3所示。 

## 3.2. Multi-Instance Modulation Block

​	在本节中，我们将描述可以在任何现有特征提取主干中轻松引入的多实例调制块（MIMB）。MIMB允许自顶向下的姿态估计器P从输入图像x预测多个实例。使用MIMB，P现在可以接受x和实例选择器λ作为输入。MIMB的设计灵感来自[14]的squeeze excite块。让X∈ R^(P×Q×C)是具有C个通道的中间特征图，使得X=[x1，x2，…，xC]。我们使用实例选择器λ去调整激励(excite)模块输出的通道激活，如图3（右）所示。我们的设计的关键见解是，我们可以使用同一组卷积滤波器来动态地适应输入中的不同实例。与复制特征骨干或为每个实例分配固定数量通道的暴力方法相比，我们的设计是参数高效的。 

​	设Fsq、Fex、Fem表示挤压、激发和嵌入操作。我们将λ表示为标量λ的一个one-hot表示。特征图X被变换为X'=[x'1，x'2，…，x'C]，如下所示，

![image-20221211221918585](E:\MarkDown\picture\image-20221211221918585.png)

Fsq使用全局平均池化来压缩全局空间信息为信道描述符。Fex允许在Fsq的输出上对通道交互进行建模。Fex被实现为两层全连接的神经网络。在激励模块的输出之后，我们使用来自另一个简单神经网络Fem的λ嵌入来调节通道激活。Fem的设计与Fex相似。 

​	在推断过程中，我们将实例选择器λ从0更改为N−1以获得N个预测，然后在合并所有预测后应用OKS-NMS[40]。详情请参阅补充资料。图2显示了来自HRNet和MIPNet的预测热图（使用N=2）。注意，HRNet仅输出与前景人物对应的热图，而MIPNet在推断时使用不同的λ值预测两个人的热图。 

## 4.实验

​	我们在三个数据集上评估MIPNet：COCO[25]、CrowdPose[23]和被遮挡的人类OCHuman[48]。这些数据集代表了不同程度的遮挡/拥挤（见表1），并有助于说明在自顶向下方法中预测多个实例的好处。我们报告了标准度量，如AP、AP50、AP75、APM、APL、AR、APeasy、APmed和APhard在[25，23]中定义的各种对象关键点相似度。我们报告了使用地面真实边界框以及通过YOLO[36]和Faster R-CNN[37]探测器获得的边界框的结果。

​	我们将MIPNet基于最近最先进的自顶向下架构，即SimpleBaseline[44]和HRNet[40]。**与HRNet相比，MIPNet采用了类似的特征提取主干，并在第3和第4阶段结束时在卷积块的输出处添加了MIMB**[40]。为了与SimpleBaseline[44]进行比较，在编码器的最后两个ResNet块中添加了两个MIMB。 

​	**实例数N**：通常，N=1相当于基线自顶向下方法。根据设计，MIPNet支持预测多个实例。根据经验，在数据集上，我们分别使用N=3和N=4，在N=2的基础上观察到0.3AP和0.5AP的小幅改善。这与大多数数据集的每个边界框很少有三个或更多gt姿态实例的事实相一致 (图4)。然而，如我们的实验所示，N=2比N=1基线提供了实质性的改进。注意，由于在我们的实验中，MIMB被添加到最后几个阶段，因此由于预测N=2个实例，推断时间的增加很小（表3）。对于输入分辨率为384×288的较大HRNet-48网络，推理时间增加8.2ms（16.7%）。对于较小的HRNet-32网络，运行时间增加4.7ms（11.9%）。这明显优于为每个实例复制主干，这将导致N=2的推理时间增加2倍。有关更多详细信息，请参阅补充。 























































