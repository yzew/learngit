人体姿态估计存在一个多视角问题，同一个人在不同视角下差异较大。想过通过错切等操作尝试达成变换视角来扩充数据，之后发现不可行

# 摘要

​	人体姿势估计旨在准确地估计各种各样的人体姿势。然而，现有数据集通常遵循一种long-tailed分布，即长尾分布，少数类别 (head class) 含有训练集中的多数标注数，而大量其余类别 (tail class) 仅有少数标注数据，这会导致对头部数据过拟合，对尾部类别欠拟合。不寻常的姿势只占一小部分，这进一步导致罕见姿势缺乏多样性。这些问题导致当前姿态估计网络的泛化能力较差。在本文中，我们提出了一种简单而有效的数据增强方法，称为Pose变换（PoseTrans），以缓解上述问题。具体而言，我们提出姿势变换模块（PTM）来创建具有不同姿势的新训练样本，并采用姿势判别器来确保 增强姿势 的合理性。此外，我们提出了姿势聚类模块（PCM）来测量姿势稀有度，并选择“最稀有”的姿势，以帮助平衡长尾分布。在三个基准数据集上的大量实验证明了我们方法的有效性，尤其是在罕见姿势上。此外，我们的方法高效且易于实现，可以很容易地集成到现有姿态估计模型的训练pipeline中。 

![image-20221130144445247](E:\MarkDown\picture\image-20221130144445247.png)

我们将MS-COCO数据集中的姿势分为20类，并使用预先训练的HRNet模型评估AP[43]。排名前1的类别有超过25000个样本和高精度，而近一半的类别样本少于2000个，精度相对较低。 

# 介绍

​	现有的人类姿态估计数据集并不统一地表示现实生活中所有可能的人类姿态。我们以MS-COCO数据集[31]为例，分析了人体姿势的分布，如图1所示。我们将姿势标准化，并将其分为20个类别。我们观察到，它遵循长尾分布，**少数常见的姿势类别（如站立和行走）占据了数据集的大部分，而不常见的姿势类型（如蹲下和跳跃）占据了较小的部分**。我们还发现，尽管当前最先进的数据驱动(data-driven)方法在常见姿势上取得了良好的性能，但是，由于长尾类别既没有足够的训练样本，也没有足够的多样性，因此它们在一些不常见姿势上仍会出现性能下降。 

​	由于收集和注释罕见姿势的示例的成本很高，解决这个问题的可行方法是数据扩充。先前的方法主要通过全局图像级变换(global image-level transformations)[37，12，35，45，42]（例如缩放和旋转）或局部对象级变换(local object-level transformations)[5，37，18]（例如复制粘贴和遮挡）来增强人体姿态。由于这些方法无法增加姿势的多样性并缓解长尾分布，因此它们对识别多样的罕见姿势几乎没有贡献。 

​	在本文中，我们提出了一种简单而有效的数据增强方法，称为Pose Transformation（PoseTrans），以应对上述挑战。PoseTrans由带有姿势判别器的**姿势变换模块（PTM）**和**姿势聚类模块（PCM）**组成。在训练期间，PTM将仿射变换应用于训练样本的原始姿势，并生成一组不同的新姿势。采用预训练的姿态鉴别器来评估生成的样本的合理性，然后过滤出不自然的样本。PCM基于高斯混合模型（GMM），该模型对数据集中的人体姿势进行归一化和聚类。罕见的姿势类型由具有小权重的高斯分量表示。PCM评估每个候选姿势的分量密度，并选择“最稀少”的一个（即分量密度的最小加权和）作为最终的增强训练样本。通过变换现有姿态，PoseTrans有助于通过PTM生成多样化、合理的姿态，并通过PCM缓解长尾分布问题。我们还设计了一个关注罕见姿势的指标，称为平衡(balanced) AP/AR，并观察到该指标的更多性能增益。我们的方法易于实现，并且可以很容易地集成到现有姿态估计模型的训练流水线中。 

我们总结我们的贡献如下：

•我们提出了一种简单而有效的数据增强方法，称为PoseTrans。为了解决不寻常的人类姿势的有限多样性问题，我们提出了一种新的姿势变换模块（PTM），该模块带有姿势鉴别器，以生成具有多样和合理姿势的新训练样本。

•我们提出姿势聚类模块（PCM）来测量姿势稀有度，并选择稀有姿势进行数据扩充，这有助于平衡训练集的长期分布。

•在各种姿态估计数据集上的大量实验表明，PoseTrans始终提高了各种最先进姿态估计器的性能，尤其是在罕见姿态上。 

# Related Works

## Data Augmentation数据扩充

数据扩充已被广泛用于提高模型泛化能力。对于图像分类，常用的增强方法包括information dropping信息丢弃、多图像信息混合、自动扩增 。对于人体姿态估计，数据增强主要集中于全局图像级变换[37，12，35，45，42]（例如缩放、旋转和翻转）和局部对象级变换[5，37]（例如复制粘贴、遮挡）。这些常见的数据增强方案增强了遮挡情况下的全局平移不变性和鲁棒性，但难以提高对罕见姿态的免疫力。最近，一些增强方法[18. Fang, H.S., Sun, J., Wang, R., Gou, M., Li, Y.L., Lu, C.: Instaboost: Boosting instance segmentation via probability map guided copy-pasting. In: Int. Conf. Comput. Vis. pp. 682–691 (2019)  19.Fang, H.S., Xie, Y., Shao, D., Li, Y.L., Lu, C.: Decaug: Augmenting hoi detection via decomposition. In: AAAI. pp. 1300–1308 (2021]提出对实例执行jitting以增加模型的泛化，但它们既不会改变实例本身，也不会改变实例的分布。与现有的数据增强策略不同，我们提出了一种新颖、简单、有效的PoseTrans增强方案，该方案可以直接生成各种罕见姿态。 

##  Long-tailed Distribution

在视觉识别中，存在一个具有挑战性的长尾训练集分布问题，其中一小部分类具有大量训练样本，而分布尾部的类具有少量样本[51]。过度采样Over-sampling[8]和重新加权re-weighting[17]是解决这一问题的两种常用方法。过采样方法通过在训练期间重复数据样本来提高次要类的频率水平。重新加权方法为这些次要类别分配了更高的损失权重，从而增加了它们的重要性。然而，这样的方法不会增加数据的多样性，并且容易受到过拟合的影响，从而导致性能下降。其他方法还包括强制类间边距的度量学习[22]和学习从少数镜头模型参数回归许多镜头模型参数的元学习[44]，但它们仅设计用于视觉识别。在**人体姿态估计**中，我们遇到了类似的问题。对于许多人类姿态估计数据集[31，3，29]，例如MS-COCO数据集[31]，人类姿态的分布是高度偏差的，这并不统一地表示现实生活中的人类姿态。这些数据集偏差导致这些“长期”姿势的泛化能力差，检测精度降低。为了解决上述问题，我们提出了一种简单而有效的PoseTrans方法来创建所需的各种姿势。 

# Method

## 3.1 Overview

生成data imitation的过程：
1、就是给定一张原图之后，我们会对它做human parsing得到每一个肢体的分割结果。我们有了这个分割结果，再加上原图，就可以对这个肢体做姿态的变换（PTM）。
2、姿态变换之后有一些变换的肢体其实不符合人的人的自然的骨架的形式。这些不符合自然骨架的图像或者是生成的这个图像质量比较差，那这些就是不合格的一些图片，我们就会把它删掉。
3、对于这些合格的图片，我们可能会产生多种多样的姿势。就会形成一个Candidate Pose Pool，这个Pose Pool里就可能有一些候选的生成的结果。接下来我们会对这个候选的结果去判断它们的罕见程度。（这一步骤使用的就是PCM模块）
4、使用PCM模块后，把它聚成若干类，比如这个例子里，会把它聚成了三类，这个 A 类是站立的肢体，然后 B 类是侧身的，C 类是坐着的。

这张图在经过我们的聚类模块之后，它就会得到这样一个聚类结果，它以 0.3 的概率属于这个 A 类，然后 0.4 的概率属于这个 B 类，0.3的概率属于这个 C 类。我们发现在这三张图当中，这一类是相对来说最罕见的，因为它的这个 C 类这个罕见肢体的概率比较高。这样的话我们就会选择这个比较罕见的一个肢体作为我们的训练样本。


![image-20221130151401925](E:\MarkDown\picture\image-20221130151401925.png)

图2：PoseTrans概述。给定单个人类图像x及其关键点注释y，我们首先通过人工解析（Human Parsing）将人体分割成不同的部分。PTM在人体的四肢上应用仿射变换来构造新的姿势。预先训练的姿态鉴别器用于合理性检查。合理的姿势形成候选姿势池<img src="E:\MarkDown\picture\image-20221130151748871.png" alt="image-20221130151748871" style="zoom:45%;" />，其中t∈ {1,2,3}为例。对于姿势<img src="E:\MarkDown\picture\image-20221130151840099.png" alt="image-20221130151840099" style="zoom:45%;" />，PCM预测wt，这是属于每个类别的概率（以3个类别为例)。PCM选择分量密度加权和最小的最稀疏的一个作为新的训练样本，即<img src="E:\MarkDown\picture\image-20221130151952656.png" alt="image-20221130151952656" style="zoom:30%;" /> 

​	为了增加姿势的多样性并缓解长尾分布问题，我们提出了姿势变换（PoseTrans），以生成具有不同姿势的新训练样本，如图2所示。PoseTrans包括带有姿势鉴别器 D 的姿势变换模块（PTM）和姿势聚类模块（PCM）。给定由单个人类图像x及其关键点注释y组成的训练样本（x，y），PTM旨在通过在人类四肢上应用仿射变换来创建新的训练样本，其中<img src="E:\MarkDown\picture\image-20221130151147167.png" alt="image-20221130151147167" style="zoom:30%;" />。H、W和J表示高度、宽度和关键点的数量。为了确保合理性，我们利用姿态鉴别器D过滤掉不可信的样本。PoseTrans重复应用PTM，直到形成具有T个合理生成的姿势的候选姿势池。PCM将人类姿势分类为N个类别，并评估属于生成姿势的每个类别的概率，以从池中选择最罕见的姿势作为新的训练样本（如图中pc最罕见，第二个姿势是pc的概率最大，就选了那个）。在每个训练epoch之后，我们使用原始训练集和所有选定的增强样本重新拟合PCM。 



## 3.2 Pose Transformation Module (PTM) and Pose Discriminator

姿势变换模块（PTM）和姿势鉴别器 

![image-20221130165021503](E:\MarkDown\picture\image-20221130165021503.png)

​	通过对现有数据集中的人类姿势进行聚类，可以观察到许多聚类只有几个示例。缺乏罕见姿势的训练示例进一步导致罕见姿势的多样性不足，这导致当前数据驱动方法在这些类型的姿势上的性能较差。为了解决这个问题，我们设计了姿势变换模块（PTM）和姿势鉴别器，以基于现有的训练样本创建可信的新姿势。PTM的详细信息如图3所示。 

![image-20221130152407775](E:\MarkDown\picture\image-20221130152407775.png)

图3 PTM 通过利用人工解析（Human Parsing）结果，我们首先从x中删除肢体，然后以给定的概率p=0.5分别变换每个肢体。没有出现或被遮挡的肢体将不会被变换。右下角的放大视图表示在第i个肢体（下臂）上应用缩放si和旋转ri的仿射变换。 



​	**建模身体部位运动**。身体运动学骨架由姿势图构成，其中人体被划分为几个部分，即头部、躯干、左臂/右臂和左腿/右腿。在这项工作中，我们主要关注手臂和腿部的角度运动。角度运动（弯曲和伸展）发生在肩部、臀部、肘部、膝盖和手腕。弯曲会减小骨骼之间的角度（弯曲关节），而伸展增加了角度并使关节变直。通过将仿射变换应用于刚体的身体分割部位，可以对图像平面中的这些身体部件的运动进行建模。在我们的实现中，仿射变换由旋转和缩放组成。 

​	我们将肢体定义为连接自然相邻关节y_src和y_dst的单个的刚体身体部件，其中ysrc、ydst∈ R^2分别是源关节和目标关节的坐标。我们为每个实例定义K=8个肢体，包括下臂、上臂、小腿和两侧的大腿。 

​	**姿势变换**。利用 通过ECCV 2018的DensePose[1]模型获得的人体解析结果，PTM首先通过有效的修复方法擦除x中的原始肢体[Navier-stokes, fluid dynamics, and image and video inpainting. In: IEEE Conf. Comput. Vis. Pattern Recog. vol. 1, pp. I–I.IEEE (2001) ]。之后，每个肢体分别通过其仿射变换矩阵进行变换。为了增加多样性，每个分支有一个p=0.5的概率来决定是否变换。变换的肢体和修复的图像被合成以形成新的增强图像<img src="E:\MarkDown\picture\image-20221130154044497.png" alt="image-20221130154044497" style="zoom:50%;" />。并且姿势标注也被相应地变换以得到<img src="E:\MarkDown\picture\image-20221130154055931.png" alt="image-20221130154055931" style="zoom:50%;" />。 

​	具体地，第i个肢体的角度运动the angular movement可以通过以下仿射变换矩阵来建模 

![image-20221130154150596](E:\MarkDown\picture\image-20221130154150596.png)

​	<img src="E:\MarkDown\picture\image-20221130154214173.png" alt="image-20221130154214173" style="zoom:60%;" />表示第i个肢体的比例和旋转，<img src="E:\MarkDown\picture\image-20221130154249716.png" alt="image-20221130154249716" style="zoom:62%;" />是第i个肢体的旋转中心的坐标。对于前臂、上臂、小腿和大腿，旋转中心分别为肘部、肩部、膝盖和臀部。为了确保增强姿态的多样性，Hi中的比例si和旋转ri参数为 从恒等变换（1，0）的相邻空间中的正态分布 中随机采样。在我们的实现中，比例和旋转参数也被限制在一定范围内，以确保大多数随机生成的姿势是合理的。请注意，不会变换图像中未显示或被遮挡的肢体。 

​	根据运动学骨骼层次，上臂/腿的运动将影响其下部的运动。假设第j个肢体是下臂/腿，第k个肢体是其相应的上部。考虑到组合效应，第j个肢体的总运动可以通过矩阵乘法（即Hk Hj）来建模。 

​	**Pose discriminator for the plausibility check用于合理性检查的姿势鉴别器** 。纯粹随机生成的姿势可能会导致违反人体生物力学结构的难以置信的姿势。一些其他增强方法[30，10]依赖于预定义的规则来确保合理性，但这限制了生成姿势的多样性。受到[Poseaug: A differentiable pose augmentation framework for 3d human pose estimation. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. pp. 8575–8584 (2021)]的启发，我们设计了一个适合我们任务的姿势鉴别器D，以避免场景中关节角度不自然或位置不合理的不可信姿势。对于扩增样本<img src="E:\MarkDown\picture\image-20221130160349601.png" alt="image-20221130160349601" style="zoom:50%;" />，鉴别器D被训练来预测似然性<img src="E:\MarkDown\picture\image-20221130160452760.png" alt="image-20221130160452760" style="zoom:60%;" />。在训练姿态估计器之前，我们采用LS-GAN损失[IEEE2017:Least squares generative adversarial networks]来训练鉴别器： 

![image-20221130160525365](E:\MarkDown\picture\image-20221130160525365.png)

通过预先训练的鉴别器D，PoseTrans有效地过滤出可信度小于预定义阈值E∈ [0,1]的扩增样本，并用可信且多样的样本填充候选姿势池。 

## 3.3 Pose Clustering Module (PCM)
在通过PTM获得 创建新人类姿势 的能力之后，我们提出姿势聚类模块（PCM）来测量姿势的稀有性，并选择所需的姿势进行数据增强。 

这个姿势聚类其实非常简单，一共就分为三步。
第一步，就是归一化，会对所有的训练样本（根据人体检测框）进行人体姿态的一个归一化
第二步，把这个归一化后的人体关键点的向量去拟合一个高斯混合模型。这样做姿态的聚类，我们会把它聚类成 20 类，这里就会自然地聚类成这种站立或者侧身或者蹲着的这种不同的姿势。
第三步，有了这样拟合好的高斯混合模型之后，就可以拿它去做预测。我们给定一个输入的图片，就能预测出它是属于哪一个类别，同时能够知道它归属于各个类别的一个高斯分量的概率。



​	**Fitting the PCM**。我们的PCM基于具有N个高斯分量的高斯混合模型（GMM）。作为一种软聚类方法，它预测属于某一类别的概率。在姿态聚类之前，首先对训练集中的人类姿态进行归一化。我们裁剪图像上的每个人类实例，并将裁剪的图像重新缩放为相同的高度和宽度（256×256）。相应的关键点坐标也同时被归一化。我们使用训练集中的标准化人体姿势来拟合PCM。拟合后，给定姿势y，我们将P(y)建模为： 

![image-20221130161057905](E:\MarkDown\picture\image-20221130161057905.png)

![image-20221130161111276](E:\MarkDown\picture\image-20221130161111276.png)

covariance:协方差

​	通过预测属于每个高斯分量的概率，人体姿势被分类为具有最大概率的分量。我们使用t-SNE[32]可视化每个示例的概率向量，如图4所示。使用PCM，我们将人类姿势分类为N个类别，其中权重较小的高斯分量（即少数示例）表示罕见姿势的类别。我们观察到一个长尾问题，即正面站立占很大比例，而蹲姿和侧身姿势占很小比例。 

![image-20221130161523914](E:\MarkDown\picture\image-20221130161523914.png)

图4：通过t-SNE降维算法对聚类结果的可视化。不同的颜色点表示不同的簇。站姿、蹲姿和侧姿的代表性图像和平均骨架也被可视化。 

​	**Pose selection from the candidate pose pool.从候选姿势池中选择姿势。** PoseTrans重复PTM以构建具有训练样本(x，y)的T个样本的候选姿势池<img src="E:\MarkDown\picture\image-20221130161730571.png" alt="image-20221130161730571" style="zoom:60%;" />其中t∈{1，2，…，T}。PoseTrans在候选姿势池中选择最稀有的一种<img src="E:\MarkDown\picture\image-20221130161810153.png" alt="image-20221130161810153" style="zoom:60%;" />：

<img src="E:\MarkDown\picture\image-20221130161839682.png" alt="image-20221130161839682" style="zoom:67%;" />

其中，<img src="E:\MarkDown\picture\image-20221130161922040.png" alt="image-20221130161922040" style="zoom:67%;" />是通过拟合PCM 预测的~yt属于N个高斯分量的概率。 我们考虑变换后的样本<img src="E:\MarkDown\picture\image-20221130162038305.png" alt="image-20221130162038305" style="zoom:50%;" />其中分量密度的最小加权和是最罕见的，并将其选择为新的训练样本。 































