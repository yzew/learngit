[Benchmarking and Error Diagnosis in Multi-Instance Pose Estimation翻译](https://zhuanlan.zhihu.com/p/429277476)

[官方tensorflow代码](https://github.com/mks0601/PoseFix_RELEASE)

[个人pytorch实现](https://github.com/heimish-kyma/Pytorch-PoseFix)

PoseFix: Model-agnostic General Human Pose Refinement Network

PoseFix:模型不可知的一般人体姿态细化网络

Backbone:ResNet50

# Abstract

​	从二维图像中估计多人姿态是理解人类行为的一项重要技术。在本文中，我们提出了一个人体姿态优化网络，它从输入图像和输入姿态的组中估计出一个经过优化的姿态。在以往的方法中，主要是通过端到端可训练的多阶段体系结构来实现姿态细化。然而，它们高度依赖于姿态估计模型，需要仔细的模型设计。相比之下，我们提出了一种**模型无关的姿态细化方法**。根据最近的一项研究，最先进的二维人体姿态估计方法具有**类似的误差分布**。我们**使用这些误差统计作为先验信息来生成合成姿态，并使用合成姿态来训练我们的模型**。在测试阶段，可以将任何其他方法的姿态估计结果输入到所提出的方法中。此外，所提出的模型不需要代码或其他方法的知识，这使得它在后处理步骤中很容易使用。结果表明，该方法比传统的多阶段细化模型取得了更好的性能，并在常用基准上持续改进了各种最先进的姿态估计方法的性能。

# 1. Introduction

​	人体姿态估计的目标是定位人体的语义关键点。它是理解人类行为和人机交互的重要技术。最近，许多方法[5,7,11,14,15,18,20,22,23,26,30]利用深度卷积神经网络(CNNs)实现了显著的性能改进。他们也在更新二维人体关键点检测年度比赛的性能上限，如MS COCO关键点检测挑战[19]。

​	在本文中，我们提出了一种人体姿态精细化网络，从输入图像和姿态的元组中估计出精确姿态的工作。传统上，姿态精细化主要由多级结构完成[4,7,21,29]。也就是说，第一阶段生成的初始姿态和图像特征经过后续的阶段，每个阶段输出一个细化的姿态。这些多阶段体系结构通常以端到端方式进行训练。然而，传统的基于多阶段体系结构的细化方法高度依赖于姿态估计模型，需要精心设计才能成功细化。相比之下，在本研究中，我们提出了一种不依赖于姿态估计模型的模型无关的姿态细化方法。

​	Ronchi等人[**Benchmarking and error diag-nosis in multi-instance pose estimation**. In ICCV, 2017.]最近的研究为我们设计一个通用的模型不可知姿态优化器提供了线索。他们使用新的姿态估计评估指标，即关键点相似度(KS)和物体关键点相似度(OKS)，分析了MS COCO 2016关键点检测挑战优胜者的结果[5,22]。他们将姿态估计误差分为几种类型，如抖动、反转、互换、并描述了这些错误发生的频率以及它们对性能的负面影响。虽然胜利者[5,22]使用的方法非常不同，但他们的姿态误差分布非常相似，这表明更准确的位姿估计存在共同的问题

​	我们的基本思想是使用该误差统计作为先验信息来生成合成姿态，并使用合成姿态训练所提出的姿态优化模型(PoseFix)。为了训练我们的模型，我们基于Ronchi et al[24]的姿态误差分布，生成各种类型的误差(即抖动、反转、交换和错过)，并构建不同的和真实的姿态。生成的输入姿势与输入图像一起馈送给PoseFix, PoseFix学习改进姿势。我们将PoseFix设计为具有从粗到细的评估pipeline的单阶段体系结构。它以粗的形式接受输入的姿态，并以更细的形式估计细化的姿态。粗糙的输入姿态使所提出的模型不仅专注于输入姿态的精确位置，而且围绕它，允许我们的模型修正输入姿态的误差。此外，与现有的方法相比，更精细的输出姿态形式使所提出的模型能够更准确地定位姿态的位置。经过训练后，我们的PoseFix可以应用于任何单一或多人姿态估计方法的姿态估计结果，并对其进行优化。图1显示了提议的PoseFix的这样一个姿态细化pipeline。

![image-20221115151733119](E:\MarkDown\picture\image-20221115151733119.png)

测试PoseFix的pipeline。该方法将其他方法的姿态估计结果与输入图像进行比较，并输出一个细化的姿态。注意，PoseFix不需要任何关于其他方法的代码或知识

我们的贡献可以总结如下

* 我们表明，模型无关的一般姿态细化是可能的。PoseFix训练独立于姿态估计模型。相反，它是基于通过实证分析获得的误差统计数据。

* 我们的PoseFix可以将任何姿态检测方法的姿态估计结果作为输入。由于PoseFix不需要任何其他方法的代码或知识，因此我们的模型具有非常高的灵活性和易用性。

* 我们将PoseFix设计为一个由粗到细的估算系统。我们根据经验观察到，这种从粗到细的管道对于成功姿态细化是至关重要的。

* 与传统的基于多阶段体系结构的细化方法相比，我们的PoseFix取得了更好的结果。此外，PoseFix持续改进了各种最先进的姿态估计方法在常用基准上的性能。

# 2. Related works

**Human pose refinement**

许多方法试图改进估计的关键点，以获得更精确的性能。Newell等人[21]，Bulat和Tzimiropoulos [4]， Liu等人[29]和Chen等人[7]利用了端到端可训练的基于多阶段体系结构的网络。每一个阶段都试图通过端到端学习来改进前一阶段的姿态估计结果。Carreria等人[Human pose estimation with iterative error feedback. In CVPR,
2016.]迭代估计了来自共享权重模型的误差反馈。将前一次迭代的输出误差反馈转化为下一次迭代的输入位姿，进行多次迭代，逐步进行位姿细化。所有这些方法都将姿态估计和细化结合到一个模型中，每个细化模块都依赖于估计。因此，细化模块具有不同的结构，不能保证它们与其他估计方法相结合时能够成功工作。另一方面，我们的姿态优化方法与估计无关，因此不管之前的姿态估计方法如何，结果都可以持续改进。

​		最近，Fieraru等[Learning to refine human pose estimation. CVPRW, 2018]提出了一种后处理网络来细化其他方法的姿态估计结果，这在概念上与我们的方法类似。他们综合了训练的姿势，并采用了简单的网络结构，估计每个关节的细化热图和偏移向量。他们的方法遵循特定规则生成输入位姿，而我们的方法是基于通过经验为依据的分析获得的实际误差统计。此外，我们的网络从粗到精的结构也取得了更强的细化性能。

# 3. Overview of the proposed model

PoseFix的目标是细化输入图像中所有人的人体关键点的输入2D坐标。为了解决这一问题，我们的系统是基于自顶向下的pipeline来构建的，它处理裁剪后的人体图像和给定的人体姿态估计结果，而不是处理包含多个人的整个图像。在训练阶段，输入姿态在gt姿态下真实、多样地合成。在测试阶段，任何其他方法的位姿估计结果都可以作为系统的输入位姿。PoseFix的整个管道如图2所示。

![image-20221115153528100](E:\MarkDown\picture\image-20221115153528100.png)

图2:PoseFix的整体管道。在训练阶段，输入姿态通过合成姿态误差生成，其中姿态误差基于gt pose的真实姿态误差分布。在测试阶段，任何其他方法的位姿估计结果都成为输入位姿。通过沿通道轴执行最大池化来可视化heatmap。

# 4. Synthesizing poses for training

​	为了训练PoseFix，我们使用groundtruth pose生成合成pose。由于PoseFix在测试阶段需要覆盖来自不同方法的不同姿态估计结果，因此合成的姿态需要多样化和逼真。为了满足这些特性，我们根据[24]中描述的真实位姿的误差分布随机生成合成位姿。分布包括每个姿态误差(即抖动、反转、交换和遗漏)的频率，根据关节类型、可见关键点的数量和输入图像中的重叠。也可能存在没有任何误差的关节，这些关节应该非常接近于groundtruth进行合成，以模拟正确的估计。Ronchi等人称这种状态是好的。考虑到[24]中的大多数经验分布，我们计算了每个关节有其中一个姿态误差或处于良好状态的概率。

​	属于p（一个人）的关节j的每个gt关键点θp_j的详细的误差合成步骤如下所示。为了更清楚地描述，我们将 j‘ 定义为来自j的左/右倒置关节，将 p’ 定义为与输入图像中的p不同的人。另外，dkj被定义为一个L2距离，让关节j的groundtruth关键点的KS变为k（意思就是关键点移动了d，ks就变为了K的值）。注意，dkj取决于关节j的类型，因为每个关节的误差分布有不同的尺度[24]。例如，眼睛需要比臀部更精确的定位来获得相同的KS，即 k。图3可视化了每种类型的合成姿势误差的例子。

![image-20221115154739326](E:\MarkDown\picture\image-20221115154739326.png)

每种类型的合成姿态误差的可视化。带有姿态误差的关键点用黄色矩形突出显示，而groundtruth关键点则画在黄色圆圈中。



**GOOD**	好的状态被定义为一个与gt关键点**非常小**的位移。从[0,2Π)和<img src="E:\MarkDown\picture\image-20221115155026828.png" alt="image-20221115155026828" style="zoom:70%;" />均匀采样角度和长度的偏移向量 分别被添加到<img src="E:\MarkDown\picture\image-20221115155121153.png" alt="image-20221115155121153" style="zoom:67%;" />上。比起<img src="E:\MarkDown\picture\image-20221115155235363.png" alt="image-20221115155235363" style="zoom:67%;" />，合成的关键点位置应更接近原始的groundtruth<img src="E:\MarkDown\picture\image-20221115155249601.png" alt="image-20221115155249601" style="zoom:67%;" />

**Jitter **	抖动误差被定义为从gt关键点的一个**小**位移。一种角度和长度<img src="E:\MarkDown\picture\image-20221115155951748.png" alt="image-20221115155951748" style="zoom:67%;" />均匀采样的偏移向量被加入到gt <img src="E:\MarkDown\picture\image-20221115155249601.png" alt="image-20221115155249601" style="zoom:67%;" />中。同样，比起<img src="E:\MarkDown\picture\image-20221115155235363.png" alt="image-20221115155235363" style="zoom:67%;" />，合成的关键点位置应更接近原始的groundtruth<img src="E:\MarkDown\picture\image-20221115155249601.png" alt="image-20221115155249601" style="zoom:67%;" />

**Inversion**	当一个姿态估计模型中属于同一实例的语义相似部分发生混淆，就会发生反转错误。我们将反转误差限制在左右身体部分的混淆。

**Swap**	交换错误是指属于不同人的相同或相似部分之间的混淆。抖动被加到<img src="E:\MarkDown\picture\image-20221115160624172.png" alt="image-20221115160624172" style="zoom:67%;" />中。离合成关键点最近的关键点应该是<img src="E:\MarkDown\picture\image-20221115160732713.png" alt="image-20221115160732713" style="zoom:67%;" /><img src="E:\MarkDown\picture\image-20221115160748794.png" alt="image-20221115160748794" style="zoom:67%;" />

**Miss**	Miss error表示与groundtruth关键点位置的**较大**位移。![image-20221115160836906](E:\MarkDown\picture\image-20221115160836906.png)

合成输入姿势的一些例子如图4所示

![image-20221115160907744](E:\MarkDown\picture\image-20221115160907744.png)

图4：gt和合成输入姿势的可视化。合成的姿态是通过在groundtruth姿态中添加误差来生成的，这些误差用于训练PoseFix。

# 5. Architecture and learning of PoseFix

## 5.1. Model design

​	我们设计PoseFix从输入图像和输入姿态的元组中直接估计出一个精细的姿态，如图2所示。输入图像和输入姿势分别向PoseFix提供上下文和结构化的信息，而PoseFix学会使用这些信息来修复输入姿势中的姿势错误。尽管在输入位姿中存在一些错误，但它仍然提供了有用的结构化信息，因为正如Ronchi等人[24]指出的那样，输入位姿中的大多数关键点处于良好状态或有抖动误差，这表示从groundtruth位姿的一个小位移。这些粗略的结构化信息就像注意力一样，告诉PoseFix在人体的哪里集中注意力。

​	我们观察到，通过学习修复输入姿势中的姿势错误，PoseFix学习关注人体的位置，如图5所示。正如它所示，虽然在输入姿势中存在一些错误，但PoseFix最初很好地集中在输入姿势的可靠关键点位置上。在不受输入姿态误差影响的情况下，成功地定位了正确的关键点。

![image-20221115161847137](E:\MarkDown\picture\image-20221115161847137.png)

图5：PoseFix的特征图和最终heatmap的可视化。特征图和热图通过沿通道轴的最大池化简化为一个通道，以实现可视化。图中特征图和热图的顺序与前馈的顺序相同。

## 5.2. Coarse-to-fine estimation

​	为了使它对错误更加健壮，我们将提议的PoseFix设计为以一种从粗到细的方式操作。我们用“粗”和“细”来表示姿势的不确定性程度。例如，在表示构成一个姿态的每个关节的位置时，高斯斑有一个高的不确定度，与标准差的大小相等。另一方面，一个one-hot vector具有相对较低的不确定性，其大小可达一个量化网格的大小。关键点的坐标具有最少的不确定性，因为它提供了关于位置本身的确切信息。因此，在我们的工作中，粗到细的估计意味着由高斯blobs集合表示的粗的输入姿态<img src="E:\MarkDown\picture\image-20221115162613829.png" alt="image-20221115162613829" style="zoom:67%;" />信号被传入网络，以one-hot vector的形式生成更精细的姿态<img src="E:\MarkDown\picture\image-20221115162848707.png" alt="image-20221115162848707" style="zoom:67%;" />，然后是关键点坐标下的最佳姿势<img src="E:\MarkDown\picture\image-20221115162943542.png" alt="image-20221115162943542" style="zoom:67%;" />生成为最终输出，如图2所示。在本小节中，我们将更详细地描述这种从粗到细的估计。

​	输入姿态以粗略的形式被构造，通过single-mode高斯热图表示如下:

![image-20221115163244380](E:\MarkDown\picture\image-20221115163244380.png)

式中，Pn和(in,jn)分别为第n个关键点的输入热图和二维坐标，σ为高斯峰的标准差。生成的输入姿势与输入图像连接，并输入到PoseFix中。这种高斯热图表示适用于后续的卷积运算，因为它与输入图像按像素对齐。此外，由于输入姿势可能包含一些错误，可以使用blob中心周围的非零值来鼓励PoseFix不仅关注输入姿势的确切位置，而且还关注它周围的位置。

​	该网络从粗略形式的输入高斯热图中，依次生成第n个关键点的热图Hn和关键点坐标Cn。为了使Hn成为更精细的形式，我们使用一个one-hot向量来监督它。然后对Hn进行soft-argmax运算[26]，以可微的方式生成Cn。Soft-argmax被定义为输入热图和网格网格之间的基于元素的乘积，然后是求和，如图2所示。更精确地，二维坐标由Hn计算如下：

![image-20221115163633210](E:\MarkDown\picture\image-20221115163633210.png)

其中w和h分别为Hn的宽和高。我们的网络通过最小化基于交叉熵的积分损失[26]来训练，其定义如下:

![image-20221115163716465](E:\MarkDown\picture\image-20221115163716465.png)

其中L为基于交叉熵的积分损失，LH和LC两个损耗描述如下。

​	LH是沿空间轴对输出热图应用softmax函数后计算的交叉熵损失。LH的定义如下:

![image-20221115163801428](E:\MarkDown\picture\image-20221115163801428.png)

其中H*n和Hn分别是应用了softmax的gt和估计热图。如果groundtruth关键点坐标是整数，则groundtruth热图H *n是一个one-hot向量。否则，两个网格各自的的x轴和y轴将通过向上和向下取整操作选择，并通过线性推断，因此充满了可能性。LC是应用于以下坐标的所有L1损失之和：

![image-20221115164313645](E:\MarkDown\picture\image-20221115164313645.png)

其中C*n是第n个关键点的groundtruth坐标向量。LH迫使PoseFix在估计的热图中选择一个网格点，LC使PoseFix能够更精确地定位关键点，因为它是在连续空间中计算的，没有量化误差。





# 8. Conclusion

我们提出了一个新颖而强大的网络，PoseFix，用于人体姿势的改进。与传统的端到端多阶段体系结构模型不同，提出的PoseFix是一个模型无关的位姿细化网络。为了训练PoseFix，我们根据经验位姿误差分布在groundtruth位姿上合成了输入位姿误差。PoseFix采用粗糙形式的输入姿势，并以更精细的形式估计细化的姿势。由于PoseFix是模型无关的，所以它不需要任何关于目标模型的代码或知识。因此，它可以方便地用作后处理附加模块。

我们证明了PoseFix比传统的基于多阶段体系结构的姿态细化模块取得了更好的性能。此外，PoseFix在常用的姿态估计基准上持续提高了其他方法的准确性。















